{"title":"Tutorial 5: Data analysis in R","markdown":{"yaml":{"title":"Tutorial 5: Data analysis in R","author":[{"name":"Benjamin Delory","orcid":"0000-0002-1190-8060","email":"b.m.m.delory@uu.nl","affiliations":[{"name":"Environmental sciences group, Copernicus institute of sustainable development, Utrecht University"}]}]},"headingText":"About this tutorial","containsRefs":false,"markdown":"\n\n\nWelcome to this tutorial on data analysis in R!\n\nIn this tutorial, **our goal is to review some of the R functions you will need to analyse the data you have collected in the field and answer your research questions**. For this tutorial, we strongly recommend that you reflect on what you have learned in the Statistics GSS course during Period 3. The Statistics GSS course taught you many useful tools for data analysis. Now it's time to put them into practice on a real ecological data set. For this tutorial, you will be using the same POEM data as in the tutorial on data wrangling. If you don't remember what these data are, please refer to the first sections of the first tutorial on data wrangling.\n\nLet's get started!\n\n## Importing POEM data\n\nThe first thing to do after opening RStudio is to import the POEM data. This is exactly the same as what we already did in the first tutorial. [Try writing the code yourself this time]{.underline} (i.e. without looking too quickly at the solution)!\n\n### Download the POEM data from Zenodo\n\nThe POEM data that will be used in this tutorial are available on a [Zenodo repository](https://zenodo.org/records/10119982). You can download the data manually, but you can also do it using an R function called `download_zenodo()`. Let's give it a try.\n\nFirst, install the *inborutils* R package using the following code:\n\n```{r}\n#| eval: false \n#| echo: true \n#| warning: false \n#| message: false \n#| code-fold: false  \n\ninstall.packages(\"inborutils\", \n                 repos = c(inbo = \"https://inbo.r-universe.dev\",\n                           CRAN = \"https://cloud.r-project.org\"))\n```\n\nYou can now download the data used in this tutorial using `download_zenodo()`.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\ninborutils::download_zenodo(doi=\"10.5281/zenodo.10119982\",\n                            quiet=TRUE)\n```\n\nBy default, the data will be downloaded as a zip file and will be stored in your working directory. If you do not know what is your working directory, run `getwd()` in your R console. Let's extract (or unzip) the files we have just downloaded from Zenodo and let's store these files in a new folder called \"Data_POEM\":\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\nunzip(zipfile = \"Data_POEM_Paper1_Alonso-Crespo_et_al_2024-v1.0.zip\",       \n      exdir = \"Data_POEM\")\n```\n\n### Load R packages\n\nMost of the functions we need for the rest of this tutorial are available with base R and in R packages from the *tidyverse* collection. We will also need the `read_excel()` function from the *readxl* package and the `kable()` function from the *knitr* package. We will also need functions from the *vegan*, *car*, *emmeans,* and *viridis* R packages later in this tutorial. If they are not yet installed in your library, install it using `install.packages()`.\n\nYou can load all the packages required for this tutorial using `library()`.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\nlibrary(tidyverse) \nlibrary(readxl) \nlibrary(knitr)\nlibrary(vegan)\nlibrary(car)\nlibrary(emmeans)\nlibrary(viridis)\n```\n\n### Import data into R\n\nIn the POEM project, raw biomass data (measured at the species level) are stored in different folders for the experiment started in 2020 (POEM2020) and the experiment started in 2021 (POEM2021). For each experiment, there is one data file for each growing season. As the data is stored in Excel files (.xlsx), we can use `read_excel()` to import our data into R. For now, we will simply store each set of data in separate R objects.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\n#Import data from the first experiment (POEM2020)  \n\npoem2020_year1 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2020-07.xlsx\")\n\npoem2020_year2 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2021-06.xlsx\")\n\npoem2020_year3 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2022-06.xlsx\")  \n\n#Import data from the second experiment (POEM2021)  \n\npoem2021_year1 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2021-07.xlsx\")  \n\npoem2021_year2 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2022-06.xlsx\")  \n\npoem2021_year3 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2023-06.xlsx\")\n```\n\nIn RStudio, you can see how each data frame looks like using `View()`.\n\n```{r}\n#| eval: false \n#| echo: true \n#| warning: false \n#| message: false  \n\nView(poem2021_year1)\n```\n\nYou can see that each dataset consists of a number of observations (rows) of 6 variables (columns). These variables are:\n\n-   **Year**: the year of initiation of each experiment\n-   **Harvest**: the date at which biomass data were collected (YYYY-MM)\n-   **Plot**: the plot identification number (plot number - arrival order/replicate)\n-   **Quadrat**: the quadrat identification number (plant biomass was collected in 2 or 4 quadrats per plot)\n-   **Species**: the plant species name\n-   **SDW_g**: the shoot dry weight in grams\n\nTo enable data exploration and analysis, we now need to combine these different datasets, so that all the data is stored in the same R object. You can do this using `rbind()`.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\npoem_data <- rbind(poem2020_year1,\n                   poem2020_year2,\n                   poem2020_year3,\n                   poem2021_year1,\n                   poem2021_year2,\n                   poem2021_year3)\n```\n\n## Organise POEM data\n\nWrite R code to reorganise the data so that we can analyse them. Make sure to do the following:\n\n-   Create new columns based on the information contained in the Plot column. This can be done easily using `separate_wider_delim()` and `separate_wider_position()`. Make sure to add the following three columns to the dataset:\n\n    -   PlotID (the plot number)\n    -   Arrival (the order of arrival treatment: S, F, G, L, B)\n    -   Replicate (the replicate number)\n\n-   Make sure that PlotID and Replicate are stored as numerical variables. You can do this by combining `mutate()` with `as.numeric()`.\n\n-   Finally, rename the column storing plant biomass values (SDW_g). Name it \"Biomass\". You can do this using `rename()`.\n\n```{r}\n#| eval: true\n#| echo: true\n#| warning: false\n#| message: false\n\npoem_data <- poem_data |> \n  separate_wider_delim(cols = Plot,\n                       delim=\"-\",\n                       names=c(\"PlotID\", \"Treatment\"),\n                       cols_remove=TRUE) |> \n  separate_wider_position(cols = Treatment,\n                          width=c(Arrival=1, Replicate=1),\n                          cols_remove=TRUE) |> \n  mutate(PlotID=as.numeric(PlotID),\n         Replicate=as.numeric(Replicate)) |> \n  rename(Biomass=SDW_g)\n```\n\nLet's take a quick look at the first ten rows of our dataset using `head().` We can also use `kable()` in the *knitr* package to produce a nice looking table in your R console.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\nkable(head(poem_data, n = 10))\n```\n\n## Exercise 1: Do plant order of arrival and year of initiation of an experiment affect the total aboveground biomass production of plant communities?\n\n### Step 1: Calculate the total biomass production in each plot\n\nBefore starting analysing our data, we must first calculate the total biomass production of each plant community at each harvest date. This can be done by summing the biomass value of all species collected in a plot at a given harvest date. Use what you learned in the data wrangling tutorial to write a piece of R code that does that. When writing your code, remember the following:\n\n-   Store the dataset in a new object called `poem_data_biomass`.\n\n-   Do not forget to standardise biomass data in g/m². Each quadrat has a surface area of 0.1 m². Use `mutate()` to add a new column called \"Std_biomass\" to the dataset.\n\n-   Depending on the harvest date, all plant species located within 2 or 4 randomly positioned quadrats were collected in each plot. To obtain a biomass value per species and per plot, it is first necessary to calculate the average biomass value for each species in a plot at each harvest date (i.e., across quadrats). Use `group_by()` and `summarise()` to do that.\n\n-   Once you have calculated the average biomass value for each species in a plot, use `group_by()` and `summarise()` again to calculate the total aboveground biomass in each plot by adding up the yield (in g/m²) of all species in a plot.\n\n-   Only keep the data for the second harvest date of each sub-experiment (2021-06 for the experiment initiated in 2020, 2022-06 for the experiment initiated in 2021).\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n\npoem_data_biomass <- poem_data |> \n  mutate(Std_biomass=Biomass/0.1, #Convert to g/m²\n         .after = \"Biomass\") |>  #Specify that we want this new column to be after the Biomass column\n  group_by(Year, Harvest, PlotID, Arrival, Species) |> #Define grouping factors in your data\n  summarise(Std_biomass=mean(Std_biomass)) |> #Calculates the average productivity of each species in a plot\n  group_by(Year, Harvest, PlotID, Arrival) |> #Redefine groups (interested in summing biomass values across species)\n  summarise(Total_biomass=sum(Std_biomass)) |>  #Calculate total biomass production in each plot\n  filter((Year == 2020 & Harvest == \"2021-06\")|(Year == 2021 & Harvest == \"2022-06\"))\n```\n\nLet's take a quick look at the first ten rows of our new dataset using `head().`\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\nkable(head(poem_data_biomass, n = 10))\n```\n\n### Step 2: Visualise raw data\n\nBefore fitting a statistical model to our data, let's first create a plot to help us answer our research question: Do plant order of arrival and year of initiation of an experiment affect the total aboveground biomass production of plant communities?\n\nThis research question gives us important information about what needs to be represented. The first half of the question tells us that our graph should present results for all possible combinations of plant arrival order (S, F, G, L, B) and year of initiation (2020 and 2021). These are the fixed factors of the experiment. We can make sure that these columns are correctly interpreted as factors by using `factor()`. It may also be a good idea to reorder factor levels in a meaningful way (S, F, G, L, B). The second half of the research question tells us that we need to show the differences in total aboveground biomass production between all possible treatment combinations. This is the response variable of our experiment.\n\nUsing what you have learned in the previous tutorials, create a high-quality figure that answers the research question. Feel free to personalise your plot in any way you think best communicates the results (you do not necessarily have to produce the same plot as below). What can you already notice from this graph? Does it look like ANOVA (ANalysis Of VAriance)) assumptions are met?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\npoem_data_biomass$Year <- factor(poem_data_biomass$Year)\npoem_data_biomass$Arrival <- factor(poem_data_biomass$Arrival,\n                                    levels=c(\"S\", \"F\", \"G\", \"L\", \"B\"))\n\nplot <- poem_data_biomass |> \n          ggplot(aes(x=Arrival,\n                     y=Total_biomass))+\n          facet_grid(~Year)+\n          geom_jitter(height = 0,\n                      width=0.1,\n                      shape=1)+\n          stat_summary(fun.data = \"mean_cl_boot\")+\n          theme_bw()+\n          xlab(\"Plant order of arrival\")+\n          ylab(\"Total shoot dry weight (g/m²)\")+\n          theme(axis.title.x = element_text(margin = margin(t=10)),\n                axis.title.y = element_text(margin = margin(r=10)),\n                axis.text = element_text(colour=\"black\"))+\n          scale_y_continuous(breaks=seq(from = 100,\n                                        to = 600,\n                                        by = 100))\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot\n```\n:::\n\n### Step 3: Fit a model\n\nLet's fit a statistical model to study the relationship between our response variable of interest (Total_biomass) and our two experimental factors (Year and Arrival). There are different ways to do this in R. First, let's check whether a ***simple linear regression model*** can correctly model our data. We will use the `lm()` function to fit this linear model (this will give us the same results as the `aov()` function). Note that each group being compared has 5 independent observations, which is not sufficient to test the assumption that the data are normally distributed at each combination of factor levels.\n\nThe syntax to fit a simple linear regression model with two predictor variables in R is as follows:\n\n`model <- lm(Response ~ Predictor1*Predictor2, data)`\n\nThe asterisks (\\*) means that we want to take the interaction between predictor variables into account (you then assume that Predictor1 and Predictor2 have non-additive effects on your response variable). Using a plus sign (+) instead of an asterisks would fit a model without considering an interaction between predictors (in that case, you then assume that Predictor1 and Predictor2 have additive effects on your response variable).\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\n#Fit simple linear regression model\n\nmodel1 <- lm(Total_biomass ~ Year*Arrival,\n             data = poem_data_biomass)\n```\n\nBefore checking model results, let's first make sure that model assumptions are met. We can check for homoscedasticity by plotting model residuals (i.e., the difference between model predictions and observations) against fitted values (i.e., model predictions). This is called a residual plot. Fitted values can be calculated using `predict()`. Residuals can be calculated using `residuals()`. Try to create such a plot using what you have learned in previous tutorials. Do you notice any pattern in this residual plot?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot <- data.frame(predicted = predict(model1),\n           residuals = residuals(model1)) |> \n        ggplot(aes(x=predicted,\n                 y=residuals))+\n        geom_point()+\n        geom_hline(yintercept = 0,\n                   colour = \"red\",\n                   linetype = 2)+\n        theme_bw()+\n        xlab(\"Predicted values\")+\n        ylab(\"Residuals\")+\n        theme(axis.title.x = element_text(margin = margin(t=10)),\n              axis.title.y = element_text(margin = margin(r=10)),\n              axis.text = element_text(colour=\"black\"))\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot\n```\n:::\n\nIt seems that there is a strong mean - variance relationship in our data (heteroscedasticity), which means that the model we just fitted is not the best option. A better approach is to switch to a ***generalised linear model*** (also referred to as GLM). Generalised linear models can be fitted using the `glm()` function in the *stats* package. The syntax is exactly the same as for the `lm()` function, but there is an extra argument to specify: `family`. The `family` argument allows you to describe the error distribution and the link function to be used in the model.\n\n::: callout-note\n## Relationship between `lm()` and `glm()`\n\nA simple linear regression model (`lm()`) is a special case of a gaussian generalised linear model with an identity link. This means that\n\n`lm(Response ~ Predictor1*Predictor2, data)`\n\nand\n\n`glm(Response ~ Predictor1*Predictor2, data, family=gaussian(link=\"identity\")`\n\nproduce the same results.\n:::\n\nInstead of using a gaussian distribution, a gamma distribution can be used for a response variable that is continuous and strictly positive. Negative values and zeros are not allowed with a gamma distribution. This distribution is useful to model variables such as biomass, length, etc. Using a log link function will also help deal with heteroscedasticity. This can be done by writing `family=Gamma(link=\"log\")` in `glm()`.\n\nLet's fit a new model (this time a GLM) to our data.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\n#Fit simple linear regression model\n\nmodel2 <- glm(Total_biomass ~ Year*Arrival,\n              data = poem_data_biomass,\n              family = Gamma(link=\"log\"))\n```\n\nBefore checking model results, let's first create a residual plot. What do you notice? What's new in this residual plot?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot <- data.frame(predicted = predict(model2),\n           residuals = residuals(model2)) |> \n        ggplot(aes(x=predicted,\n                 y=residuals))+\n        geom_point()+\n        geom_hline(yintercept = 0,\n                   colour = \"red\",\n                   linetype = 2)+\n        theme_bw()+\n        xlab(\"Predicted values\")+\n        ylab(\"Pearson residuals\")+\n        theme(axis.title.x = element_text(margin = margin(t=10)),\n              axis.title.y = element_text(margin = margin(r=10)),\n              axis.text = element_text(colour=\"black\"))\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot\n```\n:::\n\nLet's now take a look at model outputs. You can do this using `summary()`. This output contains a wealth of useful information. The coefficient table gives you the coefficients of the model. When looking at the results of the statistical tests, it seems that only three to four coefficients in the equation above can be considered significantly different from zero (marked with a dot or an asterisks).\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\noutput <- summary(model2)\n```\n\n## Solution (output)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n\noutput\n```\n:::\n\nGLM models do not return any R² values (like for simple linear regression models). The closest we can get is to calculate the explained deviance:\n\n$$\nExplainedDeviance = 100 \\times \\frac{NullDeviance - ResidualDeviance}{NullDeviance}\n$$\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\nnull_deviance <- summary(model2)$null.deviance\nresidual_deviance <- summary(model2)$deviance\n\nexplained_deviance <- 100*(null_deviance-residual_deviance)/null_deviance\n```\n\nThe explanatory variables included in the model explain `r round(explained_deviance, 1)`% of the variation in total plant biomass production.\n\n### Step 4: Compare group means\n\nYou can use the `Anova()` function in the *car* package to produce an ANOVA table (in this case, an analysis of deviance table). This table shows that the two factors of our experiment interact with each other. This means that the effect of plant order of arrival on community biomass depends on the year of initiation of an experiment.\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\ntable <- Anova(model2)\n```\n\n## Solution (table)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\ntable\n```\n:::\n\nTo determine where the differences in community productivity lie between the plant arrival order scenarios for each sub-experiment, we need to perform a posthoc test. The `emmeans()` function in the *emmeans* R package is a good option for this. For the `emmeans()` function, we will need to specify a value for the following arguments:\n\n-   `object` (the object containing the fitted model)\n-   `specs` (a character vector specifying the names of the predictors for which levels must be compared). In this example, this is plant arrival order.\n-   `by` (a character vector specifying the names of the predictors to condition on). In this example, this is the year of initiation of an experiment.\n-   `contr` (a character value specifying the contrasts to be added). We will use pairwise contrasts (i.e., all possible pairs of groups will be compared).\n\nTo check the results of the posthoc test, we will then call a `summary()` function on the object produced by `emmeans()` . In `summary()`, we will use the `type` argument to specify that we want model predictions to be on the same scale as the original data (not log scale, but original scale in g/m²).\n\nWhat can you conclude from this posthoc test?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\ntable <- summary(emmeans(object = model2, \n                         specs = \"Arrival\", \n                         by= \"Year\",\n                         contr = \"pairwise\"), \n         type=\"response\")\n```\n\n## Solution (table)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\ntable\n```\n:::\n\nFor the sub-experiment set up in 2020, all plots where seeds were added (S, F, G, L) were on average more productive than free succession plots. Consequently, the observed effect on community productivity does not appear to be due to the manipulation of plant arrival order, but solely to whether or not seeds were sown in the plots at the start of the experiment. In 2021, there is no evidence of any difference in aboveground biomass production between plant arrival order scenarios.\n\n### Step 5: Add posthoc test results to the graph\n\nWe can add posthoc test results to a graph by adding annotations. This is often done by adding letters next to the groups being compared. Groups that do not share a common letter are considered statistically significantly different from each other (p \\< 0.05). We can easily add these letters to our graph in two steps:\n\n-   Start by creating a data frame (called `annotations` in the code below) that contains all the information that *ggplot2* needs to add the annotations to your graph. In our example, this data frame should have as many rows as annotations to add to the graph and must contain the following columns:\n\n    -   **Year**: the year of initiation of an experiment (2020 or 2021). Use the same column name as in `poem_data_biomass`.\n    -   **Arrival**: the plant order of arrival (S, F, G, L, B). Use the same column name as in `poem_data_biomass`.\n    -   **y**: the vertical coordinates where annotations should be added. You can freely choose the name of this column.\n    -   **Label**: the annotations to be added to the graph. You can freely choose the name of this column.\n\n-   Once this is done, add an extra layer to your ggplot object using `geom_text()`.\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n#| fig-align: center\n\nannotations <- data.frame(Year=rep(c(2020,2021), each=5),\n                          Arrival=rep(c(\"S\", \"F\", \"G\", \"L\", \"B\"), 2),\n                          y=rep(600, 10),\n                          Label=c(\"a\", \"a\", \"a\", \"a\", \"b\", \"a\", \"a\", \"a\", \"a\", \"a\"))\n\nplot <- poem_data_biomass |> \n          ggplot(aes(x=Arrival,\n                     y=Total_biomass))+\n          facet_grid(~Year)+\n          geom_jitter(height = 0,\n                      width=0.1,\n                      shape=1)+\n          stat_summary(fun.data = \"mean_cl_boot\")+\n          theme_bw()+\n          xlab(\"Plant order of arrival\")+\n          ylab(\"Total shoot dry weight (g/m²)\")+\n          theme(axis.title.x = element_text(margin = margin(t=10)),\n                axis.title.y = element_text(margin = margin(r=10)),\n                axis.text = element_text(colour=\"black\"))+\n          scale_y_continuous(breaks=seq(from = 100,\n                                        to = 600,\n                                        by = 100))+\n          geom_text(data=annotations,\n                    aes(x=Arrival,\n                        y=y,\n                        label=Label))\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n#| fig-align: center\n\nplot\n```\n:::\n\n## Exercise 2: Non-metric multidimensional scaling\n\n### Step 1: Choose a measure of association\n\n**Non-metric multidimensional scaling** (NMDS) is a technique often used in ecological research to visualise differences (or (dis)similarities) in species composition between ecological communities.\n\nThe first step is to choose a measure of association and calculate a dissimilarity matrix. This dissimilarity matrix will have as many rows and columns as ecological communities to be compared. The help page of the `vegdist()` function of the *vegan* package lists a number of dissimilarity indices for ecologists wishing to quantify dissimilarity in species composition between communities. You can access this help page by running `?vegdist` in your R console (a detailed discussion of the advantages and disadvantages of each dissimilarity index is beyond the scope of this tutorial). The Bray-Curtis dissimilarity is usually good at detecting ecological gradients (see `?vegdist`) and is often used as default when performing NMDS. This is the dissimilarity index we are going to use in this tutorial too.\n\n### Step 2: Organise your data\n\nTo obtain the dissimilarity matrix required for NMDS, we first need to reorganise our data so that each species has its own column and each ecological community has its own row (i.e., a site-by-species matrix). Use the `poem_data` object as a starting point. In your code, include the following steps:\n\n-   Store the dataset in a new object called `poem_data_wide`.\n-   Standardise biomass data in g/m². Each quadrat has a surface area of 0.1 m². Use `mutate()` to add a new column called \"Std_biomass\" to the dataset.\n-   Depending on the harvest date, all plant species located within 2 or 4 randomly positioned quadrats were collected in each plot. To obtain a biomass value per species and per plot, it is first necessary to calculate the average biomass value for each species in a plot at each harvest date (i.e., across quadrats). Use `group_by()` and `summarise()` to do that.\n-   Use `pivot_wider()` to reorganise your data (one column per species).\n-   Only keep the data for the second harvest date of each sub-experiment (2021-06 for the experiment initiated in 2020, 2022-06 for the experiment initiated in 2021).\n-   Remove all species columns that only contain zeros. You can do this using `select(where( ~ is.numeric(.x) && sum(.x) != 0))`.\n-   Remove the column named \"Unknown\".\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\npoem_data_wide <- poem_data |> \n  mutate(Std_biomass=Biomass/0.1, #Convert to g/m²\n         .after = \"Biomass\") |>  #Specify that we want this new column to be after the Biomass column\n  group_by(Year, Harvest, PlotID, Arrival, Species) |> #Define grouping factors in your data\n  summarise(Std_biomass=mean(Std_biomass)) |> \n  pivot_wider(names_from = Species, #Species names will be used as column names\n              values_from = Std_biomass, #Biomass values are stored in the Std_biomass column\n              values_fill = 0, #If a species is absent in a plot, its biomass value is zero\n              values_fn = sum) |>  #Sum biomass values measured on the same species and in the same quadrat\n  filter((Year == 2020 & Harvest == \"2021-06\")|(Year == 2021 & Harvest == \"2022-06\")) |>  #Filter data\n  select(where( ~ is.numeric(.x) && sum(.x) != 0)) |> \n  select(-Unknown)\n\nkable(head(poem_data_wide, 10))\n```\n\n### Step 3: Perform the NMDS\n\nNow that our community dataset has the right format, we can perform the NMDS using the `metaMDS()` function of the *vegan* package. The following arguments are of particular importance:\n\n-   `comm`: the community data (only select the species columns).\n-   `distance`: a character value for the dissimilarity index used. Use \"bray\" for the Bray-Curtis dissimilarity index.\n-   `k`: the number of dimensions to compute. Let's start with `k=2` (we want to produce a 2D plot).\n-   `trymax`: the maximum number of random starts in search of a stable solution. The NMDS algorithm iteratively searches for a stable solution (numerical optimisation methods). Increasing the value of this argument can help reaching a stable solution.\n\nWe will keep the default values for all other arguments. Store the results in an object named `nmds`. Do not forget to set a seed (using `set.seed()` for reproducibility).\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\nset.seed(123)\n\nnmds <- metaMDS(comm = poem_data_wide[,5:ncol(poem_data_wide)],\n                distance = \"bray\",\n                k = 2,\n                trymax = 100)\n```\n\n### Step 4: Check NMDS results\n\nThe main goal of NMDS is to visualise a dissimilarity matrix in a lower (typically 2D) dimensional space. Contrary to principal coordinate analysis (PCoA), which aims to create a plot in which distances between points match the original dissimilarities as closely as possible, NMDS focuses on representing the order, or ranking, of the original dissimilarities as closely as possible (Zuur AF, Ieno EN, Smith GM. 2007. *Analysing ecological data*. Springer.).\n\nThe first way to assess the quality of the display is to look at a parameter called \"stress\". You can extract it from the `nmds` object created earlier using `nmds$stress`. In our example, the stress value is equal to `r round(nmds$stress, 3)`. Zuur et al (2007) provided some guidelines on how to interpret stress values (usually, the lower the stress value, the better):\n\n-   stress \\< 0.05: Excellent configuration\n-   stress between 0.05 and 0.1: Good configuration\n-   stress between 0.1 and 0.2: Be careful with interpretation\n-   stress between 0.2 and 0.3: Problems start. Consider increasing the number of dimensions (`k`).\n-   stress above 0.3: Poor representation. Increase the number of dimensions (`k`).\n\nAnother way to assess the quality of the configuration is to create a Shepard plot. A Shepard plot shows the relationship between ordination distances (i.e., distances in the configuration produced by the NMDS) and original distances. You can produce a Shepard plot using the `stressplot()` function in *vegan*. What can you conclude from this Shepard plot?\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nstressplot(nmds)\n```\n\n### Step 5: Visualise NMDS results\n\nNMDS results are stored in our `nmds` object. You can extract the coordinates of each community using `nmds$points`. To make it easier to work with *ggplot2*, we will create a new data frame (`data_nmds`) by merging the first four columns of `poem_data_wide` (Harvest, Arrival, Year, PlotID) with NMDS results.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n\ndata_nmds <- cbind(poem_data_wide[, 1:4], nmds$points)\n\nkable(head(data_nmds, 10))\n```\n\nWe now have everything we need to plot the results of the NMDS using *ggplot2*:\n\n-   Create a plot displaying MDS1 on the horizontal axis and MDS2 on the vertical axis.\n-   Use a specific colour for each plant order of arrival scenario (mind colour-blind people!).\n-   Use a specific shape for each year of initiation.\n-   Add an informative legend to your graph.\n-   Add an annotation on the top left corner of your graph for the stress value. Use `geom_text()` to do that.\n\nWhat can you conclude from this NMDS?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n\n#Make sure that Arrival and Year are factors\n\ndata_nmds$Arrival <- factor(data_nmds$Arrival,\n                            levels=c(\"S\", \"F\", \"G\", \"L\", \"B\"))\n\ndata_nmds$Year <- factor(data_nmds$Year,\n                         levels=c(\"2020\", \"2021\"))\n\n#Plot results\n\nplot <- data_nmds |> \n  ggplot(aes(x = MDS1,\n             y = MDS2,\n             colour = Arrival,\n             shape = Year))+\n  geom_point(size=2)+\n  theme_bw()+\n  scale_colour_viridis(name = \"Plant order of arrival\",\n                       discrete = TRUE,\n                       option = \"D\")+\n  scale_shape_manual(name = \"Year of initiation\",\n                     values = c(16, 17))+\n  theme(axis.text = element_text(colour=\"black\"),\n        axis.title.x = element_text(margin = margin(t=10)),\n        axis.title.y = element_text(margin = margin(r=10)))+\n  xlab(\"NMDS1\")+\n  ylab(\"NMDS2\")+\n  geom_text(data=data.frame(x=min(data_nmds$MDS1),\n                            y=max(data_nmds$MDS2),\n                            label=paste(\"Stress = \", \n                                        round(nmds$stress, 3), \n                                        sep=\"\")), \n            aes(x = x, \n                y = y, \n                label = label),\n            hjust = 0.1, \n            vjust = 0, \n            inherit.aes = FALSE)\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot\n```\n:::\n\n```{r}\n#| eval: true \n#| echo: false \n#| warning: false \n#| message: false  \n\nunlink(\"Data_POEM\", recursive = TRUE) \nfile.remove(\"Data_POEM_Paper1_Alonso-Crespo_et_al_2024-v1.0.zip\")\n```\n","srcMarkdownNoYaml":"\n\n## About this tutorial\n\nWelcome to this tutorial on data analysis in R!\n\nIn this tutorial, **our goal is to review some of the R functions you will need to analyse the data you have collected in the field and answer your research questions**. For this tutorial, we strongly recommend that you reflect on what you have learned in the Statistics GSS course during Period 3. The Statistics GSS course taught you many useful tools for data analysis. Now it's time to put them into practice on a real ecological data set. For this tutorial, you will be using the same POEM data as in the tutorial on data wrangling. If you don't remember what these data are, please refer to the first sections of the first tutorial on data wrangling.\n\nLet's get started!\n\n## Importing POEM data\n\nThe first thing to do after opening RStudio is to import the POEM data. This is exactly the same as what we already did in the first tutorial. [Try writing the code yourself this time]{.underline} (i.e. without looking too quickly at the solution)!\n\n### Download the POEM data from Zenodo\n\nThe POEM data that will be used in this tutorial are available on a [Zenodo repository](https://zenodo.org/records/10119982). You can download the data manually, but you can also do it using an R function called `download_zenodo()`. Let's give it a try.\n\nFirst, install the *inborutils* R package using the following code:\n\n```{r}\n#| eval: false \n#| echo: true \n#| warning: false \n#| message: false \n#| code-fold: false  \n\ninstall.packages(\"inborutils\", \n                 repos = c(inbo = \"https://inbo.r-universe.dev\",\n                           CRAN = \"https://cloud.r-project.org\"))\n```\n\nYou can now download the data used in this tutorial using `download_zenodo()`.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\ninborutils::download_zenodo(doi=\"10.5281/zenodo.10119982\",\n                            quiet=TRUE)\n```\n\nBy default, the data will be downloaded as a zip file and will be stored in your working directory. If you do not know what is your working directory, run `getwd()` in your R console. Let's extract (or unzip) the files we have just downloaded from Zenodo and let's store these files in a new folder called \"Data_POEM\":\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\nunzip(zipfile = \"Data_POEM_Paper1_Alonso-Crespo_et_al_2024-v1.0.zip\",       \n      exdir = \"Data_POEM\")\n```\n\n### Load R packages\n\nMost of the functions we need for the rest of this tutorial are available with base R and in R packages from the *tidyverse* collection. We will also need the `read_excel()` function from the *readxl* package and the `kable()` function from the *knitr* package. We will also need functions from the *vegan*, *car*, *emmeans,* and *viridis* R packages later in this tutorial. If they are not yet installed in your library, install it using `install.packages()`.\n\nYou can load all the packages required for this tutorial using `library()`.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\nlibrary(tidyverse) \nlibrary(readxl) \nlibrary(knitr)\nlibrary(vegan)\nlibrary(car)\nlibrary(emmeans)\nlibrary(viridis)\n```\n\n### Import data into R\n\nIn the POEM project, raw biomass data (measured at the species level) are stored in different folders for the experiment started in 2020 (POEM2020) and the experiment started in 2021 (POEM2021). For each experiment, there is one data file for each growing season. As the data is stored in Excel files (.xlsx), we can use `read_excel()` to import our data into R. For now, we will simply store each set of data in separate R objects.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\n#Import data from the first experiment (POEM2020)  \n\npoem2020_year1 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2020-07.xlsx\")\n\npoem2020_year2 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2021-06.xlsx\")\n\npoem2020_year3 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2022-06.xlsx\")  \n\n#Import data from the second experiment (POEM2021)  \n\npoem2021_year1 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2021-07.xlsx\")  \n\npoem2021_year2 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2022-06.xlsx\")  \n\npoem2021_year3 <- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2023-06.xlsx\")\n```\n\nIn RStudio, you can see how each data frame looks like using `View()`.\n\n```{r}\n#| eval: false \n#| echo: true \n#| warning: false \n#| message: false  \n\nView(poem2021_year1)\n```\n\nYou can see that each dataset consists of a number of observations (rows) of 6 variables (columns). These variables are:\n\n-   **Year**: the year of initiation of each experiment\n-   **Harvest**: the date at which biomass data were collected (YYYY-MM)\n-   **Plot**: the plot identification number (plot number - arrival order/replicate)\n-   **Quadrat**: the quadrat identification number (plant biomass was collected in 2 or 4 quadrats per plot)\n-   **Species**: the plant species name\n-   **SDW_g**: the shoot dry weight in grams\n\nTo enable data exploration and analysis, we now need to combine these different datasets, so that all the data is stored in the same R object. You can do this using `rbind()`.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\npoem_data <- rbind(poem2020_year1,\n                   poem2020_year2,\n                   poem2020_year3,\n                   poem2021_year1,\n                   poem2021_year2,\n                   poem2021_year3)\n```\n\n## Organise POEM data\n\nWrite R code to reorganise the data so that we can analyse them. Make sure to do the following:\n\n-   Create new columns based on the information contained in the Plot column. This can be done easily using `separate_wider_delim()` and `separate_wider_position()`. Make sure to add the following three columns to the dataset:\n\n    -   PlotID (the plot number)\n    -   Arrival (the order of arrival treatment: S, F, G, L, B)\n    -   Replicate (the replicate number)\n\n-   Make sure that PlotID and Replicate are stored as numerical variables. You can do this by combining `mutate()` with `as.numeric()`.\n\n-   Finally, rename the column storing plant biomass values (SDW_g). Name it \"Biomass\". You can do this using `rename()`.\n\n```{r}\n#| eval: true\n#| echo: true\n#| warning: false\n#| message: false\n\npoem_data <- poem_data |> \n  separate_wider_delim(cols = Plot,\n                       delim=\"-\",\n                       names=c(\"PlotID\", \"Treatment\"),\n                       cols_remove=TRUE) |> \n  separate_wider_position(cols = Treatment,\n                          width=c(Arrival=1, Replicate=1),\n                          cols_remove=TRUE) |> \n  mutate(PlotID=as.numeric(PlotID),\n         Replicate=as.numeric(Replicate)) |> \n  rename(Biomass=SDW_g)\n```\n\nLet's take a quick look at the first ten rows of our dataset using `head().` We can also use `kable()` in the *knitr* package to produce a nice looking table in your R console.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\nkable(head(poem_data, n = 10))\n```\n\n## Exercise 1: Do plant order of arrival and year of initiation of an experiment affect the total aboveground biomass production of plant communities?\n\n### Step 1: Calculate the total biomass production in each plot\n\nBefore starting analysing our data, we must first calculate the total biomass production of each plant community at each harvest date. This can be done by summing the biomass value of all species collected in a plot at a given harvest date. Use what you learned in the data wrangling tutorial to write a piece of R code that does that. When writing your code, remember the following:\n\n-   Store the dataset in a new object called `poem_data_biomass`.\n\n-   Do not forget to standardise biomass data in g/m². Each quadrat has a surface area of 0.1 m². Use `mutate()` to add a new column called \"Std_biomass\" to the dataset.\n\n-   Depending on the harvest date, all plant species located within 2 or 4 randomly positioned quadrats were collected in each plot. To obtain a biomass value per species and per plot, it is first necessary to calculate the average biomass value for each species in a plot at each harvest date (i.e., across quadrats). Use `group_by()` and `summarise()` to do that.\n\n-   Once you have calculated the average biomass value for each species in a plot, use `group_by()` and `summarise()` again to calculate the total aboveground biomass in each plot by adding up the yield (in g/m²) of all species in a plot.\n\n-   Only keep the data for the second harvest date of each sub-experiment (2021-06 for the experiment initiated in 2020, 2022-06 for the experiment initiated in 2021).\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n\npoem_data_biomass <- poem_data |> \n  mutate(Std_biomass=Biomass/0.1, #Convert to g/m²\n         .after = \"Biomass\") |>  #Specify that we want this new column to be after the Biomass column\n  group_by(Year, Harvest, PlotID, Arrival, Species) |> #Define grouping factors in your data\n  summarise(Std_biomass=mean(Std_biomass)) |> #Calculates the average productivity of each species in a plot\n  group_by(Year, Harvest, PlotID, Arrival) |> #Redefine groups (interested in summing biomass values across species)\n  summarise(Total_biomass=sum(Std_biomass)) |>  #Calculate total biomass production in each plot\n  filter((Year == 2020 & Harvest == \"2021-06\")|(Year == 2021 & Harvest == \"2022-06\"))\n```\n\nLet's take a quick look at the first ten rows of our new dataset using `head().`\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false  \n\nkable(head(poem_data_biomass, n = 10))\n```\n\n### Step 2: Visualise raw data\n\nBefore fitting a statistical model to our data, let's first create a plot to help us answer our research question: Do plant order of arrival and year of initiation of an experiment affect the total aboveground biomass production of plant communities?\n\nThis research question gives us important information about what needs to be represented. The first half of the question tells us that our graph should present results for all possible combinations of plant arrival order (S, F, G, L, B) and year of initiation (2020 and 2021). These are the fixed factors of the experiment. We can make sure that these columns are correctly interpreted as factors by using `factor()`. It may also be a good idea to reorder factor levels in a meaningful way (S, F, G, L, B). The second half of the research question tells us that we need to show the differences in total aboveground biomass production between all possible treatment combinations. This is the response variable of our experiment.\n\nUsing what you have learned in the previous tutorials, create a high-quality figure that answers the research question. Feel free to personalise your plot in any way you think best communicates the results (you do not necessarily have to produce the same plot as below). What can you already notice from this graph? Does it look like ANOVA (ANalysis Of VAriance)) assumptions are met?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\npoem_data_biomass$Year <- factor(poem_data_biomass$Year)\npoem_data_biomass$Arrival <- factor(poem_data_biomass$Arrival,\n                                    levels=c(\"S\", \"F\", \"G\", \"L\", \"B\"))\n\nplot <- poem_data_biomass |> \n          ggplot(aes(x=Arrival,\n                     y=Total_biomass))+\n          facet_grid(~Year)+\n          geom_jitter(height = 0,\n                      width=0.1,\n                      shape=1)+\n          stat_summary(fun.data = \"mean_cl_boot\")+\n          theme_bw()+\n          xlab(\"Plant order of arrival\")+\n          ylab(\"Total shoot dry weight (g/m²)\")+\n          theme(axis.title.x = element_text(margin = margin(t=10)),\n                axis.title.y = element_text(margin = margin(r=10)),\n                axis.text = element_text(colour=\"black\"))+\n          scale_y_continuous(breaks=seq(from = 100,\n                                        to = 600,\n                                        by = 100))\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot\n```\n:::\n\n### Step 3: Fit a model\n\nLet's fit a statistical model to study the relationship between our response variable of interest (Total_biomass) and our two experimental factors (Year and Arrival). There are different ways to do this in R. First, let's check whether a ***simple linear regression model*** can correctly model our data. We will use the `lm()` function to fit this linear model (this will give us the same results as the `aov()` function). Note that each group being compared has 5 independent observations, which is not sufficient to test the assumption that the data are normally distributed at each combination of factor levels.\n\nThe syntax to fit a simple linear regression model with two predictor variables in R is as follows:\n\n`model <- lm(Response ~ Predictor1*Predictor2, data)`\n\nThe asterisks (\\*) means that we want to take the interaction between predictor variables into account (you then assume that Predictor1 and Predictor2 have non-additive effects on your response variable). Using a plus sign (+) instead of an asterisks would fit a model without considering an interaction between predictors (in that case, you then assume that Predictor1 and Predictor2 have additive effects on your response variable).\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\n#Fit simple linear regression model\n\nmodel1 <- lm(Total_biomass ~ Year*Arrival,\n             data = poem_data_biomass)\n```\n\nBefore checking model results, let's first make sure that model assumptions are met. We can check for homoscedasticity by plotting model residuals (i.e., the difference between model predictions and observations) against fitted values (i.e., model predictions). This is called a residual plot. Fitted values can be calculated using `predict()`. Residuals can be calculated using `residuals()`. Try to create such a plot using what you have learned in previous tutorials. Do you notice any pattern in this residual plot?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot <- data.frame(predicted = predict(model1),\n           residuals = residuals(model1)) |> \n        ggplot(aes(x=predicted,\n                 y=residuals))+\n        geom_point()+\n        geom_hline(yintercept = 0,\n                   colour = \"red\",\n                   linetype = 2)+\n        theme_bw()+\n        xlab(\"Predicted values\")+\n        ylab(\"Residuals\")+\n        theme(axis.title.x = element_text(margin = margin(t=10)),\n              axis.title.y = element_text(margin = margin(r=10)),\n              axis.text = element_text(colour=\"black\"))\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot\n```\n:::\n\nIt seems that there is a strong mean - variance relationship in our data (heteroscedasticity), which means that the model we just fitted is not the best option. A better approach is to switch to a ***generalised linear model*** (also referred to as GLM). Generalised linear models can be fitted using the `glm()` function in the *stats* package. The syntax is exactly the same as for the `lm()` function, but there is an extra argument to specify: `family`. The `family` argument allows you to describe the error distribution and the link function to be used in the model.\n\n::: callout-note\n## Relationship between `lm()` and `glm()`\n\nA simple linear regression model (`lm()`) is a special case of a gaussian generalised linear model with an identity link. This means that\n\n`lm(Response ~ Predictor1*Predictor2, data)`\n\nand\n\n`glm(Response ~ Predictor1*Predictor2, data, family=gaussian(link=\"identity\")`\n\nproduce the same results.\n:::\n\nInstead of using a gaussian distribution, a gamma distribution can be used for a response variable that is continuous and strictly positive. Negative values and zeros are not allowed with a gamma distribution. This distribution is useful to model variables such as biomass, length, etc. Using a log link function will also help deal with heteroscedasticity. This can be done by writing `family=Gamma(link=\"log\")` in `glm()`.\n\nLet's fit a new model (this time a GLM) to our data.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\n#Fit simple linear regression model\n\nmodel2 <- glm(Total_biomass ~ Year*Arrival,\n              data = poem_data_biomass,\n              family = Gamma(link=\"log\"))\n```\n\nBefore checking model results, let's first create a residual plot. What do you notice? What's new in this residual plot?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot <- data.frame(predicted = predict(model2),\n           residuals = residuals(model2)) |> \n        ggplot(aes(x=predicted,\n                 y=residuals))+\n        geom_point()+\n        geom_hline(yintercept = 0,\n                   colour = \"red\",\n                   linetype = 2)+\n        theme_bw()+\n        xlab(\"Predicted values\")+\n        ylab(\"Pearson residuals\")+\n        theme(axis.title.x = element_text(margin = margin(t=10)),\n              axis.title.y = element_text(margin = margin(r=10)),\n              axis.text = element_text(colour=\"black\"))\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot\n```\n:::\n\nLet's now take a look at model outputs. You can do this using `summary()`. This output contains a wealth of useful information. The coefficient table gives you the coefficients of the model. When looking at the results of the statistical tests, it seems that only three to four coefficients in the equation above can be considered significantly different from zero (marked with a dot or an asterisks).\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\noutput <- summary(model2)\n```\n\n## Solution (output)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n\noutput\n```\n:::\n\nGLM models do not return any R² values (like for simple linear regression models). The closest we can get is to calculate the explained deviance:\n\n$$\nExplainedDeviance = 100 \\times \\frac{NullDeviance - ResidualDeviance}{NullDeviance}\n$$\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\nnull_deviance <- summary(model2)$null.deviance\nresidual_deviance <- summary(model2)$deviance\n\nexplained_deviance <- 100*(null_deviance-residual_deviance)/null_deviance\n```\n\nThe explanatory variables included in the model explain `r round(explained_deviance, 1)`% of the variation in total plant biomass production.\n\n### Step 4: Compare group means\n\nYou can use the `Anova()` function in the *car* package to produce an ANOVA table (in this case, an analysis of deviance table). This table shows that the two factors of our experiment interact with each other. This means that the effect of plant order of arrival on community biomass depends on the year of initiation of an experiment.\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\ntable <- Anova(model2)\n```\n\n## Solution (table)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\ntable\n```\n:::\n\nTo determine where the differences in community productivity lie between the plant arrival order scenarios for each sub-experiment, we need to perform a posthoc test. The `emmeans()` function in the *emmeans* R package is a good option for this. For the `emmeans()` function, we will need to specify a value for the following arguments:\n\n-   `object` (the object containing the fitted model)\n-   `specs` (a character vector specifying the names of the predictors for which levels must be compared). In this example, this is plant arrival order.\n-   `by` (a character vector specifying the names of the predictors to condition on). In this example, this is the year of initiation of an experiment.\n-   `contr` (a character value specifying the contrasts to be added). We will use pairwise contrasts (i.e., all possible pairs of groups will be compared).\n\nTo check the results of the posthoc test, we will then call a `summary()` function on the object produced by `emmeans()` . In `summary()`, we will use the `type` argument to specify that we want model predictions to be on the same scale as the original data (not log scale, but original scale in g/m²).\n\nWhat can you conclude from this posthoc test?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\ntable <- summary(emmeans(object = model2, \n                         specs = \"Arrival\", \n                         by= \"Year\",\n                         contr = \"pairwise\"), \n         type=\"response\")\n```\n\n## Solution (table)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\ntable\n```\n:::\n\nFor the sub-experiment set up in 2020, all plots where seeds were added (S, F, G, L) were on average more productive than free succession plots. Consequently, the observed effect on community productivity does not appear to be due to the manipulation of plant arrival order, but solely to whether or not seeds were sown in the plots at the start of the experiment. In 2021, there is no evidence of any difference in aboveground biomass production between plant arrival order scenarios.\n\n### Step 5: Add posthoc test results to the graph\n\nWe can add posthoc test results to a graph by adding annotations. This is often done by adding letters next to the groups being compared. Groups that do not share a common letter are considered statistically significantly different from each other (p \\< 0.05). We can easily add these letters to our graph in two steps:\n\n-   Start by creating a data frame (called `annotations` in the code below) that contains all the information that *ggplot2* needs to add the annotations to your graph. In our example, this data frame should have as many rows as annotations to add to the graph and must contain the following columns:\n\n    -   **Year**: the year of initiation of an experiment (2020 or 2021). Use the same column name as in `poem_data_biomass`.\n    -   **Arrival**: the plant order of arrival (S, F, G, L, B). Use the same column name as in `poem_data_biomass`.\n    -   **y**: the vertical coordinates where annotations should be added. You can freely choose the name of this column.\n    -   **Label**: the annotations to be added to the graph. You can freely choose the name of this column.\n\n-   Once this is done, add an extra layer to your ggplot object using `geom_text()`.\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n#| fig-align: center\n\nannotations <- data.frame(Year=rep(c(2020,2021), each=5),\n                          Arrival=rep(c(\"S\", \"F\", \"G\", \"L\", \"B\"), 2),\n                          y=rep(600, 10),\n                          Label=c(\"a\", \"a\", \"a\", \"a\", \"b\", \"a\", \"a\", \"a\", \"a\", \"a\"))\n\nplot <- poem_data_biomass |> \n          ggplot(aes(x=Arrival,\n                     y=Total_biomass))+\n          facet_grid(~Year)+\n          geom_jitter(height = 0,\n                      width=0.1,\n                      shape=1)+\n          stat_summary(fun.data = \"mean_cl_boot\")+\n          theme_bw()+\n          xlab(\"Plant order of arrival\")+\n          ylab(\"Total shoot dry weight (g/m²)\")+\n          theme(axis.title.x = element_text(margin = margin(t=10)),\n                axis.title.y = element_text(margin = margin(r=10)),\n                axis.text = element_text(colour=\"black\"))+\n          scale_y_continuous(breaks=seq(from = 100,\n                                        to = 600,\n                                        by = 100))+\n          geom_text(data=annotations,\n                    aes(x=Arrival,\n                        y=y,\n                        label=Label))\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n#| fig-align: center\n\nplot\n```\n:::\n\n## Exercise 2: Non-metric multidimensional scaling\n\n### Step 1: Choose a measure of association\n\n**Non-metric multidimensional scaling** (NMDS) is a technique often used in ecological research to visualise differences (or (dis)similarities) in species composition between ecological communities.\n\nThe first step is to choose a measure of association and calculate a dissimilarity matrix. This dissimilarity matrix will have as many rows and columns as ecological communities to be compared. The help page of the `vegdist()` function of the *vegan* package lists a number of dissimilarity indices for ecologists wishing to quantify dissimilarity in species composition between communities. You can access this help page by running `?vegdist` in your R console (a detailed discussion of the advantages and disadvantages of each dissimilarity index is beyond the scope of this tutorial). The Bray-Curtis dissimilarity is usually good at detecting ecological gradients (see `?vegdist`) and is often used as default when performing NMDS. This is the dissimilarity index we are going to use in this tutorial too.\n\n### Step 2: Organise your data\n\nTo obtain the dissimilarity matrix required for NMDS, we first need to reorganise our data so that each species has its own column and each ecological community has its own row (i.e., a site-by-species matrix). Use the `poem_data` object as a starting point. In your code, include the following steps:\n\n-   Store the dataset in a new object called `poem_data_wide`.\n-   Standardise biomass data in g/m². Each quadrat has a surface area of 0.1 m². Use `mutate()` to add a new column called \"Std_biomass\" to the dataset.\n-   Depending on the harvest date, all plant species located within 2 or 4 randomly positioned quadrats were collected in each plot. To obtain a biomass value per species and per plot, it is first necessary to calculate the average biomass value for each species in a plot at each harvest date (i.e., across quadrats). Use `group_by()` and `summarise()` to do that.\n-   Use `pivot_wider()` to reorganise your data (one column per species).\n-   Only keep the data for the second harvest date of each sub-experiment (2021-06 for the experiment initiated in 2020, 2022-06 for the experiment initiated in 2021).\n-   Remove all species columns that only contain zeros. You can do this using `select(where( ~ is.numeric(.x) && sum(.x) != 0))`.\n-   Remove the column named \"Unknown\".\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\npoem_data_wide <- poem_data |> \n  mutate(Std_biomass=Biomass/0.1, #Convert to g/m²\n         .after = \"Biomass\") |>  #Specify that we want this new column to be after the Biomass column\n  group_by(Year, Harvest, PlotID, Arrival, Species) |> #Define grouping factors in your data\n  summarise(Std_biomass=mean(Std_biomass)) |> \n  pivot_wider(names_from = Species, #Species names will be used as column names\n              values_from = Std_biomass, #Biomass values are stored in the Std_biomass column\n              values_fill = 0, #If a species is absent in a plot, its biomass value is zero\n              values_fn = sum) |>  #Sum biomass values measured on the same species and in the same quadrat\n  filter((Year == 2020 & Harvest == \"2021-06\")|(Year == 2021 & Harvest == \"2022-06\")) |>  #Filter data\n  select(where( ~ is.numeric(.x) && sum(.x) != 0)) |> \n  select(-Unknown)\n\nkable(head(poem_data_wide, 10))\n```\n\n### Step 3: Perform the NMDS\n\nNow that our community dataset has the right format, we can perform the NMDS using the `metaMDS()` function of the *vegan* package. The following arguments are of particular importance:\n\n-   `comm`: the community data (only select the species columns).\n-   `distance`: a character value for the dissimilarity index used. Use \"bray\" for the Bray-Curtis dissimilarity index.\n-   `k`: the number of dimensions to compute. Let's start with `k=2` (we want to produce a 2D plot).\n-   `trymax`: the maximum number of random starts in search of a stable solution. The NMDS algorithm iteratively searches for a stable solution (numerical optimisation methods). Increasing the value of this argument can help reaching a stable solution.\n\nWe will keep the default values for all other arguments. Store the results in an object named `nmds`. Do not forget to set a seed (using `set.seed()` for reproducibility).\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false \n\nset.seed(123)\n\nnmds <- metaMDS(comm = poem_data_wide[,5:ncol(poem_data_wide)],\n                distance = \"bray\",\n                k = 2,\n                trymax = 100)\n```\n\n### Step 4: Check NMDS results\n\nThe main goal of NMDS is to visualise a dissimilarity matrix in a lower (typically 2D) dimensional space. Contrary to principal coordinate analysis (PCoA), which aims to create a plot in which distances between points match the original dissimilarities as closely as possible, NMDS focuses on representing the order, or ranking, of the original dissimilarities as closely as possible (Zuur AF, Ieno EN, Smith GM. 2007. *Analysing ecological data*. Springer.).\n\nThe first way to assess the quality of the display is to look at a parameter called \"stress\". You can extract it from the `nmds` object created earlier using `nmds$stress`. In our example, the stress value is equal to `r round(nmds$stress, 3)`. Zuur et al (2007) provided some guidelines on how to interpret stress values (usually, the lower the stress value, the better):\n\n-   stress \\< 0.05: Excellent configuration\n-   stress between 0.05 and 0.1: Good configuration\n-   stress between 0.1 and 0.2: Be careful with interpretation\n-   stress between 0.2 and 0.3: Problems start. Consider increasing the number of dimensions (`k`).\n-   stress above 0.3: Poor representation. Increase the number of dimensions (`k`).\n\nAnother way to assess the quality of the configuration is to create a Shepard plot. A Shepard plot shows the relationship between ordination distances (i.e., distances in the configuration produced by the NMDS) and original distances. You can produce a Shepard plot using the `stressplot()` function in *vegan*. What can you conclude from this Shepard plot?\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nstressplot(nmds)\n```\n\n### Step 5: Visualise NMDS results\n\nNMDS results are stored in our `nmds` object. You can extract the coordinates of each community using `nmds$points`. To make it easier to work with *ggplot2*, we will create a new data frame (`data_nmds`) by merging the first four columns of `poem_data_wide` (Harvest, Arrival, Year, PlotID) with NMDS results.\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n\ndata_nmds <- cbind(poem_data_wide[, 1:4], nmds$points)\n\nkable(head(data_nmds, 10))\n```\n\nWe now have everything we need to plot the results of the NMDS using *ggplot2*:\n\n-   Create a plot displaying MDS1 on the horizontal axis and MDS2 on the vertical axis.\n-   Use a specific colour for each plant order of arrival scenario (mind colour-blind people!).\n-   Use a specific shape for each year of initiation.\n-   Add an informative legend to your graph.\n-   Add an annotation on the top left corner of your graph for the stress value. Use `geom_text()` to do that.\n\nWhat can you conclude from this NMDS?\n\n::: panel-tabset\n## Solution (code)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n\n#Make sure that Arrival and Year are factors\n\ndata_nmds$Arrival <- factor(data_nmds$Arrival,\n                            levels=c(\"S\", \"F\", \"G\", \"L\", \"B\"))\n\ndata_nmds$Year <- factor(data_nmds$Year,\n                         levels=c(\"2020\", \"2021\"))\n\n#Plot results\n\nplot <- data_nmds |> \n  ggplot(aes(x = MDS1,\n             y = MDS2,\n             colour = Arrival,\n             shape = Year))+\n  geom_point(size=2)+\n  theme_bw()+\n  scale_colour_viridis(name = \"Plant order of arrival\",\n                       discrete = TRUE,\n                       option = \"D\")+\n  scale_shape_manual(name = \"Year of initiation\",\n                     values = c(16, 17))+\n  theme(axis.text = element_text(colour=\"black\"),\n        axis.title.x = element_text(margin = margin(t=10)),\n        axis.title.y = element_text(margin = margin(r=10)))+\n  xlab(\"NMDS1\")+\n  ylab(\"NMDS2\")+\n  geom_text(data=data.frame(x=min(data_nmds$MDS1),\n                            y=max(data_nmds$MDS2),\n                            label=paste(\"Stress = \", \n                                        round(nmds$stress, 3), \n                                        sep=\"\")), \n            aes(x = x, \n                y = y, \n                label = label),\n            hjust = 0.1, \n            vjust = 0, \n            inherit.aes = FALSE)\n```\n\n## Solution (plot)\n\n```{r}\n#| eval: true \n#| echo: true \n#| warning: false \n#| message: false\n#| fig-align: center\n\nplot\n```\n:::\n\n```{r}\n#| eval: true \n#| echo: false \n#| warning: false \n#| message: false  \n\nunlink(\"Data_POEM\", recursive = TRUE) \nfile.remove(\"Data_POEM_Paper1_Alonso-Crespo_et_al_2024-v1.0.zip\")\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"svg","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"toc-depth":5,"output-file":"data_analysis.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","editor":"visual","editor_options":{"chunk_output_type":"console"},"theme":{"light":["cosmo","theme-light.scss"],"dark":["cosmo","theme-dark.scss"]},"code-copy":true,"code-summary":"Show me the R code","fig-cap-location":"bottom","title":"Tutorial 5: Data analysis in R","author":[{"name":"Benjamin Delory","orcid":"0000-0002-1190-8060","email":"b.m.m.delory@uu.nl","affiliations":[{"name":"Environmental sciences group, Copernicus institute of sustainable development, Utrecht University"}]}]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}