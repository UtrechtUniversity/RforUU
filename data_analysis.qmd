---
title: "Tutorial 5: Data analysis in R"
author:
  - name: Benjamin Delory
    orcid: 0000-0002-1190-8060
    email: b.m.m.delory@uu.nl
    affiliations:
      - name: Environmental sciences group, Copernicus institute of sustainable development, Utrecht University
---

## About this tutorial

Welcome to this tutorial on data analysis in R!

In this tutorial, **our goal is to review some of the R functions you will need to analyse the data you have collected in the field and answer your research questions**. For this tutorial, we strongly recommend that you reflect on what you have learned in the Statistics GSS course during Period 3. The Statistics GSS course taught you many useful tools for data analysis. Now it's time to put them into practice on a real ecological data set. For this tutorial, you will be using the same vegetation data as in the tutorial on data wrangling. If you don't remember what these data are, please refer to the first sections of the first tutorial on data wrangling.

The focus of this tutorial will be on answering the following research questions:

-   In the first exercise, we will test if different habitat types around Utrecht (grassland, forest, heathland, peatland) harbor different levels of plant species diversity.

-   In the second exercise, we will visualize the differences in plant species composition between the different habitats.

Let's get started!

## Load R packages

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false  

library(tidyverse) 
library(knitr)
library(vegan)
library(car)
library(emmeans)
library(viridis)
```

## Importing vegetation data

You can download the data manually (either from Brightspace or from GitHub), but you can also import the data directly from Github using an R function called `read_csv()`. Let's give it a try.

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false

#URL to access the data

url <- "https://raw.github.com/BenjaminDelory/GEO2-2439/master/Data/data_vegetation.csv"

#Import data in R

data <- readr::read_csv(url)
```

You can see that the dataset consists of a number of observations (rows) of 7 variables (columns). These variables are:

-   **Date**: the sampling date (YYYY-MM-DD)
-   **Student**: the student ID number
-   **Site**: the site name (4 levels: A_grassland, B_forest, C_heathland, D_peatland)
-   **Location**: the location within a site (2 levels: 1 or 2)
-   **Plot**: the plot ID number (in each site, plots were labelled from 1 to 20)
-   **Species**: the plant species name (or species group name)
-   **Cover**: the percent cover (numeric value between 0 and 100)

## Organise vegetation data

Before carrying out any statistical analysis, we first need to get to know our data. The best way to do this is to represent them graphically. That's precisely what we are going to do next, but first we need to organize our data in such a way that we can represent plant species diversity (calculated using Hill numbers, see the tutorial on quantifying biodiversity) in different habitat types.

For the moment, the data set consists of numerous individual observations made by different students at different sites on four different dates... This is a lot of information, and we first need to summarize it by calculating the average cover of each plant species in a plot (i.e. across all students and all observation dates).

::: callout-note
Note that it would also have been possible to plot the results separately for each observation date, but for simplicity's sake we won't dwell on this temporal aspect in this tutorial.
:::

The first step is to write R code to do the following:

-   Create a new object called `data_plot` in which the reorganized data will be stored.

-   Remove all observations related to "Deadwood", "Bare_ground" or "Litter" (you can do this using `filter()`).

-   Group data by Site, Plot, and Species (you can do this using `group_by()`). We will deliberately ignore the `Location` variable in this tutorial (despite the fact that there may be small differences in species composition and diversity between locations).

-   Calculate an average cover value for each unique combination of Site, Location, Plot, and Species (you can do this using `summarize()`).

-   Convert Site as a factor (you can do this using `mutate()`).

-   When this is done, use `pivot_wider()` to create as many new columns as there are species in the data. These columns should contain the average cover value for each species measured in all plots. Make sure that, if a species is not present in a plot, the percent cover of that species is zero in that plot.

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false

data_plot <- data |> 
  filter(Species != "Deadwood") |> 
  filter(Species != "Bare_ground") |>
  filter(Species != "Litter") |>
  group_by(Site, Plot, Species) |>
  summarise(Avg_cover = mean(Cover)) |> 
  mutate(Site = as.factor(Site)) |> 
  pivot_wider(names_from = Species,
              values_from = Avg_cover,
              values_fill = 0)

kable(head(data_plot, 10))
```

The result is a data set comprising 80 rows (one row per plot) and 132 variables (including 130 species).

We are ready to go!

## Exercise 1: Does plant species diversity change with habitat type?

### Step 1: Calculate Hill numbers

Since we are interested in modelling the relationship between plant species diversity and habitat type, we first need to quantify plant species diversity in all plots. We will do this using Hill numbers (see tutorial on quantifying taxonomic diversity if you need to refresh your memory). To do this, we first need to calculate the [*relative*]{.underline} abundance of all species in all plots. The simplest way to do this is to create a new column called `Total` in the dataset by summing the percent cover value of all species present in each plot, and then use this information to express all species data in relative form.

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false

#Create a new column called "Total"

data_plot <- data_plot |> 
  mutate(Total = sum(c_across(Acer_pseudoplatanus:Myrica_gale)))
```

We can now reorganize the data into a more tidy format using the `pivot_longer()` function. What we want is a data set whose structure is similar to that of our original data, but with an extra column (`Total`). Since we have added several observations with zero values (which happens when a species is not present in a plot), we will end up with a dataset with many more rows than in our original data. But this does not matter, as we can easily filter out these values using `filter()`.

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false

#Reorganise data (tidy format) and filter out zero values

data_plot <- data_plot |> 
  pivot_longer(cols = Acer_pseudoplatanus:Myrica_gale,
               names_to = "Species",
               values_to = "Abundance") |> 
  filter(Abundance > 0)
```

The next step is to calculate the relative abundance of each species in all plots by dividing `Abundance` by `Total`. We will store these relative abundance values in a new column: `Rel_abundance`.

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false

#Calculate species relative abundance

data_plot <- data_plot |> 
  mutate(Rel_abundance = Abundance/Total)
```

We are now ready to calculate Hill numbers. We will do this for three values of *q* (0, 1, and 2). We can easily do this using `group_by()` and `summarise()`. Let's store this data set into a new R object called `data_hill`.

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false

#Calculate Hill numbers at q=0, q=1, and q=2

data_hill <- data_plot |> 
  group_by(Site, Plot) |> 
  summarise(q0=sum(Rel_abundance^0)^(1/(1-0)),
            q1=exp(-sum(Rel_abundance*log(Rel_abundance))),
            q2=sum(Rel_abundance^2)^(1/(1-2)))
```

This new dataset consists of 80 rows (one row per plot) and 5 variables:

-   **Site**: the site name (4 levels: A_grassland, B_forest, C_heathland, D_peatland)

-   **Plot**: the plot ID number (in each site, plots were labelled from 1 to 20)

-   **q0**: the effective number of species at q=0 (species richness)

-   **q1**: the effective number of species at q=1 (Hill-Shannon)

-   **q2**: the effective number of species at q=2 (Hill-Simpson)

To make it easier to plot the data for multiple values of *q*, let's reorganise the dataset to have all values of *q* stored in a single column. We will store this new data set in a new R object called `data_hill_long`.

Use `pivot_longer()` to reorganise the dataset and create a column called `q` to store all diversity order values (0, 1, and 2) and a column called `diversity` to store the effective number of species in each community. In `pivot_longer()`, you will need to use two extra arguments: `names_prefix = "q"` (this will make sure to remove the letter "q" from "q0", "q1", and "q2") and `names_transform = as.numeric` (to convert "0", "1" and "2" into numeric values).

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false

#Reorganise data ina tidy format

data_hill_long <- data_hill |> 
  pivot_longer(q0:q2,
               names_to = "q",
               names_prefix = "q",
               names_transform = as.numeric,
               values_to = "diversity")

kable(head(data_hill_long, 10))
```

### Step 2: Plot the data

Before fitting a statistical model to our data, let's first create a plot to help us answer our research question: Does plant species diversity change with habitat type?

This research question gives us important information about what needs to be represented. The question tells us that our graph should present data on plant species diversity (`diversity`) as a function of habitat type (`Site`). As we have calculated plant diversity for three diversity orders (q=0, q=1 and q=2), it makes sense to create a panel for each value of *q*.

Let's create our plot!

Using what you have learned in the previous tutorials, create a high-quality figure that answers the research question. Feel free to personalize your plot in any way you think best communicates the results (you do not necessarily have to produce the same plot as below).

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false
#| fig-align: center
#| fig-dpi: 1000
#| fig-height: 3.4

#Add "q=" in front of diversity order values

data_hill_long$q <- paste("q=", data_hill_long$q, sep = "")

#Plot the data

ggplot(data_hill_long,
       aes(x = Site,
           y = diversity))+
  geom_jitter(shape = 1,
              alpha = 0.3,
              height = 0,
              width = 0.2)+
  stat_summary(fun.data = "mean_cl_boot")+
  theme_bw()+
  xlab("")+
  ylab("Effective number of species")+
  facet_wrap(~q, ncol=3)+
  theme(axis.text.x = element_text(angle=90, 
                                   vjust = 0.5,
                                   hjust = 1))+
  scale_colour_viridis(discrete = TRUE)
```

What can you already notice from this graph?

Does it look like ANOVA (ANalysis Of VAriance) assumptions are met?

### Step 3: Fit a model

Let's fit a statistical model to study the relationship between our response variable of interest (Plant species diversity at different values of *q*) and our two experimental factors (Site and Location). There are different ways to do this in R. First, let's check whether a ***simple linear regression model*** can correctly model our data. We will use the `lm()` function to fit this linear model (this will give us the same results as the `aov()` function). Note that each group being compared has 10 independent observations, which is not sufficient to test the assumption that the data are normally distributed at each combination of factor levels.

The syntax to fit a simple linear regression model with two predictor variables in R is as follows:

`model <- lm(Response ~ Predictor1*Predictor2, data)`

The asterisks (`*`) means that we want to take the interaction between predictor variables into account (you then assume that Predictor1 and Predictor2 have non-additive effects on your response variable). Using a plus sign (`+`) instead of an asterisks would fit a model without considering an interaction between predictors (in that case, you then assume that Predictor1 and Predictor2 have additive effects on your response variable).

Let's fit a linear model to plant diversity data at q=0 (i.e., species richness) using Site as an explanatory variable.

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

#Fit simple linear regression model
#Only consider q=0 for now

model1 <- lm(q0 ~ Site,
             data = data_hill)
```

Before checking model results, let's first make sure that model assumptions are met. We can check for homoscedasticity by plotting model residuals (i.e., the difference between model predictions and observations) against fitted values (i.e., model predictions). This is called a residual plot. Fitted values can be calculated using `predict()`. Residuals can be calculated using `residuals()`. Try to create such a plot using what you have learned in previous tutorials. Do you notice any pattern in this residual plot?

::: panel-tabset
## Solution (code)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false
#| fig-align: center

plot <- data.frame(predicted = predict(model1),
                   residuals = residuals(model1)) |> 
        ggplot(aes(x=predicted,
                 y=residuals))+
        geom_point()+
        geom_hline(yintercept = 0,
                   colour = "red",
                   linetype = 2)+
        theme_bw()+
        xlab("Predicted values")+
        ylab("Residuals")+
        theme(axis.title.x = element_text(margin = margin(t=10)),
              axis.title.y = element_text(margin = margin(r=10)),
              axis.text = element_text(colour="black"))
```

## Solution (plot)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false
#| fig-align: center

plot
```
:::

It seems that there is a strong mean - variance relationship in our data (heteroscedasticity), which means that the model we just fitted is not the best option. A better approach is to switch to a ***generalised linear model*** (also referred to as GLM). Generalised linear models can be fitted using the `glm()` function in the *stats* package. The syntax is exactly the same as for the `lm()` function, but there is an extra argument to specify: `family`. The `family` argument allows you to describe the error distribution and the link function to be used in the model.

::: callout-note
## Relationship between `lm()` and `glm()`

A simple linear regression model (`lm()`) is a special case of a gaussian generalised linear model with an identity link. This means that

`lm(Response ~ Predictor1*Predictor2, data)`

and

`glm(Response ~ Predictor1*Predictor2, data, family=gaussian(link="identity")`

produce the same results.
:::

In the context of this course, two types of distribution are of interest to us:

-   The **Poisson distribution** **to model [count]{.underline} data** (e.g., plant diversity at q=0). A Poisson distribution is characterized by the fact that its mean and variance are equal. In reality, cases of overdispersion (where the variance is greater than the mean) are frequent in ecological data. One way of solving this problem is to use a **quasi-Poisson distribution**, which corrects for overdispersion by estimating an overdispersion parameter (it assumes that the variance is a linear function of the mean). Using a log link function will also help deal with heteroscedasticity. This can be done by writing `family=quasipoisson(link="log")` in `glm()`.

-   The **Gamma distribution** **to model [continuous and strictly positive]{.underline} data** (e.g., plant diversity at q=1 and q=2). Negative values and zeros are not allowed with a gamma distribution. This distribution is useful to model variables such as biomass, length, etc. Using a log link function will also help deal with heteroscedasticity. This can be done by writing `family=Gamma(link="log")` in `glm()`.

Let's fit a new model (this time a GLM) to our species richness data (q=0).

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

#Fit a generalised linear model with a quasipoisson distribution

model2 <- glm(q0 ~ Site,
              data = data_hill,
              family = quasipoisson(link="log"))
```

Before checking model results, let's first create a residual plot. What do you notice? What's new in this residual plot?

::: panel-tabset
## Solution (code)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false
#| fig-align: center

plot <- data.frame(predicted = predict(model2),
                   residuals = residuals(model2)) |> 
        ggplot(aes(x=predicted,
                 y=residuals))+
        geom_point()+
        geom_hline(yintercept = 0,
                   colour = "red",
                   linetype = 2)+
        theme_bw()+
        xlab("Predicted values")+
        ylab("Pearson residuals")+
        theme(axis.title.x = element_text(margin = margin(t=10)),
              axis.title.y = element_text(margin = margin(r=10)),
              axis.text = element_text(colour="black"))
```

## Solution (plot)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false
#| fig-align: center

plot
```
:::

Let's now take a look at model outputs. You can do this using `summary()`. This output contains a wealth of useful information. The coefficient table gives you the coefficients of the model. When looking at the results of the statistical tests, it seems that most of the coefficients in the equation above can be considered significantly different from zero (marked with a dot or an asterisks).

::: panel-tabset
## Solution (code)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

output <- summary(model2)
```

## Solution (output)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false

output
```
:::

GLM models do not return any R² values (like for simple linear regression models). The closest we can get is to calculate the explained deviance:

$$
ExplainedDeviance = 100 \times \frac{NullDeviance - ResidualDeviance}{NullDeviance}
$$

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

null_deviance <- summary(model2)$null.deviance
residual_deviance <- summary(model2)$deviance

explained_deviance <- 100*(null_deviance-residual_deviance)/null_deviance
```

The explanatory variables included in the model explain `r round(explained_deviance, 1)`% of the variation in plant species richness (q=0).

### Step 4: Compare group means

You can use the `Anova()` function in the *car* package to produce an ANOVA table (in this case, an analysis of deviance table). This table shows that plant species richness strongly differs between sites.

::: panel-tabset
## Solution (code)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

table <- Anova(model2)
```

## Solution (table)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

table
```
:::

To determine where the differences in plant species richness lie between the four different sites, we need to perform a posthoc test. The `emmeans()` function in the *emmeans* R package is a good option for this. For the `emmeans()` function, we will need to specify a value for the following arguments:

-   `object` (the object containing the fitted model)
-   `specs` (a character vector specifying the names of the predictors for which levels must be compared). In this example, this is `Site`.
-   `by` (a character vector specifying the names of the predictors to condition on). We will not need this argument in this case because our model has only one explanatory variable, but this argument is particularly useful if the model includes an interaction term between two explanatory variables.
-   `contr` (a character value specifying the contrasts to be added). We will use pairwise contrasts (i.e., all possible pairs of groups will be compared).

To check the results of the posthoc test, we will then call a `summary()` function on the object produced by `emmeans()` . In `summary()`, we will use the `type` argument to specify that we want model predictions to be on the same scale as the original data (not log scale, but original scale).

::: panel-tabset
## Solution (code)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

table <- summary(emmeans(object = model2, 
                         specs = "Site", 
                         contr = "pairwise"), 
         type="response")
```

## Solution (table)

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

table
```
:::

What can you conclude from this posthoc test?

::: callout-important
## Challenge to do at home

You can repeat all steps 3 and 4 for plant species diversity at q=1 and q=2. The only difference will be that you will need to use a different distribution family to model the data (since the diversity values at q=1 and q=2 are continuous and strictly positive). A Gamma distribution should do the trick.

Give it a try!
:::

```{r}
#| eval: true 
#| echo: false 
#| warning: false 
#| message: false 

model3 <- glm(q1 ~ Site,
              data = data_hill,
              family = Gamma(link="log"))

model4 <- glm(q2 ~ Site,
              data = data_hill,
              family = Gamma(link="log"))

table3 <- summary(emmeans(object = model3, 
                         specs = "Site", 
                         contr = "pairwise"), 
          type="response")

table4 <- summary(emmeans(object = model4, 
                         specs = "Site", 
                         contr = "pairwise"), 
          type="response")
```

### Step 5: Add posthoc test results to the graph

We can add posthoc test results to a graph by adding annotations. This is often done by adding letters next to the groups being compared. Groups that do not share a common letter are considered statistically significantly different from each other (p \< 0.05). We can easily add these letters to our graph in two steps:

-   Start by creating a data frame (called `annotations` in the code below) that contains all the information that *ggplot2* needs to add the annotations to your graph. In our example, this data frame should have as many rows as annotations to add to the graph and must contain the following columns:

    -   **Site**: the site name (4 levels: A_grassland, B_forest, C_heathland, D_peatland). Use the same column name as in `data_hill_long`.
    -   **q**: the diversity order. Use the same column name as in `data_hill_long`.
    -   **y**: the vertical coordinates where annotations should be added. You can freely choose the name of this column.
    -   **Label**: the annotations to be added to the graph. You can freely choose the name of this column.

-   Once this is done, add an extra layer to your ggplot object using `geom_text()`.

```{r}
#| eval: true
#| echo: true
#| warning: false
#| message: false
#| fig-align: center
#| fig-dpi: 1000
#| fig-height: 3.4

#Create table with annotations

annotations <- data.frame(Site=rep(unique(data_hill_long$Site), 3),
                          q=rep(unique(data_hill_long$q), each=4),
                          y=c(rep(50, 4),
                              rep(30, 4),
                              rep(23, 4)),
                          Label=c("a", "b", "b", "a",
                                  "a", "b", "b", "a",
                                  "a", "b", "b", "a"))

#Plot the data

ggplot(data_hill_long,
       aes(x = Site,
           y = diversity))+
  geom_jitter(shape = 1,
              alpha = 0.3,
              height = 0,
              width = 0.2)+
  stat_summary(fun.data = "mean_cl_boot")+
  theme_bw()+
  xlab("")+
  ylab("Effective number of species")+
  facet_wrap(~q, ncol=3)+
  theme(axis.text.x = element_text(angle=90, 
                                   vjust = 0.5,
                                   hjust = 1))+
  scale_colour_viridis(discrete = TRUE)+
  geom_text(data=annotations,
            aes(y=y,
                x=Site,
                label=Label))
```

## Exercise 2: Non-metric multidimensional scaling

### Step 1: Choose a measure of association

**Non-metric multidimensional scaling** (NMDS) is a technique often used in ecological research to visualise differences (or (dis)similarities) in species composition between ecological communities.

The first step is to choose a measure of association and calculate a dissimilarity matrix. This dissimilarity matrix will have as many rows and columns as ecological communities to be compared. The help page of the `vegdist()` function of the *vegan* package lists a number of dissimilarity indices for ecologists wishing to quantify dissimilarity in species composition between communities. You can access this help page by running `?vegdist` in your R console (a detailed discussion of the advantages and disadvantages of each dissimilarity index is beyond the scope of this tutorial). The Bray-Curtis dissimilarity is usually good at detecting ecological gradients (see `?vegdist`) and is often used as default when performing NMDS. This is the dissimilarity index we are going to use in this tutorial too.

### Step 2: Organise your data

To obtain the dissimilarity matrix required for NMDS, we first need to reorganise our data so that each species has its own column and each ecological community has its own row (i.e., a site-by-species matrix). We already wrote the code to do this at the beginning of this tutorial.

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

data_nmds <- data |> 
  filter(Species != "Deadwood") |> 
  filter(Species != "Bare_ground") |>
  filter(Species != "Litter") |>
  group_by(Site, Plot, Species) |>
  summarise(Avg_cover = mean(Cover)) |> 
  mutate(Site = as.factor(Site)) |> 
  pivot_wider(names_from = Species,
              values_from = Avg_cover,
              values_fill = 0)

kable(head(data_nmds, 10))
```

### Step 3: Perform the NMDS

Now that our community dataset has the right format, we can perform the NMDS using the `metaMDS()` function of the *vegan* package. The following arguments are of particular importance:

-   `comm`: the community data (only select the species columns).
-   `distance`: a character value for the dissimilarity index used. Use `distance="bray"` for the Bray-Curtis dissimilarity index.
-   `k`: the number of dimensions to compute. Let's start with `k=2` (we want to produce a 2D plot).
-   `trymax`: the maximum number of random starts in search of a stable solution. The NMDS algorithm iteratively searches for a stable solution (numerical optimisation methods). Increasing the value of this argument can help reaching a stable solution.

We will keep the default values for all other arguments. Store the results in an object named `nmds`. Do not forget to set a seed (using `set.seed()` for reproducibility).

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false 

set.seed(123)

nmds <- metaMDS(comm = data_nmds[,3:ncol(data_nmds)],
                distance = "bray",
                k = 2,
                trymax = 1000)
```

### Step 4: Check NMDS results

The main goal of NMDS is to visualise a dissimilarity matrix in a lower (typically 2D) dimensional space. Contrary to principal coordinate analysis (PCoA), which aims to create a plot in which distances between points match the original dissimilarities as closely as possible, NMDS focuses on representing the order, or ranking, of the original dissimilarities as closely as possible (Zuur AF, Ieno EN, Smith GM. 2007. *Analysing ecological data*. Springer.).

The first way to assess the quality of the display is to look at a parameter called "stress". You can extract it from the `nmds` object created earlier using `nmds$stress`. In our example, the stress value is equal to `r round(nmds$stress, 3)`. Zuur et al (2007) provided some guidelines on how to interpret stress values (usually, the lower the stress value, the better):

-   stress \< 0.05: Excellent configuration
-   stress between 0.05 and 0.1: Good configuration
-   stress between 0.1 and 0.2: Be careful with interpretation
-   stress between 0.2 and 0.3: Problems start. Consider increasing the number of dimensions (`k`).
-   stress above 0.3: Poor representation. Increase the number of dimensions (`k`).

Another way to assess the quality of the configuration is to create a Shepard plot. A Shepard plot shows the relationship between ordination distances (i.e., distances in the configuration produced by the NMDS) and original distances. You can produce a Shepard plot using the `stressplot()` function in *vegan*. What can you conclude from this Shepard plot?

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false
#| fig-align: center

stressplot(nmds)
```

### Step 5: Visualise NMDS results

NMDS results are stored in our `nmds` object. You can extract the coordinates of each community using `nmds$points`. To make it easier to work with *ggplot2*, we will add these coordinates to our data frame (`data_nmds`).

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false

data_nmds <- cbind(data_nmds, nmds$points)

kable(head(data_nmds, 10))
```

We now have everything we need to plot the results of the NMDS using *ggplot2*:

-   Create a plot displaying MDS1 on the horizontal axis and MDS2 on the vertical axis.
-   Use a specific colour for each habitat type (mind colour-blind people!).
-   Add an informative legend to your graph.
-   Add an annotation on the top left corner of your graph for the stress value. Use `geom_text()` to do that.

What can you conclude from this NMDS?

```{r}
#| eval: true 
#| echo: true 
#| warning: false 
#| message: false
#| fig-align: center
#| fig-dpi: 1000

data_nmds |> 
  ggplot(aes(x = MDS1,
             y = MDS2,
             colour = Site))+
  geom_point(size=2.5)+
  theme_bw()+
  scale_colour_viridis(name = "Habitat type",
                       discrete = TRUE,
                       option = "D")+
  theme(axis.text = element_text(colour="black"),
        axis.title.x = element_text(margin = margin(t=10)),
        axis.title.y = element_text(margin = margin(r=10)))+
  xlab("NMDS1")+
  ylab("NMDS2")+
  geom_text(data=data.frame(x=min(data_nmds$MDS1),
                            y=max(data_nmds$MDS2),
                            label=paste("Stress = ", 
                                        round(nmds$stress, 3), 
                                        sep="")), 
            aes(x = x, 
                y = y, 
                label = label),
            hjust = 0.1, 
            vjust = 0, 
            inherit.aes = FALSE)
```
