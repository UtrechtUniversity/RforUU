[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "",
    "text": "GEO2-2439"
  },
  {
    "objectID": "index.html#course-code",
    "href": "index.html#course-code",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "",
    "text": "GEO2-2439"
  },
  {
    "objectID": "index.html#prologue",
    "href": "index.html#prologue",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "Prologue",
    "text": "Prologue\nThis Quarto website has been created to provide you with a single, searchable platform containing all the tutorials and R code used during our ecological field research course. We hope you will find it useful for learning data science in R and working on your course assignments.\nThe effectiveness of these tutorials lies in their practical approach. Instead of quickly scrolling down our tutorials and simply reading R code, we encourage you to actively use it and to take the time to understand what each function does. Even if you find learning R difficult at first, don’t give up and just keep learning at the pace that suits you. Learning R is exactly like learning a new language. At first, you can only write and speak short, simple sentences, but with regular practice, you will soon be able to write and understand the language fluently. The best way to learn R is by practicing it and reusing the same commands over and over again.\nNow get ready to improve your data science skills. Let’s get started!"
  },
  {
    "objectID": "index.html#r-for-data-science",
    "href": "index.html#r-for-data-science",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "R for Data Science",
    "text": "R for Data Science\nOur tutorials rely on the R for Data Science book (second edition) written by Hadley Wickham, Mine Cetinkaya-Rundel, Garrett Grolemund, and many other contributors. To freely access the content of this book, just click on its cover. Thank you to the authors of this book for creating such a gold mine of infoRmation. Due to the time constraints of our course, it is unfortunately not possible to go through all of the techniques and R code described in this data science book, but we strongly encourage you to explore its content and continue to learn new skills. In the tutorials, we will often refer to specific sections of the book if you wish to dive deeper into certain topics."
  },
  {
    "objectID": "R_basics.html",
    "href": "R_basics.html",
    "title": "R basics",
    "section": "",
    "text": "An R package is like a toolbox, except that instead of containing tools, it contains functions for performing specific tasks such as filtering data or fitting a statistical model. Most of the R packages you will need for these tutorials are freely available from CRAN (The Comprehensive R Archive Network) or GitHub. You can install CRAN R packages using install.packages().\n\n#Install an R package to import data from Excel files\ninstall.packages(\"readxl\")\n\nIf you want to install an R package stored in a GitHub repository, use install_github() in the devtools R package.\n\n#Install tbi R package to calculate Tea Bag Index paramaters\ndevtools::install_github(\"BenjaminDelory/tbi/tbi\")"
  },
  {
    "objectID": "R_basics.html#commenting",
    "href": "R_basics.html#commenting",
    "title": "R basics",
    "section": "Commenting",
    "text": "Commenting\nYou can add comments to your R script using the hash tag symbol: #\nEvery line that starts with # will be ignored by R and will not be executed.\n\n#This line of code is a comment and will be ignored by R when running the code\n\n\n\n\n\n\n\nAlways comment your R script!\n\n\n\nWe strongly advise you to add comments to your R code. At the very least, these comments should indicate why you have written each section of your code. It can also be useful to add information about the what and how. These comments can save a lot of time if you need to go back over your code after a while or, even more difficult, if someone else needs to go through your code and understand what you’ve done."
  },
  {
    "objectID": "R_basics.html#creating-r-objects",
    "href": "R_basics.html#creating-r-objects",
    "title": "R basics",
    "section": "Creating R objects",
    "text": "Creating R objects\n\n\n\n\n\n\nThe assignment operator\n\n\n\nNew R objects are created using the assigment operator: &lt;-\nYou can think of this assignment operator as an arrow that puts what’s on its right side into an R object located on its left side.\nFor instance, let’s create an object called x that contains the value 2.\n\n#Create object\nx &lt;- 2\n\n#Show content of R object\nx\n\n[1] 2\n\n\n\n\n\n\n\n\nRStudio shortcut\n\n\n\nPress Alt and the minus sign on your keyboard (Alt+-) to quickly write the assignment operator.\n\n\n\n\n\nScalars\nA scalar is a quantity that can only hold one value at a time. Here are the most common types of scalars in R:\n\nNumeric: numbers with a decimal value (e.g., 17.8)\nInteger: numbers without a decimal value (e.g., 18)\nCharacter: a letter or a combination of letters. Character strings must be enclosed by quotes in your R code.\nFactor: data type used in statistical modelling to specify what are the factors in the model\nLogical: a logical variable can be either TRUE or FALSE\n\nYou can check the data type of an R object using the class() function.\n\nx &lt;- 2\nclass(x)\n\n[1] \"numeric\"\n\n\n\n\nVectors\nA vector is a sequence of data elements of the same type. Vectors can be created using the c() function.\n\n#Numeric vector\nx1 &lt;- c(1,2,3,4,5)\nx1 &lt;- c(1:5)\n\n#Character vector\nx &lt;- c(\"control\", \"treatment\")\n\n#Logical vector\nx &lt;- c(TRUE, TRUE, FALSE)\n\nYou can check how many elements there are in a vector using the length() function.\n\nlength(x1)\n\n[1] 5\n\n\n\n\nMatrices\nA matrix is an ensemble of data elements of the same type arranged in a 2D layout (i.e., like a table). Matrices can be created using the matrix() function.\n\n#Generate 25 random numbers between 0 and 1 from a uniform distribution\nx2 &lt;- runif(25)\n\n#Arrange these random numbers into a matrix with 5 rows and 5 columns\nx2 &lt;- matrix(x2,\n            ncol = 5,\n            nrow = 5)\n\n#View matrix\nx2\n\n          [,1]       [,2]      [,3]       [,4]      [,5]\n[1,] 0.5899461 0.57870352 0.1579748 0.64363682 0.6548861\n[2,] 0.8209395 0.52230536 0.6096660 0.78847686 0.5791427\n[3,] 0.9982041 0.01246834 0.4590289 0.09040608 0.9303828\n[4,] 0.5442717 0.15606440 0.7885804 0.62668380 0.5882061\n[5,] 0.9914867 0.80992546 0.6077309 0.97170644 0.3522920\n\n\nYou can check the size of a matrix using the dim() function. The first element of the output is the number of rows. The second element of the output is the number of columns.\n\ndim(x2)\n\n[1] 5 5\n\n\nYou can also extract the number of rows and columns using nrow() and ncol(), respectively.\n\nnrow(x2)\n\n[1] 5\n\nncol(x2)\n\n[1] 5\n\n\n\n\nData frames\nA data frame is an ensemble of data elements arranged in a 2D layout (i.e., like a table). Different columns of a data frame can contain different types of data (character, logical, numeric, etc.). It is probably the most common data structure used when analysing ecological data. Data frames can be created using the data.frame() function.\n\n#Create data frame\nx3 &lt;- data.frame(Var1=c(1:6),\n                 Var2=c(\"R\", \"i\", \"s\", \"f\", \"u\", \"n\"),\n                 Var3=c(TRUE, TRUE, FALSE, FALSE, TRUE, FALSE))\n\n#View data frame\nx3\n\n  Var1 Var2  Var3\n1    1    R  TRUE\n2    2    i  TRUE\n3    3    s FALSE\n4    4    f FALSE\n5    5    u  TRUE\n6    6    n FALSE\n\n\nThe functions dim(), ncol(), and nrow() can also be used on data frames.\n\n\nLists\nA list is a vector containing other objects (vectors, matrices, data frames, other lists, etc.). It can contain elements of various data types. Lists can be created using the list() function.\n\n#Create a list\nx4 &lt;- list(x1, x2, x3)\n\n#View list\nx4\n\n[[1]]\n[1] 1 2 3 4 5\n\n[[2]]\n          [,1]       [,2]      [,3]       [,4]      [,5]\n[1,] 0.5899461 0.57870352 0.1579748 0.64363682 0.6548861\n[2,] 0.8209395 0.52230536 0.6096660 0.78847686 0.5791427\n[3,] 0.9982041 0.01246834 0.4590289 0.09040608 0.9303828\n[4,] 0.5442717 0.15606440 0.7885804 0.62668380 0.5882061\n[5,] 0.9914867 0.80992546 0.6077309 0.97170644 0.3522920\n\n[[3]]\n  Var1 Var2  Var3\n1    1    R  TRUE\n2    2    i  TRUE\n3    3    s FALSE\n4    4    f FALSE\n5    5    u  TRUE\n6    6    n FALSE\n\n\nThe length() function can be used to check how many data elements there are in a list.\n\nlength(x4)\n\n[1] 3"
  },
  {
    "objectID": "R_basics.html#indexing",
    "href": "R_basics.html#indexing",
    "title": "R basics",
    "section": "Indexing",
    "text": "Indexing\nOne of the main advantages of R is that it is very easy to extract any given value from a data set. This is called indexing. Let’s have a look at a few examples.\n\nVectors\nTo extract the ith value of a vector object called x, you should write x[i].\n\n#Extract the third value of the x1 object \n#x1 is a vector\n\nx1[3]\n\n[1] 3\n\n\n\n\nMatrices and data frames\nTo extract the value located at the intersection between the ith row and jth column of a matrix or a data frame object called x, you should write x[i,j].\n\n#Extract the value at the intersection of row 2 and column 3 in the x2 object\n#x2 is a matrix\n\nx2[2,3]\n\n[1] 0.609666\n\n\nWith a data frame, there are a couple of other options to extract data from specific columns. One option is to use the dollar symbol ($) followed by the column name.\n\n#Extract all the values stored in the second column of the x3 object\n#x3 is a data frame\n\nx3$Var2\n\n[1] \"R\" \"i\" \"s\" \"f\" \"u\" \"n\"\n\n\nNote that the following code would also work and would produce the same result. To extract all the values from a specific column, simply leave the square brackets empty before the comma. It is important to specify the name of the column (in quotes), otherwise you will simply extract all the values from your data frame.\n\n#Extract all the values stored in the second column of the x3 object\n#x3 is a data frame\n\nx3[,\"Var2\"]\n\n[1] \"R\" \"i\" \"s\" \"f\" \"u\" \"n\"\n\n\nIf you want to subset a matrix or a data frame called x (i.e., selecting only specifics rows and columns), you should write:\nx[rows to select, columns to select]\n\n#Extract only the values located between rows 2 and 4 \n#in the second column of the x3 object\n#x3 is a data frame\n\nx3[2:4, 2]\n\n[1] \"i\" \"s\" \"f\"\n\n\nNote that writing 2:4 means “from index 2 to index 4”. It is exactly the same as writing c(2,3,4).\n\n\nLists\nTo extract the ith element of a list object called x, you should write x[[i]].\n\n#Extract the second element of the x4 object\n#x4 is a list\n\nx4[[2]]\n\n          [,1]       [,2]      [,3]       [,4]      [,5]\n[1,] 0.5899461 0.57870352 0.1579748 0.64363682 0.6548861\n[2,] 0.8209395 0.52230536 0.6096660 0.78847686 0.5791427\n[3,] 0.9982041 0.01246834 0.4590289 0.09040608 0.9303828\n[4,] 0.5442717 0.15606440 0.7885804 0.62668380 0.5882061\n[5,] 0.9914867 0.80992546 0.6077309 0.97170644 0.3522920"
  },
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "To make the best out of these tutorials, you will need to install three things on your computer: R, RStudio, and a collection of R packages called tidyverse. If other R packages are needed, we will always mention them at the beginning of each tutorial."
  },
  {
    "objectID": "prerequisites.html#step-1-installing-r",
    "href": "prerequisites.html#step-1-installing-r",
    "title": "Prerequisites",
    "section": "Step 1: Installing R",
    "text": "Step 1: Installing R\nYou can download R for Linux, macOS, or Windows on the CRAN website. CRAN is an abbreviation for the Comprehensive R Archive Network."
  },
  {
    "objectID": "prerequisites.html#step-2-installing-rstudio",
    "href": "prerequisites.html#step-2-installing-rstudio",
    "title": "Prerequisites",
    "section": "Step 2: Installing RStudio",
    "text": "Step 2: Installing RStudio\nRStudio is an integrated development environment (IDE) for R (and other languages such as Python) developed by Posit, an open-source data science company. We highly recommend using RStudio, which will make your experience of working with R much more enjoyable. With RStudio, you can easily write your own scripts, run R code, manage your workspace, install and load R packages, view graphical output, and much more! You can download RStudio on the Posit website."
  },
  {
    "objectID": "prerequisites.html#step-3-installing-tidyverse",
    "href": "prerequisites.html#step-3-installing-tidyverse",
    "title": "Prerequisites",
    "section": "Step 3: Installing tidyverse",
    "text": "Step 3: Installing tidyverse\ntidyverse is a collection of R packages for data science. When installing tidyverse, you will install a suite of R packages that are very commonly used when processing and visualising data, such as readr, dyplr, tibble, ggplot2, and more! After opening RStudio, you can install tidyverse by executing the following code in your R console:\n\ninstall.packages(\"tidyverse\")"
  },
  {
    "objectID": "data_visualisation.html",
    "href": "data_visualisation.html",
    "title": "Tutorial 2: Data visualisation in R",
    "section": "",
    "text": "Welcome to this tutorial on data visualisation in R!\nThroughout this tutorial, our aim is to provide you with the basic tools for visualising your data in R. After organizing some variables, computing new ones, and filtering data for statistical analyses, we are now left with plotting and visualising our data. The aim of this tutorial is to help you master this fundamental skill!\nWe will work with the following published dataset on plant communities across Eurasia: Wassen MJ, Schrader J, van Dijk J, Eppinga MB. 2021. Phosphorus fertilization is eradicating the niche of northern Eurasia’s threatened plant species. Nature ecology & evolution 5: 67–73.\nAt the end of this tutorial, you will also learn how to map field site locations in R.\nLet’s get started!"
  },
  {
    "objectID": "data_visualisation.html#about-this-tutorial",
    "href": "data_visualisation.html#about-this-tutorial",
    "title": "Tutorial 2: Data visualisation in R",
    "section": "",
    "text": "Welcome to this tutorial on data visualisation in R!\nThroughout this tutorial, our aim is to provide you with the basic tools for visualising your data in R. After organizing some variables, computing new ones, and filtering data for statistical analyses, we are now left with plotting and visualising our data. The aim of this tutorial is to help you master this fundamental skill!\nWe will work with the following published dataset on plant communities across Eurasia: Wassen MJ, Schrader J, van Dijk J, Eppinga MB. 2021. Phosphorus fertilization is eradicating the niche of northern Eurasia’s threatened plant species. Nature ecology & evolution 5: 67–73.\nAt the end of this tutorial, you will also learn how to map field site locations in R.\nLet’s get started!"
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Tutorial 5: Data analysis in R",
    "section": "",
    "text": "Welcome to this tutorial on data analysis in R!\nThe rest is coming soon :-)"
  },
  {
    "objectID": "data_analysis.html#about-this-tutorial",
    "href": "data_analysis.html#about-this-tutorial",
    "title": "Tutorial 5: Data analysis in R",
    "section": "",
    "text": "Welcome to this tutorial on data analysis in R!\nThe rest is coming soon :-)"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact information",
    "section": "",
    "text": "Did you find a mistake in our tutorials? Or do you have suggestions to improve them?\nFeel free to contact Dr Benjamin Delory (b.m.m.delory@uu.nl)"
  },
  {
    "objectID": "data_exploration.html",
    "href": "data_exploration.html",
    "title": "Tutorial 4: Data exploration in R",
    "section": "",
    "text": "Welcome to this tutorial on data exploration in R!\nThroughout this tutorial, our aim is to provide you with the basic tools for exploring your data before carrying out any type of analysis. Data exploration is a very important step before starting any kind of analysis on ecological data, not to generate hypotheses (this should be done a priori, even before collecting data), but to make sure that the underlying assumptions of statistical models are respected, or to make sure that there are no outliers in our data that could strongly influence our analysis, thereby reducing the risk of type I (i.e., detecting an effect when none exists) or type II (i.e., not detecting an effect when there is one) errors. Data exploration is an important but often overlooked step, and this tutorial aims to understand some of the things to look for when exploring ecological data.\nThis tutorial builds on the previous ones and will focus on how we can use graphical tools to detect possible problems with our data. This tutorial is based on the excellent paper of Alain Zuur, Elena Ieno and Chris Elphick (2010), A protocol for data exploration to avoid common statistical problems, Methods in Ecology and Evolution, 1, 3-14. We strongly recommend that you read it. We will be using the same data to illustrate different data exploration techniques, but we will be constructing the graphs differently, relying mainly on the tools available in tidyverse. All the data needed for this tutorial are provided as supplementary information (Annex 1) of Zuur et al (2010).\nLet’s get started!"
  },
  {
    "objectID": "data_exploration.html#about-this-tutorial",
    "href": "data_exploration.html#about-this-tutorial",
    "title": "Tutorial 4: Data exploration in R",
    "section": "",
    "text": "Welcome to this tutorial on data exploration in R!\nThroughout this tutorial, our aim is to provide you with the basic tools for exploring your data before carrying out any type of analysis. Data exploration is a very important step before starting any kind of analysis on ecological data, not to generate hypotheses (this should be done a priori, even before collecting data), but to make sure that the underlying assumptions of statistical models are respected, or to make sure that there are no outliers in our data that could strongly influence our analysis, thereby reducing the risk of type I (i.e., detecting an effect when none exists) or type II (i.e., not detecting an effect when there is one) errors. Data exploration is an important but often overlooked step, and this tutorial aims to understand some of the things to look for when exploring ecological data.\nThis tutorial builds on the previous ones and will focus on how we can use graphical tools to detect possible problems with our data. This tutorial is based on the excellent paper of Alain Zuur, Elena Ieno and Chris Elphick (2010), A protocol for data exploration to avoid common statistical problems, Methods in Ecology and Evolution, 1, 3-14. We strongly recommend that you read it. We will be using the same data to illustrate different data exploration techniques, but we will be constructing the graphs differently, relying mainly on the tools available in tidyverse. All the data needed for this tutorial are provided as supplementary information (Annex 1) of Zuur et al (2010).\nLet’s get started!"
  },
  {
    "objectID": "data_wrangling.html",
    "href": "data_wrangling.html",
    "title": "Tutorial 1: Data wrangling in R",
    "section": "",
    "text": "Welcome to this tutorial on data wrangling in R!\nIn this tutorial, our goal is to provide you with basic tools for efficiently managing, tidying, and transforming datasets in R. Whether you are working with ecological data for exploration or analysis, a significant portion of your code will focus on tasks like importing data, organizing variables, computing new ones, and filtering data for statistical analyses and plotting. This tutorial is all about mastering these fundamental skills!\nLet’s start by getting to know the data we are going to work with a little better…"
  },
  {
    "objectID": "data_wrangling.html#about-this-tutorial",
    "href": "data_wrangling.html#about-this-tutorial",
    "title": "Tutorial 1: Data wrangling in R",
    "section": "",
    "text": "Welcome to this tutorial on data wrangling in R!\nIn this tutorial, our goal is to provide you with basic tools for efficiently managing, tidying, and transforming datasets in R. Whether you are working with ecological data for exploration or analysis, a significant portion of your code will focus on tasks like importing data, organizing variables, computing new ones, and filtering data for statistical analyses and plotting. This tutorial is all about mastering these fundamental skills!\nLet’s start by getting to know the data we are going to work with a little better…"
  },
  {
    "objectID": "data_wrangling.html#ecological-field-data-used-in-this-tutorial",
    "href": "data_wrangling.html#ecological-field-data-used-in-this-tutorial",
    "title": "Tutorial 1: Data wrangling in R",
    "section": "Ecological field data used in this tutorial",
    "text": "Ecological field data used in this tutorial\nIn this tutorial, we will import, tidy and transform data collected between 2020 and 2023 as part of a grassland field experiment located in Germany. This section will provide you with more information about the aims and design of this experiment, as well as what has been measured in the field by the researchers who have been actively working on this experiment since 2020. A detailed description of the raw data will come a little bit later.\nA detailed description of this experiment is also provided in Alonso-Crespo IM, Temperton VM, Fichtner A, Niemeyer T, Schloter M, Delory BM. 2023. Exploring priority and year effects on plant diversity, productivity and vertical root distribution: first insights from a grassland field experiment. bioRxiv: 2023.11.14.566982.\n\nObjectives of the POEM experiment\nThe POEM experiment (PriOrity Effect Mechanisms) was set up to study how the year of initiation of an experiment and the order of arrival of species during community assembly affect the structure and functioning of dry grassland plant communities. This knowledge is important because it can help us to better predict the results of restoration efforts (year effects), but also to better understand how manipulating the order of arrival of species can help us to steer the trajectory of plant communities towards desired states (priority effects).\n\n\nDesign of the POEM experiment\nThe researchers set up the same experiment manipulating the order of arrival of species at the same experimental site, but in two consecutive years. This means that one experiment was set up in 2020, while the other was set up in 2021. Both experiments test the same order of arrival scenarios. Therefore, the POEM experiment has two main fixed factors:\nFactor 1: The order of arrival of plant species. This factor has 5 different levels:\n\nSynchronous (S): all plant species are sown simultaneously\nForbs sown first (F): forb species are sown 6 weeks before grasses and legumes\nGrasses sown first (G): grass species are sown 6 weeks before forbs and legumes\nLegumes sown first (L): legume species are sown 6 weeks before forbs and grasses\nFree succession (B): no species are sown in these plots\n\nFactor 2: The year of initiation of an experiment. This factor has 2 levels:\n\n2020 if the experiment was set up in 2020\n2021 if the experiment was set up in 2021\n\nThe experiment consists of 50 experimental plots, with 5 replicates per factor combination.\n\n\n\nPOEM experiment in June 2021 (Niederhaverbeck, Germany). Photo credit: B. Delory."
  },
  {
    "objectID": "data_wrangling.html#importing-data",
    "href": "data_wrangling.html#importing-data",
    "title": "Tutorial 1: Data wrangling in R",
    "section": "Importing data",
    "text": "Importing data\nThe first thing to do after opening RStudio is to import some data to work with. There are a number of ways to do this depending on the input file format. We will focus on just a few of them here.\n\nDownload the POEM data from Zenodo\nThe POEM data that will be used in this tutorial are available on a Zenodo repository. You can download the data manually, but you can also do it using an R function called download_zenodo(). Let’s give it a try.\nFirst, install the inborutils R package using the following code:\n\ninstall.packages(\"inborutils\", repos = c(inbo = \"https://inbo.r-universe.dev\", \n                                         CRAN = \"https://cloud.r-project.org\"))\n\nYou can now download the data used in this tutorial using download_zenodo().\n\n\nCode\ninborutils::download_zenodo(doi=\"10.5281/zenodo.10119982\",\n                            quiet=TRUE)\n\n\nBy default, the data will be downloaded as a zip file and will be stored in your working directory. If you do not know what is your working directory, run getwd() in your R console. Let’s extract (or unzip) the files we have just downloaded from Zenodo and let’s store these files in a new folder called “Data_POEM”:\n\n\nCode\nunzip(zipfile = \"Data_POEM_Paper1_Alonso-Crespo_et_al_2024-v1.0.zip\",\n      exdir = \"Data_POEM\")\n\n\nThe notation inborutils::download_zenodo() means that we want to use the function download_zenodo() contained in the inborutils R package. This notation is very useful because it is not uncommon to have different R functions from different packages with the same name. It is an easy way to make sure that the right function is used for your analysis.\n\n\nLoad R packages\nMost of the functions we need for the rest of this tutorial are available in R packages from the tidyverse collection. We will also need the read_excel() function from the readxl package and the kable() function from the knitr package. You can load tidyverse, readxl, and knitr using library().\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(knitr)\n\n\n\n\nImport data into R\nThere are quite a few functions available in R to import data. Your choice will mainly depend on the file format used to store data. For instance, if your data is stored in a csv file (i.e., comma separated values), then read_csv() would be a good choice. A more general option that would work well for most data stored in text files is read_delim().\nIn the POEM project, raw biomass data are stored in different folders for the experiment started in 2020 (POEM2020) and the experiment started in 2021 (POEM2021). For each experiment, there is one data file for each growing season. As the data is stored in Excel files (.xlsx), we can use read_excel() to import our data into R. For now, we will simply store each set of data in separate R objects.\n\n\nCode\n#Import data from the first experiment (POEM2020)\n\npoem2020_year1 &lt;- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2020-07.xlsx\")\n\npoem2020_year2 &lt;- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2021-06.xlsx\")\n\npoem2020_year3 &lt;- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2020/Data_Biomass_POEM2020_2022-06.xlsx\")\n\n#Import data from the second experiment (POEM2021)\n\npoem2021_year1 &lt;- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2021-07.xlsx\")\n\npoem2021_year2 &lt;- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2022-06.xlsx\")\n\npoem2021_year3 &lt;- read_excel(\"Data_POEM/POEMexperiment-Data_POEM_Paper1_Alonso-Crespo_et_al_2024-0c2abb7/Data/POEM2021/Data_Biomass_POEM2021_2023-06.xlsx\")\n\n\n\n\n[1] TRUE\n\n\nIn RStudio, you can see how each data frame looks like using View().\n\n\nCode\nView(poem2021_year1)\n\n\nYou can see that each dataset consists of a number of observations (rows) of 6 variables (columns). These variables are:\n\nYear: the year of initiation of each experiment\nHarvest: the date at which biomass data were collected (YYYY-MM)\nPlot: the plot identification number (plot number - arrival order/replicate)\nQuadrat: the quadrat identification number (plant biomass was collected in 2 or 4 quadrats per plot)\nSpecies: the plant species name\nSDW_g: the shoot dry weight in grams\n\nTo enable data exploration and analysis, we now need to combine these different datasets, so that all the data is stored in the same R object. You can do this using rbind().\n\n\nCode\npoem_data &lt;- rbind(poem2020_year1,\n                   poem2020_year2,\n                   poem2020_year3,\n                   poem2021_year1,\n                   poem2021_year2,\n                   poem2021_year3)"
  },
  {
    "objectID": "data_wrangling.html#tidying-data",
    "href": "data_wrangling.html#tidying-data",
    "title": "Tutorial 1: Data wrangling in R",
    "section": "Tidying data",
    "text": "Tidying data\n\n\n\n\n\n\nWhat’s make a dataset tidy?\n\n\n\nA tidy dataset follows these three rules:\n\nEach variable is a column and each column is a variable\nEach observation is a row and each row is an observation\nEach value is a cell and each cell is a single value\n\nAll packages in the tidyverse are designed to work with tidy data. This section is all about learning how to make your data tidy.\n\n\n\nExtracting data from strings\nIn our dataset, the Plot column contains three different pieces of information: the plot ID number, the order of arrival scenario (S, F, G, L, B), and the replicate number. How can we store each piece of information in a specific column? The short answer is by using separate_wider_position() and/or separate_wider_delim(). These functions are very useful when several important variables are pasted together in a single string, which is generally the case when you use barcodes to make sample processing faster and less prone to human error. Let’s see how it works.\nFirst, we are going to separate the plot identification number (which is located on the left side of the hyphen) from the other elements (located on the right side of the hyphen). As the hyphen acts as a delimiter, we will use separate_wider_delim() to split the Plot column into two new columns (PlotID and Treatment), one of which stores the plot identification number (PlotID).\n\n\nCode\npoem_data &lt;- separate_wider_delim(data = poem_data,\n                                  cols = \"Plot\",\n                                  delim=\"-\",\n                                  names=c(\"PlotID\", \"Treatment\"),\n                                  cols_remove=TRUE) #Do not keep Plot column in the data\n\n#Specify that PlotID is a numeric variable\n\npoem_data$PlotID &lt;- as.numeric(poem_data$PlotID)\n\n\nWe are halfway there. The Treatment column contains two pieces of information that we would like to store in separate columns. As there is no clear delimiter between the letter referring to the order of arrival scenario and the replicate number, we will use separate_wider_position() to do that.\n\n\nCode\npoem_data &lt;- separate_wider_position(data = poem_data,\n                                     cols = \"Treatment\",\n                                     width=c(Arrival=1, Replicate=1), #Specify column names and column widths\n                                     cols_remove=TRUE) #Do not keep Plot column in the data\n\n#Specify that Replicate is a numeric variable\n\npoem_data$Replicate &lt;- as.numeric(poem_data$Replicate)\n\n\nAnd that’s it! Now each column in our dataset contains one single piece of information, which is all we needed to start exploring and analysing the data.\nOne important note before moving on to the next section. When you are writing R code, there isn’t usually just one way of writing it. Consider what we have just done: it is possible to write your code in a more compact and efficient way, while still performing the same operations. This requires using the pipe.\n\n\n\n\n\n\nThe pipe: |&gt;\n\n\n\nIn tidyverse, each action is associated to a specific verb. For instance, filter() is used to filter data, select() is used to select specific columns, rename() is used to rename variables, mutate() is used to transform variables, etc. When working with ecological data, it is very common to have to perform more than one action. In this case, you need to combine several verbs, which is best done using the pipe. The pipe works as follows: it passes the thing on its left to the function on its right. This means that writing f(x, y) is equivalent to x |&gt; f(y).\nTo add the pipe to your code, use the following keyboard shortcut: Ctrl/Cmd + Shift + M\nBefore starting using the pipe, go to Tools –&gt; Global Options… –&gt; Code, and make sure that the “Use native pipe operator” is checked. This requires R.4.1.+.\n\n\nLet’s give it a try and rewrite the code we wrote to separate strings using the pipe. This time, we are also going to use mutate() to convert PlotID and Replicate as numeric variables. We will also use rename() to rename “SDW_g” into “Biomass”.\nFirst, we need to recreate the data we started working with.\n\n\nCode\n#Recreate starting dataset\n\npoem_data &lt;- rbind(poem2020_year1,\n                   poem2020_year2,\n                   poem2020_year3,\n                   poem2021_year1,\n                   poem2021_year2,\n                   poem2021_year3)\n\n\nNow we can rewrite our code using the pipe.\n\n\nCode\n#Extract information from the Plot column using the pipe\n\npoem_data &lt;- poem_data |&gt; \n  separate_wider_delim(cols = Plot,\n                       delim=\"-\",\n                       names=c(\"PlotID\", \"Treatment\"),\n                       cols_remove=TRUE) |&gt; \n  separate_wider_position(cols = Treatment,\n                          width=c(Arrival=1, Replicate=1),\n                          cols_remove=TRUE) |&gt; \n  mutate(PlotID=as.numeric(PlotID),\n         Replicate=as.numeric(Replicate)) |&gt; \n  rename(Biomass=SDW_g)\n\n\nLet’s take a quick look at the first ten rows of our dataset using head(). We can also use kable() in the knitr package to produce a nice looking table in your R console.\n\n\nCode\nkable(head(poem_data, n = 10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nHarvest\nPlotID\nArrival\nReplicate\nQuadrat\nSpecies\nBiomass\n\n\n\n\n2020\n2020-07\n101\nF\n1\n1\nAgrostis capillaris\n0.0000\n\n\n2020\n2020-07\n101\nF\n1\n1\nAnchusa arvensis\n0.0000\n\n\n2020\n2020-07\n101\nF\n1\n1\nAnthemis arvensis\n10.2100\n\n\n2020\n2020-07\n101\nF\n1\n1\nAnthoxanthum odoratum\n0.0000\n\n\n2020\n2020-07\n101\nF\n1\n1\nArabidopsis thaliana\n0.0000\n\n\n2020\n2020-07\n101\nF\n1\n1\nBromus hordeaceus\n0.0000\n\n\n2020\n2020-07\n101\nF\n1\n1\nCapsella bursa-pastoris\n0.0000\n\n\n2020\n2020-07\n101\nF\n1\n1\nChenopodium album\n0.7658\n\n\n2020\n2020-07\n101\nF\n1\n1\nCrepis tectorum\n0.0000\n\n\n2020\n2020-07\n101\nF\n1\n1\nDianthus deltoides\n0.0000\n\n\n\n\n\n\n\nWidening and lengthening data\nWhat is meant by widening and lengthening data?\nWidening means increasing the number of columns and reducing the number of rows in your dataset. Lengthening is the opposite: increasing the number of rows and reducing the number of columns.\nWhy would we want to widen or lengthen our dataset?\nLet’s take our POEM data as an example. The Biomass column contains the shoot dry weight measured on all species in all plots. In some cases, however, we may wish to focus our analysis on specific species. In that case, it would be easier to fit statistical models if the biomass of each species is stored as a separate variable in our dataset. This requires widening our data to have as many columns storing biomass data as species in our dataset. The best way to do this is to use pivot_wider(). If your goal is to lengthen your data, pivot_longer() is the way to go. Let’s see how these two functions work.\n\n\nCode\n#Use pivot_wider so that the biomass of each species is stored as a separate variable\n\npoem_data_wide &lt;- poem_data |&gt; \n  pivot_wider(names_from = Species, #Species names will be used as column names\n              values_from = Biomass, #Biomass values are stored in the Biomass column\n              values_fill = 0, #If a species is absent in a plot, its biomass value is zero\n              values_fn = sum) #Sum biomass values measured on the same species and in the same quadrat\n\n\nIf we use dim() to check the dimensions of our dataset, we can see that it contains 350 rows and 56 columns.\n\n\nCode\ndim(poem_data_wide)\n\n\n[1] 350  56\n\n\nNow let’s use pivot_longer() on our widened dataset to bring it back to how it was before.\n\n\nCode\n#Use pivot_wider so that the biomass of each species is stored as a separate variable\n\npoem_data_long &lt;- poem_data_wide |&gt; \n  pivot_longer(cols = `Agrostis capillaris`:`Vicia hirsuta`, #From column X to column Y\n               names_to = \"Species\", #Store species names in Species column\n               values_to = \"Biomass\") #Store biomass data in Biomass column\n\n\nNote that this new dataset has the same structure as our initial dataset (poem_data), but contains many more rows. You can check this using dim() or nrow(). This is due to the fact that poem_data_long now includes many null values for species that were not detected during biomass harvesting in the quadrats."
  },
  {
    "objectID": "data_wrangling.html#transforming-data",
    "href": "data_wrangling.html#transforming-data",
    "title": "Tutorial 1: Data wrangling in R",
    "section": "Transforming data",
    "text": "Transforming data\n\nR operators\nBefore diving into this chapter, it is useful to remember the main relational and logical operators in R. This can be useful when you need to define conditions to select specific rows in your data, for example. This happens very frequently when programming in R.\n\nRelational and logical operators in R\n\n\nOperators\nDescription\nType\n\n\n\n\n&lt;\nLess than\nRelational\n\n\n&gt;\nGreater than\nRelational\n\n\n&lt;=\nLess than or equal to\nRelational\n\n\n&gt;=\nGreater than or equal to\nRelational\n\n\n==\nEqual to\nRelational\n\n\n!=\nNot equal to\nRelational\n\n\n!\nNOT\nLogical\n\n\n&\nAND\nLogical\n\n\n|\nOR\nLogical\n\n\n\n\n\nFiltering data\nFiltering allows you to select specific rows in your dataset based on column values. This is particularly useful if you only want to work on specific factor levels. For example, we might be interested in working only with plots where seeds have been added. This means that free succession plots (B) must be removed from the dataset. We can do this using filter().\n\n\nCode\npoem_data_filtered &lt;- poem_data_long |&gt; \n  filter(Arrival != \"B\") #Select rows where Arrival is not equal to \"B\"\n\n\nNote that the same result can be obtained using different coding styles:\n\n\nCode\n#Another option 1\n\npoem_data_filtered &lt;- poem_data_long |&gt; \n  filter(Arrival == \"S\" | Arrival == \"F\" | Arrival == \"G\" | Arrival == \"L\")\n\n#Another option 2\n\npoem_data_filtered &lt;- poem_data_long |&gt; \n  filter(Arrival %in% c(\"S\", \"F\", \"G\", \"L\"))\n\n\n\n\nArranging data\nArranging means sorting the rows in your dataset based on the value of other columns. You can do this using arrange(). Let’s modify our POEM data by sorting species alphabetically within each plot.\n\n\nCode\npoem_data_arranged &lt;- poem_data_long |&gt; \n  arrange(Species, PlotID)\n\n\nBy default, numeric values are sorted from the smallest to the greatest values. If you want to do the opposite, you can use desc() within arrange(). For example, let’s reuse the code we’ve just written, but this time let’s sort the species in alphabetical order within each plot and in descending order of biomass values.\n\n\nCode\npoem_data_arranged &lt;- poem_data_long |&gt; \n  arrange(Species, desc(Biomass))\n\n\nCheck what happened to the dataset using View().\n\n\nSelecting variables\nIf you have a very large dataset, with hundreds or thousands of variables, you may want to subset your data and only keep the variables that interest you the most. This is done using select().\nAs an example, let’s use the extended version of the dataset we created earlier and select all the variables related to our experimental design (Year, Harvest, PlotID, Arrival, Replicate, Quadrat), as well as the columns containing biomass data for the fourteen species that were sown in the plots at the start of the experiment (Anthoxanthum odoratum, Agrostis capillaris, Bromus hordeaceus, Festuca ovina, Lathyrus pratensis, Trifolium arvense, Trifolium campestre, Lotus corniculatus, Jasione montana, Pimpinella saxifraga, Silene vulgaris, Pilosella officinarum, Dianthus deltoides, and Potentilla argentea).\n\n\nCode\npoem_data_subset &lt;- poem_data_wide |&gt; \n  select(Year, Harvest, PlotID, Arrival, Replicate, Quadrat,\n         `Anthoxanthum odoratum`, \n         `Agrostis capillaris`, \n         `Bromus hordeaceus`, \n         `Festuca ovina`, \n         `Lathyrus pratensis`, \n         `Trifolium arvense`, \n         `Trifolium campestre`, \n         `Lotus corniculatus`, \n         `Jasione montana`, \n         `Pimpinella saxifraga`, \n         `Silene vulgaris`, \n         `Pilosella officinarum`, \n         `Dianthus deltoides`,\n         `Potentilla argentea`)\n\n\n\n\nTransforming variables\nTransforming variables is certainly one of the most common operations that data scientists do when preparing data for analysis. If you want to calculate new variables from the ones that are already present in your dataset, this is precisely what mutate() does.\nIn our POEM data, the biomass of each species in a plot is expressed in grams. In published papers, however, plant yield is often standardised per unit surface area and is expressed in grams per square meter. Let’s use mutate() to add a new column (Std_biomass) in our dataset (poem_data_long). Each quadrat used to collect plant biomass had an area of 0.1 m². In mutate(), the arguments .before and .after allow you to control where you want your new variables to be inserted in your dataset.\n\n\nCode\npoem_data_long &lt;- poem_data_long |&gt; \n  mutate(Std_biomass=Biomass/0.1, #Convert to g/m²\n         .after = \"Biomass\") #Specify that we want this new column to be after the Biomass column\n\n\n\n\nSummarise variables\nLastly, let’s have a look at the summarise() function. As its name suggests, this function allows you to calculate summary statistics for groups present in your dataset. The output of summarise() is a data frame with as many rows as groups in your data, with desired summary statistics provided for each group.\nBefore using summarise(), remember to use group_by() to divide your dataset into groups that are of interest for your analysis.\nLet’s combine group_by() and summarise() to calculate the total productivity of each plot at the end of each growing season. To do this, we have to sum the biomass values (expressed in g/m²) of all species found in our plot. Remember that several quadrats have been harvested in each plot, which means that we first have to calculate the average productivity of each species in a plot. We are going to do all this using the poem_data_long object as a starting point.\n\n\nCode\npoem_data_summary &lt;- poem_data_long |&gt; \n  group_by(Year, Harvest, PlotID, Arrival, Species) |&gt; #Define grouping factors in your data\n  summarise(Std_biomass=mean(Std_biomass)) |&gt; #Calculates the average productivity of each species in a plot\n  group_by(Year, Harvest, PlotID, Arrival) |&gt; #Redefine groups (interested in summing biomass values across species)\n  summarise(Total_biomass=sum(Std_biomass)) #Calculate total biomass production in each plot\n\n\nCheck your summary table using View()."
  },
  {
    "objectID": "quantifying_biodiversity.html",
    "href": "quantifying_biodiversity.html",
    "title": "Tutorial 3: Quantifying taxonomic diversity",
    "section": "",
    "text": "Welcome to this tutorial on quantifying taxonomic diversity in R!\nThroughout this tutorial, you will learn different ways to quantify species diversity in an ecosystem and become aware of some of the challenges associated with quantifying biodiversity. This tutorial focuses on quantifying taxonomic diversity across scales (alpha, beta, and gamma diversity sensu Whittaker 1960). In addition, you will use the knowledge gained in tutorials 1 and 2 to calculate Hill numbers of order q (i.e. the effective number of species for a given diversity order q ) and plot diversity profiles to analyse and compare biodiversity between different sites in a hypothetical metacommunity. Particular attention will be paid to the importance of sampling effort when comparing biodiversity estimates between sites with different levels of biodiversity.\nThere are R packages that allow you to calculate all the diversity measures listed above, but we will not be using them in this tutorial. We would like you to write your own R code to calculate them. Once again, it’s all about learning by doing.\nLet’s get started!"
  },
  {
    "objectID": "quantifying_biodiversity.html#about-this-tutorial",
    "href": "quantifying_biodiversity.html#about-this-tutorial",
    "title": "Tutorial 3: Quantifying taxonomic diversity",
    "section": "",
    "text": "Welcome to this tutorial on quantifying taxonomic diversity in R!\nThroughout this tutorial, you will learn different ways to quantify species diversity in an ecosystem and become aware of some of the challenges associated with quantifying biodiversity. This tutorial focuses on quantifying taxonomic diversity across scales (alpha, beta, and gamma diversity sensu Whittaker 1960). In addition, you will use the knowledge gained in tutorials 1 and 2 to calculate Hill numbers of order q (i.e. the effective number of species for a given diversity order q ) and plot diversity profiles to analyse and compare biodiversity between different sites in a hypothetical metacommunity. Particular attention will be paid to the importance of sampling effort when comparing biodiversity estimates between sites with different levels of biodiversity.\nThere are R packages that allow you to calculate all the diversity measures listed above, but we will not be using them in this tutorial. We would like you to write your own R code to calculate them. Once again, it’s all about learning by doing.\nLet’s get started!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "",
    "text": "GEO2-2439"
  },
  {
    "objectID": "about.html#course-code",
    "href": "about.html#course-code",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "",
    "text": "GEO2-2439"
  },
  {
    "objectID": "about.html#prologue",
    "href": "about.html#prologue",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "Prologue",
    "text": "Prologue\nThis Quarto website has been created to provide you with a single, searchable platform containing all the tutorials and R code used during our ecological field research course. We hope you will find it useful for learning data science in R and working on your course assignments.\nThe effectiveness of these tutorials lies in their practical approach. Instead of quickly scrolling down our tutorials and simply reading R code, we encourage you to actively use it and to take the time to understand what each function does. Even if you find learning R difficult at first, don’t give up and just keep learning at the pace that suits you. Learning R is exactly like learning a new language. At first, you can only write and speak short, simple sentences, but with regular practice, you will soon be able to write and understand the language fluently. The best way to learn R is by practicing it and reusing the same commands over and over again.\nNow get ready to improve your data science skills. Let’s get started!"
  },
  {
    "objectID": "about.html#r-for-data-science",
    "href": "about.html#r-for-data-science",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "R for Data Science",
    "text": "R for Data Science\nOur tutorials rely on the R for Data Science book (second edition) written by Hadley Wickham, Mine Cetinkaya-Rundel, Garrett Grolemund, and many other contributors. To freely access the content of this book, just click on its cover. Thank you to the authors of this book for creating such a gold mine of infoRmation. Due to the time constraints of our course, it is unfortunately not possible to go through all of the techniques and R code described in this data science book, but we strongly encourage you to explore its content and continue to learn new skills."
  },
  {
    "objectID": "data_wrangling.html#take-home-message",
    "href": "data_wrangling.html#take-home-message",
    "title": "Tutorial 1: Data wrangling in R",
    "section": "Take-home message",
    "text": "Take-home message\nData wrangling is a very important part of any data analysis pipeline. This tutorial aimed to give you a brief overview of the main functions available in R for importing, tidying and transforming data. Of course, this tutorial is far from exhaustive and many other tools are available. We encourage you to continue learning and discovering new functions available in the tidyverse by using the popular book R for Data Science."
  },
  {
    "objectID": "data_visualisation.html#introduction-to-ggplot2",
    "href": "data_visualisation.html#introduction-to-ggplot2",
    "title": "Tutorial 2: Data visualisation in R",
    "section": "Introduction to ggplot2",
    "text": "Introduction to ggplot2\nWhen visualising data in R, you can of course use base R functions (e.g., plot, points, lines, etc.), but this tutorial is only going to focus on functions of the ggplot2 R package. This is because ggplot2 can produce high-quality figures very quickly, even for complex ecological datasets. With ggplot2, you can generate a wide variety of graphs, including scatter plots, bar charts, histograms, box plots and much more, while having control over layouts, labels and aesthetics, such as colours, sizes and shapes. ggplot2 relies on a coherent system for building graphs: the grammar of graphics. Using ggplot2 requires you to learn a new grammar, which may sound overwhelming at first, but is in fact easy to learn because it relies on a simple set of core principles.\n\n\n\n\n\n\nggplot2: Elegant Graphics for Data Analysis\n\n\n\nThis tutorial will only give you a very brief introduction to ggplot2. If you want to explore all the possibilities offered by ggplot2 for data scientists, we recommend going through Hadley Wickham’s reference book: ggplot2: Elegant Graphics for Data Analysis. To freely access the content of this book, just click on its cover.\n\n\n\n\n\n\n\nIn this tutorial, we will use ggplot2 to create the following graphs:\n\nA box plot to explore the relationship between a continuous response variable and a categorical predictor\nA scatter plot to explore the relationship between two continuous variables\nA map to visualise field site locations\n\n\n\n\n\n\n\nPosit Cheat Sheets\n\n\n\nPosit, the open source data science company behind RStudio, developed some very useful cheat sheets to help you remember how to use some of the core tidyverse packages, including ggplot2. You can download the ggplot2 cheat sheet using this link."
  },
  {
    "objectID": "data_visualisation.html#load-r-packages",
    "href": "data_visualisation.html#load-r-packages",
    "title": "Tutorial 2: Data visualisation in R",
    "section": "Load R packages",
    "text": "Load R packages\nThe first step is to load all the R packages needed for this tutorial. Since ggplot2 is included in tidyverse, we just need to load the tidyverse library. We will also need a couple of other packages, including knitr, viridis, Hmisc, and ggpubr. Do not forget to install them if you do not have them in your library.\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(viridis)\nlibrary(Hmisc)\nlibrary(ggpubr)"
  },
  {
    "objectID": "data_visualisation.html#exercise-1-creating-a-box-plot",
    "href": "data_visualisation.html#exercise-1-creating-a-box-plot",
    "title": "Tutorial 2: Data visualisation in R",
    "section": "Exercise 1: Creating a box plot",
    "text": "Exercise 1: Creating a box plot\n\nImport data into R\nWassen et al (2021) showed that threatened species are most commonly found in soils with relatively low phosphorus (P) and low P to Nitrogen (N) ratio. They determined a N:P median niche value and compared species that were threatened to those that were not using a box plot (see Figure 2 in the original paper). In this first exercise, we are going to recreate and improve this visualisation.\nAs the data is stored in a csv file (NPsp_Wassen.csv), we will use read_csv() to import the data into R. This csv file is stored in our working directory, in a folder called Data_ggplot2. Store data into an R object named data_wassen.\n\n\nCode\n#Import data file (csv file)\ndata_wassen &lt;- read.csv(\"Data_ggplot2/NPsp_Wassen.csv\")\n\n\nHave a look at how the data frame looks like using View() or head().\n\n\nCode\nkable(head(data_wassen, n=10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nspecies.occurence.frequency..pool.\nthreatened\nN_variance\nP_variance\nK_variance\nNP_variance\nNK_variance\nKP_variance\nN_median\nP_median\nK_median\nNP_median\nNK_median\nKP_median\n\n\n\n\nAchillea millefolium\n99\nNo\n17.17\n0.72\n71.66\n0.18\n0.49\n0.50\n12.74\n1.99\n14.74\n6.53\n0.83\n7.93\n\n\nAchillea ptarmica\n327\nNo\n15.42\n0.55\n43.26\n0.18\n0.41\n0.43\n14.90\n1.69\n9.83\n8.93\n1.47\n6.31\n\n\nAcorus calamus\n74\nNo\n11.48\n0.28\n73.13\n0.10\n0.32\n0.46\n13.66\n1.24\n12.96\n11.01\n1.00\n10.28\n\n\nAgrostis canina\n611\nNo\n14.39\n0.65\n49.45\n0.27\n0.36\n0.50\n14.35\n1.32\n10.76\n11.00\n1.29\n8.81\n\n\nAgrostis capillaris\n304\nNo\n15.79\n0.73\n42.48\n0.29\n0.40\n0.48\n15.53\n1.60\n10.44\n9.36\n1.47\n7.36\n\n\nAgrostis gigantea\n179\nNo\n9.68\n0.40\n61.44\n0.24\n0.25\n0.47\n13.15\n1.17\n12.59\n11.32\n1.04\n10.11\n\n\nAgrostis stolonifera\n516\nNo\n14.39\n0.67\n51.01\n0.21\n0.35\n0.47\n14.39\n1.45\n11.24\n10.14\n1.21\n8.53\n\n\nAjuga reptans\n122\nNo\n16.39\n0.65\n64.76\n0.16\n0.42\n0.47\n12.75\n1.95\n14.61\n6.85\n0.82\n8.42\n\n\nAlisma plantago-aquatica\n65\nNo\n10.42\n0.34\n46.67\n0.12\n0.22\n0.32\n13.25\n1.33\n12.82\n10.12\n1.01\n10.11\n\n\nAllium angulosum\n14\nYes\n5.62\n0.59\n21.24\n0.20\n0.04\n0.10\n11.94\n0.91\n15.98\n12.34\n0.79\n13.64\n\n\n\n\n\nHaving examined the figure in the original article (Figure 2), what variables do you think are needed to recreate this figure?\n\n\nCreate a ggplot\nYou can start creating a plot using the function ggplot(). Later on, we will add new layers to this ggplot object. ggplot() has two main arguments: data and mapping. The data argument is used to specify the name of the dataset that should be used to create the graph. The mapping argument is used to specify how variables in your dataset are linked to visual properties (referred to aesthetics) of your plot. You should always use the aes() function for the mapping argument. The x and y arguments of aes() are used to choose the x (horizontal) and y (vertical) variables of your plot, respectively. The general syntax to create a ggplot object looks like this:\nggplot(data = your_data, mapping = aes(x, y, other aesthetics))\nLet’s create our first ggplot using threatened (i.e., whether a species is threatened or not) and NP_median (i.e., the N:P median niche value of each species in the dataset) as the x and y variables, respectively.\n\n\nCode\nggplot(data = data_wassen, \n       mapping = aes(x = threatened, \n                     y = NP_median))\n\n\n\n\n\n\n\n\n\nAs you can see, the structure of the plot is there, but it does not display any data yet. This is because we have not specified in our code how our observations should be represented in our plot. You can do this by defining a geom. In ggplot2, there are a number of geom to choose from. Here are a few examples (but see ggplot2 cheat sheet for more examples):\n\ngeom_point(): This geom is used to display individual data points and create a scatter plot.\ngeom_jitter(): This geom is similar to geom_point() but jitters the data to improve readability.\ngeom_line() and geom_path(): These geom are used to add lines connecting observations in your graph. While geom_path() connects observations in the order in which they appear in the data, geom_line() connects observations in the order of the variable plotted on the x axis of your graph.\ngeom_boxplot(): This geom is used to create a box plot, which is particularly useful to display and compare the distribution of a response variable for different groups.\ngeom_bar(): This geom is used to create bar charts.\ngeom_abline(): This geom is used to add horizontal, vertical, and diagonal lines to your graph.\n\nAs we want to create a box plot, let’s use geom_boxplot(). In geom_boxplot(), use the width argument to make boxes more narrow (by default, width=1).\n\n\nCode\nggplot(data = data_wassen, \n       mapping = aes(x = threatened, \n                     y = NP_median))+\n  geom_boxplot(width=0.5)\n\n\n\n\n\n\n\n\n\nIt’s starting to look like a graph! We can improve it even further by plotting the raw data on top of the box plot. You can do this using geom_jitter(). In geom_jitter(), use the width argument to adjust the horizontal spread of the data points. Set also height=0 to make sure that data points are only jittered horizontally. We will also use the shape argument to choose the symbol we want to use to represent each data point. There a number of options to choose from:\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = data_wassen, \n       mapping = aes(x = threatened, \n                     y = NP_median))+\n  geom_boxplot(width=0.5)+\n  geom_jitter(width=0.1, \n              height=0, \n              shape=1)\n\n\n\n\n\n\n\n\n\nNote that the order in which you specify the different geom matters! If geom_jitter() is used before geom_boxplot(), most of the individual data points will be hidden behind the box plots.\n\n\nCode\nggplot(data = data_wassen, \n       mapping = aes(x = threatened, \n                     y = NP_median))+\n  geom_jitter(width=0.1, \n              height=0, \n              shape=1)+\n  geom_boxplot(width=0.5)\n\n\n\n\n\n\n\n\n\n\n\nPersonalise your ggplot\nIn this section, we are going to personalise our plot by adding new layers and aesthetics.\nThe first thing we would like to do is to fill boxes with a specific colour for each group of species (threatened versus not threatened). To achieve this, we will have to provide additional information in aes(). We need to introduce two new arguments: colour (or color) and fill. As we want the two species categories to be displayed with a different color, we can use fill=threatened inside aes().\n\n\nCode\nggplot(data = data_wassen, \n       mapping = aes(x = threatened, \n                     y = NP_median,\n                     fill = threatened))+\n  geom_boxplot(width=0.5)+\n  geom_jitter(width=0.1, \n              height=0, \n              shape=1)\n\n\n\n\n\n\n\n\n\nWhat would happen if you use color=threatened instead of fill=threatened? What do you notice? Change the code and give it a try!\nBy default, when assigning a specific color to each species group, ggplot2 uses colors that are evenly spaced around a HCL (Hue Chroma Luminance) colour circle. However, this is not necessarily the best choice, especially for colour-blind people. The colour palettes provided by viridis() in the viridis R package have been specially designed to produce graphics that are pleasing to the eye, easier to read for colour-blind people and print well in greyscale. As shown in the figure below, eight colour palettes are available in viridis: magma (option A), inferno (option B), plasma (option C), viridis (option D, this is the default), cividis (option E), rocket (option F), mako (option G), and turbo (option H).\n\n\n\nColour palettes available in the viridis R package\n\n\nLet’s keep on personalising our plot by specifying that we want to use the viridis (option D) color palette to create the figure. This can be done with scale_colour_viridis() (scale_color_viridis() would work too) or scale_fill_viridis(). These functions have a couple of arguments to play with, including alpha (used to make colours more or less transparent), direction (to change the order of the colors in the scale), discrete (set to TRUE if you want to assign colours to a discrete scale such as groups), and option (to choose the colour palette you want to use). A list of colours available in R can also be found here.\n\n\nCode\nggplot(data = data_wassen, \n       mapping = aes(x = threatened, \n                     y = NP_median,\n                     fill = threatened))+\n  geom_boxplot(width=0.5)+\n  geom_jitter(width=0.1, \n              height=0, \n              shape=1)+\n  scale_fill_viridis(discrete = TRUE,\n                     option = \"D\",\n                     alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNow that we are happy with the colors used in our plot, we can keep on personalising the layout by adding new layers to our ggplot. Let’s do the following:\n\nRename the axis titles so that it is clear to the reader which variables are represented. If your variables have units, do not forget to indicate them in the axis titles. We can personalise axis titles using xlab() and ylab().\nggplot2 comes with a number of built-in themes that can be used to personalise how your plot should look like. By default, theme_grey() is used (this is the reason why our plot has a grey background). Other popular themes are theme_bw() (black and white theme), theme_minimal() (minimalistic theme), and theme_classic() (a classic theme with axis lines but no gridlines). Many more themes are available in ggplot2. We will use theme_bw() to personalise our plot.\nMake the individual points a bit more transparent using the alpha argument in geom_jitter().\nRemove the points labelled as outliers by geom_boxplot(). As individual data points are also displayed, this information is redundant. We can get rid of these points using outliers = FALSE in geom_boxplot().\nRemove the legend on the right side of the plot because this information is already provided by the x axis. This can be done using theme() and setting legend.position=\"none\". theme() is a particularly important function as it allows you to personalise many aspects of your plot, such as the color, size and orientation of the text along plot axes.\nAlong the vertical axis, we would like to have breaks at the following N:P values: 5, 10, 15, 20, 25, 30. You can do this using scale_y_continuous().\nChange the colour of the text along the horizontal and vertical axes to black. You can do this using theme() and element_text().\nAdd more space between axis titles and axis labels. You can do this in theme(), using the margin argument in element_text().\nRemove the grey grid lines in the background of the plot. This can be done in theme(), using panel.grid = element_blank().\n\n\n\nCode\nggplot(data = data_wassen, \n       mapping = aes(x = threatened, \n                     y = NP_median,\n                     fill = threatened))+\n  geom_boxplot(width=0.5,\n               outliers=FALSE)+\n  geom_jitter(width=0.1, \n              height=0, \n              shape=1,\n              alpha=0.6)+\n  scale_fill_viridis(discrete = TRUE,\n                     option = \"D\",\n                     alpha = 0.5)+\n  theme_bw()+\n  xlab(\"Are species threatened?\")+\n  ylab(\"Median N:P ratio\")+\n  scale_y_continuous(breaks=seq(from = 5,\n                                to = 30,\n                                by = 5))+\n  theme(legend.position = \"none\",\n        axis.text = element_text(colour=\"black\"),\n        axis.title.x = element_text(margin = margin(t = 10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10)),\n        panel.grid = element_blank()) #r means right\n\n\n\n\n\n\n\n\n\n\n\nCompute and display summary statistics\nWhen comparing groups to each other, we are often interested in comparing group means and their confidence limits (often represented as 95% confidence intervals). The function stat_summary() allows you to add this information to your ggplot. In stat_summary(), fun.data = \"mean_cl_boot\" can be used to calculate and display the average value and 95% confidence interval estimated by bootstrapping (which is a convenient way to estimate confidence intervals without assuming that the underlying data are normally distributed).\nTo improve readability, we want to plot these summary statistics on the right side of each box plot, using the same colour palette (tip: add aes() in stat_summary()). In stat_summary(), the position argument allows you to fine tune the position of plotted elements. The function position_nudge() allows you to shift the position of items along the vertical and horizontal axes by a small amount. In our case, shifting the position of summary statistics by 0.35 units to the right seems like a good idea.\n\n\nCode\nggplot(data = data_wassen, \n       mapping = aes(x = threatened, \n                     y = NP_median,\n                     fill = threatened))+\n  geom_boxplot(width=0.5,\n               outliers=FALSE)+\n  geom_jitter(width=0.1, \n              height=0, \n              shape=1,\n              alpha=0.6)+\n  stat_summary(fun.data=\"mean_cl_boot\",\n               aes(colour = threatened),\n               position = position_nudge(x=0.35))+\n  scale_fill_viridis(discrete = TRUE,\n                     option = \"D\",\n                     alpha = 0.5)+\n  scale_colour_viridis(discrete = TRUE,\n                       option = \"D\")+\n  theme_bw()+\n  xlab(\"Are species threatened?\")+\n  ylab(\"Median N:P ratio\")+\n  scale_y_continuous(breaks=seq(from = 5,\n                                to = 30,\n                                by = 5))+\n  theme(legend.position = \"none\",\n        axis.text = element_text(colour=\"black\"),\n        axis.title.x = element_text(margin = margin(t = 10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10)),\n        panel.grid = element_blank()) #r means right\n\n\n\n\n\n\n\n\n\n\n\nIntegrating the pipe\nRemember the pipe? We introduced it in the data wrangling tutorial. How can we rewrite the code used to produce our figure using the pipe? Give it a try!\n\n\nCode\ndata_wassen |&gt; \n  ggplot(mapping = aes(x = threatened, \n                       y = NP_median,\n                       fill = threatened))+\n  geom_boxplot(width=0.5,\n               outliers=FALSE)+\n  geom_jitter(width=0.1, \n              height=0, \n              shape=1,\n              alpha=0.6)+\n  stat_summary(fun.data=\"mean_cl_boot\",\n               aes(colour = threatened),\n               position = position_nudge(x=0.35))+\n  scale_fill_viridis(discrete = TRUE,\n                     option = \"D\",\n                     alpha = 0.5)+\n  scale_colour_viridis(discrete = TRUE,\n                       option = \"D\")+\n  theme_bw()+\n  xlab(\"Are species threatened?\")+\n  ylab(\"Median N:P ratio\")+\n  scale_y_continuous(breaks=seq(from = 5,\n                                to = 30,\n                                by = 5))+\n  theme(legend.position = \"none\",\n        axis.text = element_text(colour=\"black\"),\n        axis.title.x = element_text(margin = margin(t = 10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10)),\n        panel.grid = element_blank()) #r means right\n\n\n\n\nArrange multiple ggplots\nOften, we produce multiple plots that we want to put together into one figure as separate panels. But how can we easily do this? The answer is: by using ggarrange() in the ggpubr R package. It is easier to use ggarrange() if each individual plot is stored in a different object. Let’s do this and also create a second figure (very similar to the first) displaying median P values (in mg/g) instead of median N:P values. This time, use the size argument in geom_jitter() and stat_summary() to reduce the size of individual data points.\nOnce your two plots are created and stored in separate R objects, use ggarrange() to create one figure with two panels (1 row, 2 columns).\n\n\nCode\n#Create individual plots\n\nplot_NP &lt;- data_wassen |&gt; \n              ggplot(mapping = aes(x = threatened, \n                                   y = NP_median,\n                                   fill = threatened))+\n              geom_boxplot(width=0.5,\n                           outliers=FALSE)+\n              geom_jitter(width=0.1, \n                          height=0, \n                          shape=1,\n                          alpha=0.6,\n                          size=1)+\n              stat_summary(fun.data=\"mean_cl_boot\", \n                           aes(colour = threatened),\n                           position = position_nudge(x=0.35),\n                           size=0.4)+\n              scale_fill_viridis(discrete = TRUE,\n                                 option = \"D\",\n                                 alpha = 0.5)+\n              scale_colour_viridis(discrete = TRUE,\n                                   option = \"D\")+\n              theme_bw()+\n              xlab(\"Are species threatened?\")+\n              ylab(\"Median N:P ratio\")+\n              scale_y_continuous(breaks=seq(from = 5,\n                                            to = 30,\n                                            by = 5))+\n              theme(legend.position = \"none\",\n                    axis.text = element_text(colour=\"black\"),\n                    axis.title.x = element_text(margin = margin(t = 10)), #t means top\n                    axis.title.y = element_text(margin = margin(r=10)),\n                    panel.grid = element_blank()) #r means right\n\nplot_P &lt;- data_wassen |&gt; \n            ggplot(mapping = aes(x = threatened, \n                                 y = P_median,\n                                 fill = threatened))+\n            geom_boxplot(width=0.5,\n                         outliers=FALSE)+\n            geom_jitter(width=0.1, \n                        height=0, \n                        shape=1,\n                        alpha=0.6,\n                        size=1)+\n            stat_summary(fun.data=\"mean_cl_boot\",\n                         aes(colour = threatened),\n                         position = position_nudge(x=0.35),\n                         size=0.4)+\n            scale_fill_viridis(discrete = TRUE,\n                               option = \"D\",\n                               alpha = 0.5)+\n            scale_colour_viridis(discrete = TRUE,\n                                 option = \"D\")+\n            theme_bw()+\n            xlab(\"Are species threatened?\")+\n            ylab(\"Median P concentration (mg/g)\")+\n            scale_y_continuous(breaks=seq(from = 0,\n                                          to = 4,\n                                          by = 0.5))+\n            theme(legend.position = \"none\",\n                  axis.text = element_text(colour=\"black\"),\n                  axis.title.x = element_text(margin = margin(t = 10)), #t means top\n                  axis.title.y = element_text(margin = margin(r=10)),\n                  panel.grid = element_blank()) #r means right\n\n#Combine plots with ggarrange()\n\n(plot_final &lt;- ggarrange(plot_NP, #This is the first panel\n                         plot_P, #This is the second panel\n                         nrow = 1,\n                         ncol = 2,\n                         align = \"hv\", #Panels need to be horizontally and vertically aligned\n                         labels = \"auto\")) #Auto-generate lower-case labels for each subplot\n\n\n\n\n\n\n\n\n\n\n\nExport high-resolution figure\nOnce you are happy with your figure, you can export it as a high-resolution image file (png, tiff, jpg, etc.) for your paper or presentation using ggsave(). In ggsave(), important arguments are filename (the name of the image file, with file extension), plot (the name of your ggplot object), dpi (desired image resolution in dots per inch), width (image width), height (image height), and units (the units used for width and height). By default, the figure will be saved in your working directory (see getwd()).\n\n\nCode\nggsave(filename = \"Boxplot_Wassen.png\",\n       plot = plot_final,\n       dpi = 1000,\n       width = 15,\n       height=10,\n       units=\"cm\")"
  },
  {
    "objectID": "data_visualisation.html#exercise-2-creating-a-scatter-plot",
    "href": "data_visualisation.html#exercise-2-creating-a-scatter-plot",
    "title": "Tutorial 2: Data visualisation in R",
    "section": "Exercise 2: Creating a scatter plot",
    "text": "Exercise 2: Creating a scatter plot\nThe second exercise of this tutorial is to use the Wassen et al (2021) data to create a scatter plot displaying the relationship between median phosphorus (P) and potassium (K) concentrations. We also want our figure to show how this relationship differs between species groups (i.e., threatened or not threatened). Let’s have a look at how to do this with ggplot2.\n\nCreate a ggplot\nFirst, create a ggplot object displaying individual data points and clear axis titles (keep on using the pipe). Let’s not worry about the threat status of the species just yet.\n\n\nCode\ndata_wassen |&gt; \n  ggplot(aes(x = K_median,\n             y = P_median))+\n  geom_point(shape = 1)+\n  theme_bw()+\n  xlab(\"Median K concentration (mg/g)\")+\n  ylab(\"Median P concentration (mg/g)\")+\n  theme(axis.title.x = element_text(margin = margin(t=10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10))) #r means right\n\n\n\n\n\n\n\n\n\n\n\nPersonalise your ggplot\nIt is already a nice graph, but now we want to make it more informative by displaying the results separately for each group of species (threatened and non-threatened species). There are several ways of doing this. The first is to display the data points with a different shape (use shape in aes()) or a different colour (use colour or color in aes()). Let’s do both! Feel free to play around with different shapes (scale_shape_manual()) and colour palettes. In the previous example, we used scale_colour_viridis() to choose our viridis colour palette. This time, we are going to define the colour options by combining scale_color_manual() and viridis(). Give it a try!\n\n\nCode\ndata_wassen |&gt; \n  ggplot(aes(x = K_median,\n             y = P_median,\n             colour = threatened,\n             shape = threatened))+\n  geom_point()+\n  theme_bw()+\n  xlab(\"Median K concentration (mg/g)\")+\n  ylab(\"Median P concentration (mg/g)\")+\n  theme(axis.title.x = element_text(margin = margin(t=10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10)))+ #r means right\n  scale_shape_manual(values = c(16, 17))+\n  scale_colour_manual(values = viridis(n = 2, #Set number of colours\n                                       alpha = 0.5,\n                                       option = \"D\"))\n\n\n\n\n\n\n\n\n\n\n\nFaceting\nWe now have a graph showing the results separately for each group of species. However, it looks a little cluttered, with individual points overlapping each other. To improve readability, it would be preferable to present the data for threatened and non-threatened species in separate panels. This can be done with facet_wrap(). This function will divide our existing graph into subplots, each of which will display a subset of the data based on a categorical variable (threat status). Note that if you want to create subplots based on two variables in your dataset (a ‘row’ variable and a ‘column’ variable), using facet_grid() is more appropriate.\n\n\nCode\ndata_wassen |&gt; \n  ggplot(aes(x = K_median,\n             y = P_median,\n             colour = threatened,\n             shape = threatened))+\n  geom_point()+\n  theme_bw()+\n  xlab(\"Median K concentration (mg/g)\")+\n  ylab(\"Median P concentration (mg/g)\")+\n  theme(axis.title.x = element_text(margin = margin(t=10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10)))+ #r means right\n  scale_shape_manual(values = c(16, 17))+\n  scale_colour_manual(values = viridis(n = 2, #Set number of colours\n                                       alpha = 0.5,\n                                       option = \"D\"))+\n  facet_wrap(~threatened,\n             nrow=1,\n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nSimplify your plot\nWe are getting closer to the final version of our graph, but there are still a few points to be ironed out:\n\nThere is some redundancy in this figure because the threat status of plant species is represented by different colours, different dot shapes and in different panels. We should simplify things a little and avoid redundancy. Now that we have a specific panel for each category of species, it is no longer necessary to use a specific colour and shape for each category. This will also make it possible to do away with the legend on the right-hand side of the graph.\nIn each panel, we would like to add a trend line (‘smoother’) to better visualise the shape of the relationship between our two continuous variables. This can be done using a new geom: geom_smooth(). In geom_smooth(), the span argument allows you to control the amount of smoothing (a large number will produce a smoother line).\n\n\n\nCode\ndata_wassen |&gt; \n  ggplot(aes(x = K_median,\n             y = P_median))+\n  geom_point(shape=1)+\n  theme_bw()+\n  xlab(\"Median K concentration (mg/g)\")+\n  ylab(\"Median P concentration (mg/g)\")+\n  theme(axis.title.x = element_text(margin = margin(t=10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10)))+ #r means right\n  facet_wrap(~threatened,\n             nrow=1,\n             ncol=2)+\n  geom_smooth(span=1.5)\n\n\n\n\n\n\n\n\n\n\n\nFinalise your plot\nBefore exporting our graph as a high-resolution image file, we would like to do two things:\n\nColour the trend lines using the same colours as those used for our box plot (just to make it prettier and more consistent). Make sure to remove the legend using legend.position=\"none\".\nRename the title of each subplot to make it more informative. Instead of “No” and “Yes”, “Not threatened” and “Threatened” would be more informative. You can do this using replace() in mutate() (see tutorial on data wrangling).\n\nThat’s what we need to do!\n\n\nCode\ndata_wassen |&gt; \n  mutate(threatened = replace(threatened, threatened == \"No\", \"Non-threatened\")) |&gt;\n  mutate(threatened = replace(threatened, threatened == \"Yes\", \"Threatened\")) |&gt;\n  ggplot(aes(x = K_median,\n             y = P_median))+\n  geom_point(shape=1)+\n  theme_bw()+\n  xlab(\"Median K concentration (mg/g)\")+\n  ylab(\"Median P concentration (mg/g)\")+\n  theme(axis.title.x = element_text(margin = margin(t=10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10)),\n        legend.position=\"none\",\n        axis.text = element_text(colour = \"black\"))+ #r means right\n  facet_wrap(~threatened,\n             nrow=1,\n             ncol=2)+\n  geom_smooth(span=1.5,\n              aes(colour = threatened))+\n  scale_colour_viridis(option=\"D\",\n                       discrete = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nExport high-resolution figure\nUse ggsave() to export your plot as a high-resolution image.\n\n\nCode\nplot_final &lt;- data_wassen |&gt; \n  mutate(threatened = replace(threatened, threatened == \"No\", \"Non-threatened\")) |&gt;\n  mutate(threatened = replace(threatened, threatened == \"Yes\", \"Threatened\")) |&gt;\n  ggplot(aes(x = K_median,\n             y = P_median))+\n  geom_point(shape=1)+\n  theme_bw()+\n  xlab(\"Median K concentration (mg/g)\")+\n  ylab(\"Median P concentration (mg/g)\")+\n  theme(axis.title.x = element_text(margin = margin(t=10)), #t means top\n        axis.title.y = element_text(margin = margin(r=10)),\n        legend.position=\"none\",\n        axis.text = element_text(colour = \"black\"))+ #r means right\n  facet_wrap(~threatened,\n             nrow=1,\n             ncol=2)+\n  geom_smooth(span=1.5,\n              aes(colour = threatened))+\n  scale_colour_viridis(option=\"D\",\n                       discrete = TRUE)\n\nggsave(filename = \"Scatterplot_Wassen.png\",\n       plot = plot_final,\n       dpi = 1000,\n       width = 15,\n       height=10,\n       units=\"cm\")"
  },
  {
    "objectID": "data_visualisation.html#exercise-3-mapping-spatial-data",
    "href": "data_visualisation.html#exercise-3-mapping-spatial-data",
    "title": "Tutorial 2: Data visualisation in R",
    "section": "Exercise 3: Mapping spatial data",
    "text": "Exercise 3: Mapping spatial data\nCreating and extracting data from maps is very useful for ecological field research. This exercise will give you a brief introduction to mapping spatial data in R.\nFor this exercise, we will use the following files:\n\nA geopackage database file (GPKG) containing the spatial coordinates of field sites around Utrecht University (Locations_EFR.gpkg)\nA map of the highest ground water table (GWT_high.tif). This map is stored as a TIFF file (Tag Image File Format), which is a widely used file format for storing raster graphics images.\nA geopackage database file containing soil type information (Basisregistratie Ondergrond)\n\n\nLoad R packages to handle spatial data\nBefore starting this exercise, make sure that the sf, raster, and mapview packages are installed in your library.\n\n\nCode\nlibrary(sf)\nlibrary(raster)\nlibrary(mapview)\n\n\n\n\nImport geospatial data\nGPKG files can be read using st_read() in th sf R package. Use this function to load the locations of our field sites into R. We can then plot these locations using geom_sf() in ggplot2.\n\n\nCode\n#Read field site locations\nlocations_sf &lt;- st_read(dsn = \"Data_ggplot2/Locations_EFR.gpkg\",\n                        quiet = TRUE)\n\n#Create a ggplot\nggplot(data = locations_sf)+\n  geom_sf()+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nQuestion: Why do we not see a map in the background?\n\n\nAdd raster data (ground water)\nTo add information about the highest ground water table in the background of our map, we first need to read our raster data (GWT_high.tif) using raster(). This will create a RasterLayer object which will need to be converted into a data frame using as.data.frame() so that the data can be used in ggplot2. In our ggplot, use geom_raster() to add a raster layer to your graph.\nIn maps, the colour code used to display information is something to be considered carefully, so that your map is as informative and easy to understand as possible. In this ground water example, we would like areas with a high water table (i.e. low GWT_high values in our dataset) to appear in blue, while areas with a low water table (i.e. high GWT_high values in our dataset) would appear in red. Such a divergent colour gradient (low-medium-high) can be created using scale_colour_gradient2(). We will set the midpoint value to 2 (which means that values below 2 will appear blue, while values above 2 will appear red). We will also apply a pseudo-log transformation to improve the readability of our map. You can do this using the transform argument in scale_fill_gradient2(). As our raster data also contains missing values, we will use the na.value argument in scale_fill_gradient2() to make them transparent.\n\n\nCode\n#Create RasterLayer object\nGWT&lt;-raster(\"Data_ggplot2/GWT_high.tif\")\n\n#Convert to data frame\nGWT_df &lt;- as.data.frame(GWT, \n                        xy = TRUE)\n\n#Plot raster and location data\nggplot()+\n  geom_raster(data = GWT_df, \n              aes(x = x, \n                  y = y, \n                  fill = GWT_high))+\n  geom_sf(data = locations_sf)+\n  theme_minimal()+\n  scale_fill_gradient2(name = \"Ground\\nwater\\ntable\",\n                       low = \"blue\", \n                       mid = \"white\", \n                       high = \"red\",\n                       midpoint = 2,\n                       transform = \"pseudo_log\",\n                       na.value = \"transparent\")\n\n\n\n\n\n\n\n\n\nLet’s now look at how we can customise the legend for this ggplot. It would be interesting to edit the break values along the colour bar and provide an informative title for each axis. Give it a try!\n\n\nCode\n#Plot raster and location data\nggplot()+\n  geom_raster(data = GWT_df, \n              aes(x = x, \n                  y = y, \n                  fill = GWT_high))+\n  geom_sf(data = locations_sf)+\n  theme_minimal()+\n  scale_fill_gradient2(\"Ground\\nwater\\ntable\",\n                       low = \"blue\", \n                       mid = \"white\", \n                       high = \"red\",\n                       midpoint = 2,\n                       transform = \"pseudo_log\",\n                       na.value = \"transparent\",\n                       breaks = c(0, 2, 10, 40))+\n  ylab(\"Latitude\")+\n  xlab(\"Longitude\")+\n  theme(axis.title.x = element_text(margin = margin(t=10)),\n        axis.title.y = element_text(margin = margin(r=10)))\n\n\n\n\n\n\n\n\n\n\n\nAdd more geospatial information (soil type)\nLet’s create a new map with soil type information! Soil type data is stored as a geopackage (Soil_BRO.gpkg). You can read it using st_read().\n\n\nCode\nsoil_sf &lt;- st_read(dsn = \"Data_ggplot2/Soil_BRO.gpkg\",\n                   quiet = TRUE)\n\n\nIn soil_sf, the column ‘VEREENV’ contains soil type information. There are four soil type options in this column: DV (Peat), V (Peat), M (Clay), Z (Sand). Combine mutate() and replace() to rename elements in this column.\n\n\nCode\nsoil_sf &lt;- soil_sf |&gt; \n  mutate(VEREENV = replace(VEREENV, VEREENV %in% c(\"DV\", \"V\"), \"Peat\")) |&gt; \n  mutate(VEREENV = replace(VEREENV, VEREENV == \"M\", \"Clay\")) |&gt; \n  mutate(VEREENV = replace(VEREENV, VEREENV == \"Z\", \"Sand\"))\n\n\nNow let’s create our map of soil types and plot our site locations on top of it (use geom_sf() in both cases). Use scale_fill_manual() to assign colours to each soil type.\n\n\nCode\nggplot() +\n  geom_sf(data = soil_sf, \n          aes(fill = VEREENV),\n          alpha = 0.5) +\n  geom_sf(data = locations_sf) +\n  scale_fill_manual(name = \"Soil Type\",\n                    values = c(\"Peat\" = \"black\", \n                               \"Sand\" = \"yellow\", \n                               \"Clay\" = \"brown\"),\n                    na.value = \"transparent\") +\n  theme_minimal()+\n  ylab(\"Latitude\")+\n  xlab(\"Longitude\")+\n  theme(axis.title.x = element_text(margin = margin(t=10)),\n        axis.title.y = element_text(margin = margin(r=10)))\n\n\n\n\n\n\n\n\n\n\n\nAdding a base map\nYour maps look great, but they are all missing a base map. This can be done using mapView() in mapview. Have a look at the code below to see how to add a base map to our soil type map.\n\nmapviewOptions(fgb = FALSE)\n\nmy_map &lt;- mapView(x = locations_sf,\n                  map.types = c(\"OpenStreetMap\"))+\n          mapView(x = soil_sf, \n                  zcol = \"VEREENV\",\n                  col.regions = c(\"brown\", \n                                  \"transparent\", \n                                  \"black\", \n                                  \"yellow\"), \n                  alpha.regions = 0.4,\n                  stroke = FALSE, \n                  map.types = c(\"OpenStreetMap\"))\n\nmy_map\n\n\n\n\n\n\nYou can then use mapshot() to export your map as an image file.\n\nmapshot(my_map,\n        file = \"my_map.png\", \n        scalebar = TRUE)"
  },
  {
    "objectID": "data_visualisation.html#take-home-message",
    "href": "data_visualisation.html#take-home-message",
    "title": "Tutorial 2: Data visualisation in R",
    "section": "Take-home message",
    "text": "Take-home message\nGood data visualisation is essential for data exploration and analysis, as well as for presenting and publishing the results of your research. The aim of this tutorial was to give you a brief overview of the main functions available in ggplot2 for producing high-quality, clear and informative graphs. Of course, this tutorial is far from exhaustive and many other tools are available. We encourage you to continue learning and discovering new functions available in ggplot2 by using the popular books R for Data Science and ggplot2: Elegant Graphics for Data Analysis."
  },
  {
    "objectID": "R_basics.html#installing-r-packages",
    "href": "R_basics.html#installing-r-packages",
    "title": "R basics",
    "section": "",
    "text": "An R package is like a toolbox, except that instead of containing tools, it contains functions for performing specific tasks such as filtering data or fitting a statistical model. Most of the R packages you will need for these tutorials are freely available from CRAN (The Comprehensive R Archive Network) or GitHub. You can install CRAN R packages using install.packages().\n\n#Install an R package to import data from Excel files\ninstall.packages(\"readxl\")\n\nIf you want to install an R package stored in a GitHub repository, use install_github() in the devtools R package.\n\n#Install tbi R package to calculate Tea Bag Index paramaters\ndevtools::install_github(\"BenjaminDelory/tbi/tbi\")"
  },
  {
    "objectID": "about.html#how-to-use-our-tutorials-to-learn-r",
    "href": "about.html#how-to-use-our-tutorials-to-learn-r",
    "title": "Welcome to the tutorials of our Ecological field research course!",
    "section": "How to use our tutorials to learn R",
    "text": "How to use our tutorials to learn R\nEach tutorial is designed as a step-by-step guide to performing specific tasks that are very commonly used in data science. As well as providing the R code, we take care to explain what we want to do and what each function does. By default, the R code is hidden from you, so you can try writing the R code yourself (it is the best way to learn R). We always tell you which function you need to use to perform each task. Use the R help pages to find out more about these functions. If you get stuck and want to see how the R code should be written, just click on “Show me the R code”. If you have never used R before and want to see the whole R code from the beginning, you can click on “Show All Code” in the Code menu at the top right of each tutorial page."
  },
  {
    "objectID": "quantifying_biodiversity.html#a-hypothetical-metacommunity",
    "href": "quantifying_biodiversity.html#a-hypothetical-metacommunity",
    "title": "Tutorial 3: Quantifying taxonomic diversity",
    "section": "A hypothetical metacommunity",
    "text": "A hypothetical metacommunity\nThe first step is to create some data to work with. You will do this by sampling wooden meeples (which are small board game pieces) to generate a site by species abundance matrix. Our hypothetical metacommunity consists of six paper bags (which represent different sampling sites), each containing 30 meeples (which represent different individuals living at a site). Meeples of the same colour belong to the same species. We will not give you any information about species diversity and composition at each site. You will have to obtain this information yourself, by repeatedly sampling each site without looking inside the bags.\nOur species pool consists of 10 different species, each represented by a different colour. This is a small species pool, but it is enough to meet the objectives of this tutorial."
  },
  {
    "objectID": "quantifying_biodiversity.html#sampling-procedure",
    "href": "quantifying_biodiversity.html#sampling-procedure",
    "title": "Tutorial 3: Quantifying taxonomic diversity",
    "section": "Sampling procedure",
    "text": "Sampling procedure\nThe aim of this exercise is to simulate a survey carried out to characterise the taxonomic diversity of six sites making up our metacommunity. Each site will be sampled multiple times to simulate surveys in a number of quadrats/locations at each site.\nYou can start generating biodiversity data using the following procedure:\n\nDivide into 6 sub-groups. Each sub-group should consist of 4 to 5 students.\nEach sub-group takes one bag (each bag is labelled with a number from 1 to 6). The bags have a different composition and contain a different number of species.\nOne member of each a sub-group carefully mixes the content of the bag and randomly samples 6 individuals from the bag (this represents 20% of the individuals in a bag). Try not to look inside the bag to avoid any sampling bias.\nWrite down your observations in an Excel sheet (site as rows, species as columns).\nOnce your observations have been recorded, put your sample back into the bag and give the bag to another person in your group. Then, repeat the previous steps until you have at least five replicates. In your data sheet, report your observations independently for each replicate (i.e., each row in your data is a replicate within a site).\nOnce you have all the replicates needed for your bag, switch bags with another group and repeat the previous steps. Do this until you have five replicates for each bag.\nMake sure that your data are formatted properly."
  },
  {
    "objectID": "quantifying_biodiversity.html#exercises",
    "href": "quantifying_biodiversity.html#exercises",
    "title": "Tutorial 3: Quantifying taxonomic diversity",
    "section": "Exercises",
    "text": "Exercises\n\nLoad R packages\nLoad tidyverse, knitr, and viridis.\n\n\nCode\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(viridis)\n\n\n\n\nExercise 1: Calculate alpha, beta and gamma diversity\nAlpha diversity (within-habitat diversity) is the average number of species across sites in our hypothetical metacommunity. Gamma diversity (regional diversity) is the total number of species present in our hypothetical metacommunity. Beta diversity (between-habitat diversity differentiation) is gamma diversity divided by alpha diversity.\nUsing the data collected earlier, calculate alpha, beta and gamma diversity in our hypothetical metacommunity using R. First, import your data into R. Then, use knowledge from tutorials 1 and 2 to write R code to calculate alpha, beta, and gamma diversity in our metacommunity.\n\nExample datasetSolution (gamma)Solution (alpha)Solution (beta)\n\n\n\n\nCode\nkable(head(data, n=10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBag\nReplicate\nRed\nOrange\nYellow\nGreen\nBlue\nPurple\nPink\nWhite\nGrey\nBlack\n\n\n\n\n1\n1\n1\n0\n0\n1\n2\n1\n1\n0\n0\n0\n\n\n1\n2\n0\n1\n0\n1\n1\n0\n1\n1\n0\n1\n\n\n1\n3\n0\n1\n0\n0\n0\n0\n1\n0\n3\n1\n\n\n1\n4\n1\n0\n3\n0\n0\n0\n0\n0\n1\n1\n\n\n1\n5\n0\n1\n1\n1\n1\n1\n1\n0\n0\n0\n\n\n2\n1\n0\n0\n0\n5\n0\n1\n0\n0\n0\n0\n\n\n2\n2\n0\n0\n0\n4\n0\n2\n0\n0\n0\n0\n\n\n2\n3\n0\n0\n0\n2\n0\n4\n0\n0\n0\n0\n\n\n2\n4\n0\n0\n0\n5\n0\n1\n0\n0\n0\n0\n\n\n2\n5\n0\n0\n0\n2\n0\n4\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n\nCode\ngamma &lt;- as.numeric(data |&gt; \n                      pivot_longer(Red:Black,\n                                   names_to = \"Species\",\n                                   values_to = \"Abundance\") |&gt; \n                      group_by(Species) |&gt; \n                      summarise(Abundance = sum(Abundance)) |&gt; \n                      summarise(Gamma = sum(Abundance &gt; 0)))\n\n\nGamma diversity: 10\n\n\n\n\nCode\nalpha &lt;- round(as.numeric(data |&gt; \n                            pivot_longer(Red:Black,\n                                         names_to = \"Species\",\n                                         values_to = \"Abundance\") |&gt; \n                            group_by(Bag, Species) |&gt; \n                            summarise(Abundance = sum(Abundance)) |&gt; \n                            group_by(Bag) |&gt;\n                            summarise(Alpha = sum(Abundance &gt; 0)) |&gt; \n                            summarise(Alpha = mean(Alpha))), 1)\n\n\nAlpha diversity: 5.8\n\n\n\n\nCode\nbeta &lt;- round(gamma/alpha, 1)\n\n\nBeta diversity: 1.7\n\n\n\n\n\nExercise 2: Calculate the average species richness at each site\nUse what you learned in previous tutorials to calculate the average number of species at each site.\n\nSolution (code)Solution (table)\n\n\n\n\nCode\ntable &lt;- data |&gt; \n          pivot_longer(Red:Black,\n                       names_to = \"Species\",\n                       values_to = \"Abundance\") |&gt; \n          group_by(Bag, Replicate) |&gt; \n          summarise(Richness = sum(Abundance&gt;0)) |&gt; \n          group_by(Bag) |&gt; \n          summarise(Avg_richness = round(mean(Richness), 1))\n\n\n\n\n\n\nCode\nkable(table)\n\n\n\n\n\nBag\nAvg_richness\n\n\n\n\n1\n5.0\n\n\n2\n2.0\n\n\n3\n4.8\n\n\n4\n3.6\n\n\n5\n3.0\n\n\n6\n2.4\n\n\n\n\n\n\n\n\n\n\nExercise 3: Calculate the effective number of species (Hill numbers)\nIn a community consisting of n species, the Hill number (or effective number of species) of order q can be calculated using Equation 1 (\\(q \\geq 0\\), \\(q\\neq1\\)) and Equation 2 (\\(q=1\\)), where pi is the relative abundance of species i in the community (\\(p_i \\in [0,1]\\)).\n\\[ ^qD = (\\sum_{i=1}^{n}p_i^q)^{\\frac{1}{1-q}}   \\tag{1}\\]\n\\[ ^1D=exp(-\\sum_{i=1}^{n}p_i\\log p_i)  \\tag{2}\\]\nUse Equation 1 and Equation 2 to calculate the effective number of species of order 0 (species richness), 1 (Hill-Shannon, the exponential of Shannon’s entropy) and 2 (Hill-Simpson, the inverse of Simpson’s concentration index) at each site of our hypothetical metacommunity. Plot your results in a figure with 6 panels (one panel for each site). For each site, plot the effective number of species as a function of q (this is called a diversity profile plot). Plot separate lines (using geom_line()) for each replicate (the group argument in aes() will be useful here).\nWhat do you observe? What can you conclude about the taxonomic diversity at each site?\n\nSolution (code)Solution (plot)\n\n\n\n\nCode\nplot &lt;- data |&gt; \n          mutate(Total = Red+Orange+Yellow+Green+Blue+Purple+Pink+White+Grey+Black) |&gt; \n          mutate(Red=Red/Total,\n                 Orange=Orange/Total,\n                 Yellow=Yellow/Total,\n                 Green=Green/Total,\n                 Blue=Blue/Total,\n                 Purple=Purple/Total,\n                 Pink=Pink/Total,\n                 White=White/Total,\n                 Grey=Grey/Total,\n                 Black=Black/Total) |&gt; \n          pivot_longer(Red:Black,\n                       names_to = \"Species\",\n                       values_to = \"Abundance\") |&gt; \n          filter(Abundance!=0) |&gt; \n          group_by(Bag, Replicate) |&gt; \n          summarise(q0=sum(Abundance^0)^(1/(1-0)),\n                    q1=exp(-sum(Abundance*log(Abundance))),\n                    q2=sum(Abundance^2)^(1/(1-2))) |&gt; \n          pivot_longer(q0:q2,\n                       names_to = \"q\",\n                       names_prefix = \"q\",\n                       names_transform = as.numeric,\n                       values_to = \"diversity\") |&gt;\n          mutate(Bag=paste(\"Bag \", Bag, sep=\"\"),\n                 Replicate=as.factor(Replicate)) |&gt; \n          ggplot(aes(x = q,\n                     y = diversity,\n                     group = Replicate,\n                     colour=Replicate))+\n            geom_line()+\n            geom_point(shape=16)+\n            facet_wrap(~Bag)+\n            theme_bw()+\n            xlab(\"Diversity order (q)\")+\n            ylab(\"Effective number of species (D)\")+\n            scale_colour_viridis(discrete=TRUE)+\n            theme(axis.title.x = element_text(margin = margin(t=10)),\n                  axis.title.y = element_text(margin = margin(r=10)),\n                  axis.text = element_text(colour=\"black\"),\n                  panel.grid.minor = element_blank())+\n            scale_x_continuous(breaks=c(0,1,2),\n                               limits = c(0,2))+\n            scale_y_continuous(breaks=seq(from = 0,\n                                          to = 10,\n                                          by = 2),\n                               limits=c(0,10))\n\n\n\n\n\n\nCode\nplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 4: The importance of sampling effort for estimating taxonomic diversity\nIn the first part of this tutorial, we estimated taxonomic diversity by randomly sampling 20% of the individuals living at each site. But what would happen if we increased the sampling effort and sampled 50% of the individuals present at each site? Using the same sampling procedure as above, create a new data set by randomly selecting 15 individuals per site and make a new version of the figure you created for the third exercise.\nWhat do you notice? What can you conclude about the importance of sampling effort in accurately quantifying biodiversity? In what situations does increasing the sampling effort make it possible to obtain better biodiversity estimates?\n\nSolution (code)Solution (plot)\n\n\n\n\nCode\nplot &lt;- data |&gt; \n          mutate(Total = Red+Orange+Yellow+Green+Blue+Purple+Pink+White+Grey+Black) |&gt; \n          mutate(Red=Red/Total,\n                 Orange=Orange/Total,\n                 Yellow=Yellow/Total,\n                 Green=Green/Total,\n                 Blue=Blue/Total,\n                 Purple=Purple/Total,\n                 Pink=Pink/Total,\n                 White=White/Total,\n                 Grey=Grey/Total,\n                 Black=Black/Total) |&gt; \n          pivot_longer(Red:Black,\n                       names_to = \"Species\",\n                       values_to = \"Abundance\") |&gt; \n          filter(Abundance!=0) |&gt; \n          group_by(Bag, Replicate) |&gt; \n          summarise(q0=sum(Abundance^0)^(1/(1-0)),\n                    q1=exp(-sum(Abundance*log(Abundance))),\n                    q2=sum(Abundance^2)^(1/(1-2))) |&gt; \n          pivot_longer(q0:q2,\n                       names_to = \"q\",\n                       names_prefix = \"q\",\n                       names_transform = as.numeric,\n                       values_to = \"diversity\") |&gt;\n          mutate(Bag=paste(\"Bag \", Bag, sep=\"\"),\n                 Replicate=as.factor(Replicate)) |&gt; \n          ggplot(aes(x = q,\n                     y = diversity,\n                     group = Replicate,\n                     colour=Replicate))+\n            geom_line()+\n            geom_point(shape=16)+\n            facet_wrap(~Bag)+\n            theme_bw()+\n            xlab(\"Diversity order (q)\")+\n            ylab(\"Effective number of species (D)\")+\n            scale_colour_viridis(discrete=TRUE)+\n            theme(axis.title.x = element_text(margin = margin(t=10)),\n                  axis.title.y = element_text(margin = margin(r=10)),\n                  axis.text = element_text(colour=\"black\"),\n                  panel.grid.minor = element_blank())+\n            scale_x_continuous(breaks=c(0,1,2),\n                               limits = c(0,2))+\n            scale_y_continuous(breaks=seq(from = 0,\n                                          to = 10,\n                                          by = 2),\n                               limits=c(0,10))\n\n\n\n\n\n\nCode\nplot"
  },
  {
    "objectID": "quantifying_biodiversity.html#suggested-further-reading",
    "href": "quantifying_biodiversity.html#suggested-further-reading",
    "title": "Tutorial 3: Quantifying taxonomic diversity",
    "section": "Suggested further reading",
    "text": "Suggested further reading\nOur tutorial can’t cover everything, and there’s still a lot to learn about quantifying biodiversity! If you are interested, take a look at these excellent papers.\nChao A, Chiu C-H, Jost L. 2014. Unifying Species Diversity, Phylogenetic Diversity, Functional Diversity, and Related Similarity and Differentiation Measures Through Hill Numbers. Annual review of ecology, evolution, and systematics 45: 297–324.\nHill MO. 1973. Diversity and evenness: A unifying notation and its consequences. Ecology 54: 427–432.\nRoswell M, Dushoff J, Winfree R. 2021. A conceptual guide to measuring species diversity. Oikos 130: 321–338.\nWhittaker RH. 1960. Vegetation of the siskiyou mountains, Oregon and California. Ecological monographs 30: 279–338."
  },
  {
    "objectID": "data_exploration.html#load-r-packages",
    "href": "data_exploration.html#load-r-packages",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Load R packages",
    "text": "Load R packages\nLoad tidyverse, knitr, and corrplot.\n\n\nCode\nlibrary(tidyverse) \nlibrary(knitr) \nlibrary(corrplot)"
  },
  {
    "objectID": "data_exploration.html#step-1-are-there-outliers",
    "href": "data_exploration.html#step-1-are-there-outliers",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Step 1: Are there outliers?",
    "text": "Step 1: Are there outliers?\nZuur et al (2010) defined an outlier as “an observation that has a relatively large or small value compared to the majority of observations”. There is no hard rule as to what “relatively” means in this context, but observations that qualify as outliers usually “stand out” and look very different from all other data points, perhaps due to measurement errors. Two types of graph are well suited to outlier detection: box plots and Cleveland plots.\n\nBox plots\nLet’s start by loading the “SparrowsElphick.txt” dataset into R (use read_delim()). Have a look at how this dataset is structured using View() or head(). This dataset contains observations measured on 1295 sparrows. For the moment, we will look at just one response variable: wing length (expressed in millimeters). This variable is named “wingcrd” in the sparrows dataset.\n\n\nCode\n#Load data into R\nsparrows &lt;- read_delim(\"Data_Zuur_et_al_2010/SparrowsElphick.txt\")\n\n#View data\nkable(head(sparrows, n=10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwingcrd\nflatwing\ntarsus\nhead\nculmen\nnalospi\nwt\nbandstat\ninitials\nYear\nMonth\nDay\nLocation\nSpeciesCode\nSex\nAge\n\n\n\n\n59.0\n60.0\n22.3\n31.2\n12.3\n13.0\n9.5\n1\n2\n2002\n9\n19\n4\n1\n0\n2\n\n\n54.0\n55.0\n20.3\n28.3\n10.8\n7.8\n12.2\n1\n2\n2002\n10\n4\n4\n3\n0\n2\n\n\n53.0\n54.0\n21.6\n30.2\n12.5\n8.5\n13.8\n1\n2\n2002\n10\n4\n4\n3\n0\n2\n\n\n55.0\n56.0\n19.7\n30.4\n12.1\n8.3\n13.8\n1\n8\n2002\n7\n30\n9\n1\n0\n2\n\n\n55.0\n56.0\n20.3\n28.7\n11.2\n8.0\n14.1\n1\n3\n2002\n10\n4\n4\n3\n0\n2\n\n\n53.5\n54.5\n20.8\n30.6\n12.8\n8.6\n14.8\n1\n7\n2004\n8\n2\n1\n1\n0\n2\n\n\n55.5\n57.0\n20.3\n29.5\n11.5\n8.5\n15.0\n1\n3\n2002\n10\n4\n4\n3\n0\n2\n\n\n55.0\n56.0\n20.9\n30.0\n11.7\n8.5\n15.0\n1\n3\n2002\n10\n2\n5\n3\n0\n1\n\n\n54.0\n56.0\n21.4\n29.8\n11.0\n8.7\n15.1\n1\n1\n2002\n10\n21\n7\n3\n0\n2\n\n\n55.0\n56.0\n20.4\n29.8\n11.2\n8.1\n15.1\n1\n2\n2002\n10\n2\n5\n3\n0\n2\n\n\n\n\n\nNow use ggplot2 to create a box plot using wing length as a response variable.\n\n\nCode\nggplot(sparrows,\n       aes(y=wingcrd))+\n  geom_boxplot()+\n  theme_bw()+\n  xlab(\"\")+\n  ylab(\"Wing length (mm)\")+\n  theme(axis.text = element_text(colour = \"black\"),\n        axis.text.x = element_blank(),\n        axis.title.y = element_text(margin = margin(r=10)))\n\n\n\n\n\n\n\n\n\nSuch a box plot displays descriptive statistics on your data: the median value (represented by a thick horizontal line), as well as the 25% and 75% quartiles (lower and upper limits of the box). The difference between the 75% and 25% quartiles is called the interquartile range (the height of the box). Exactly half the observations in your data fall within this interquartile range. By default, the box plot whiskers are as long as 1.5 times the interquartile range. Observations beyond the whiskers are represented by individual dots and are possible outliers (i.e. observations whose values are rather large or small compared to the rest of the data) which will need to be checked to ensure that they are not measurement errors. It would be a mistake to remove all these observations without first checking them to make sure they are measurement errors.\n\n\nCleveland plots\nA Cleveland plot is a method of choice for detecting outliers. To create a Cleveland plot, you just need to plot your variable of interest on the horizontal axis and the row number of your observations on the vertical axis. You can easily add a new column with the row number to your data using add_column().\n\n\nCode\nsparrows |&gt; \n  add_column(row_number=1:nrow(sparrows),\n             .before=\"wingcrd\") |&gt; \n  ggplot(aes(x=wingcrd,\n             y=row_number))+\n    geom_point(shape=1)+\n    theme_bw()+\n    ylab(\"Row number\")+\n    xlab(\"Wing length (mm)\")+\n    theme(axis.text = element_text(colour = \"black\"),\n          axis.title.y = element_text(margin = margin(r=10)),\n          axis.title.x = element_text(margin = margin(t=10)))\n\n\n\n\n\n\n\n\n\nWhen looking closely at this Cleveland plot, none of the observations on the left and right sides of the graph seem to stand out. All the wing length values seem reasonable, with no particularly small or large values to check.\nLet’s continue our exploration of the sparrows data by looking at other response variables: Culmen length (culmen), Nalospi to bill tip (nalospi), Weight (wt), Wing length (wingcrd), Tarsus length (tarsus), and Head length (head). Before plotting, sort the sparrow observations by increasing weight values (to be consistent with Zuur et al, 2010). Then, create a figure with 6 panels, each displaying a Cleveland plot for each of these morphometric variables. You can do this using facet_wrap(). In facet_wrap(), set the scales argument to “free_x” to allow for different horizontal axis scales. Check what would happen if you keep scales = \"fixed\" (which is the default).\n\n\nCode\nsparrows |&gt; \n  select(culmen, nalospi, wt, wingcrd, tarsus, head) |&gt; \n  arrange(wt) |&gt; \n  add_column(row_number=1:nrow(sparrows),\n             .before=\"culmen\") |&gt; \n  pivot_longer(culmen:head,\n               names_to=\"variable\",\n               values_to = \"value\") |&gt;\n  mutate(variable = replace(variable, variable == \"culmen\", \"Culmen length\"),\n         variable = replace(variable, variable == \"nalospi\", \"Nalospi to bill tip\"),\n         variable = replace(variable, variable == \"wt\", \"Weight\"),\n         variable = replace(variable, variable == \"wingcrd\", \"Wing length\"),\n         variable = replace(variable, variable == \"tarsus\", \"Tarsus length\"),\n         variable = replace(variable, variable == \"head\", \"Head length\")) |&gt; \n  ggplot(aes(x=value,\n             y=row_number))+\n    geom_point(shape=1)+\n    theme_bw()+\n    ylab(\"Row number\")+\n    xlab(\"Value\")+\n    theme(axis.text = element_text(colour = \"black\"),\n          axis.title.y = element_text(margin = margin(r=10)),\n          axis.title.x = element_text(margin = margin(t=10)))+\n    facet_wrap(~variable, scales = \"free_x\")\n\n\n\n\n\n\n\n\n\nLooking at this figure, we quickly notice that two head length values appear smaller than the others, while one tarsus length value appears larger than the others. These observations seem to qualify as outliers and should be checked. It is unlikely that such extreme values could have occurred by chance. If these observations are indeed measurement (or observation) errors, they should be dropped before continuing the analysis. If you decide to remove observations from your dataset, always clearly document this decision in your code and give reasons for it. This is where having a detailed field notebook or experimental log comes in handy."
  },
  {
    "objectID": "data_exploration.html#step-2-do-we-have-homogeneity-of-variance",
    "href": "data_exploration.html#step-2-do-we-have-homogeneity-of-variance",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Step 2: Do we have homogeneity of variance?",
    "text": "Step 2: Do we have homogeneity of variance?\nHomogeneity of variance is an important assumption of regression-related techniques such as ANalysis Of VAriance (ANOVA). One way to check for this is to use a conditional box plot. Let’s create one using a new set of bird data. The “Godwits.txt” data file contains observations for 9 variables measured on 330 Hudsonian godwits (Limosa haemastica).\n\n\nCode\n#Load data into R\ngodwits &lt;- read_delim(\"Data_Zuur_et_al_2010/Godwits.txt\",\n                      col_select = 1:9)\n\n#View data\nkable(head(godwits, n=10))\n\n\n\n\n\nRECORD\nDAY\nMONTH\nYEAR\nLOCATION\nAGE\nSEX\nPERIOD\nmgconsumed\n\n\n\n\n1\n5\n1\n97\n0\n0\n0\n0\n0.07\n\n\n2\n5\n1\n97\n0\n0\n0\n0\n0.16\n\n\n3\n5\n1\n97\n0\n0\n0\n0\n0.25\n\n\n4\n5\n1\n97\n0\n0\n0\n0\n0.07\n\n\n5\n5\n1\n97\n0\n0\n0\n0\n0.14\n\n\n6\n5\n1\n97\n0\n0\n0\n0\n0.26\n\n\n7\n5\n1\n97\n0\n0\n0\n0\n0.10\n\n\n8\n6\n2\n97\n0\n0\n0\n1\n0.21\n\n\n9\n6\n2\n97\n1\n0\n0\n1\n0.11\n\n\n10\n6\n2\n97\n0\n0\n0\n1\n0.09\n\n\n\n\n\nWe would be interested to test if the mean food intake rate (mgconsumed) of godwits changes between sexes (variable: SEX; either female or male) and time periods (variable: PERIOD; either summer, pre-migration, or winter). Before fitting a linear model to our data, we first need to check if all groups have similar variance. Use ggplot2 to create a conditional box plot visualising this. Pay attention to the following:\n\nSEX is a variable with 3 levels: 0 (no information), 1 (female) and 2 (male). Filter out observations with SEX=0 and replace 1’s by “Female” and 2’s by “Male”.\nPERIOD is a variable with 3 levels: 0 (Summer), 1 (Pre-migration) and 2 (Winter). Replace 0’s by “Summer”, 1’s by “Pre-migration” and 2’s by “Winter”.\n\n\n\nCode\ngodwits |&gt; \n  filter(SEX != 0) |&gt; \n  mutate(SEX = replace(SEX, SEX == 1, \"Female\"),\n         SEX = replace(SEX, SEX == 2, \"Male\"),\n         PERIOD = replace(PERIOD, PERIOD == 0, \"Summer\"),\n         PERIOD = replace(PERIOD, PERIOD == 1, \"Pre-migration\"),\n         PERIOD = replace(PERIOD, PERIOD == 2, \"Winter\")) |&gt; \n  ggplot(aes(x=PERIOD,\n             y=mgconsumed))+\n    geom_boxplot(width=0.4)+\n    theme_bw()+\n    ylab(\"Food intake rate\")+\n    xlab(\"Migration period\")+\n    theme(axis.text = element_text(colour = \"black\"),\n          axis.title.y = element_text(margin = margin(r=10)),\n          axis.title.x = element_text(margin = margin(t=10)))+\n    facet_wrap(~SEX)\n\n\n\n\n\n\n\n\n\nFrom this figure, what can you conclude about (1) the variation in food intake rate between sexes (across migration periods), (2) the variation in food intake rate between migration periods (across sexes), and (3) the variation in food intake rate between migration periods within each sex category?"
  },
  {
    "objectID": "data_exploration.html#step-3-are-the-data-normally-distributed",
    "href": "data_exploration.html#step-3-are-the-data-normally-distributed",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Step 3: Are the data normally distributed?",
    "text": "Step 3: Are the data normally distributed?\nAnother important assumption of linear regression is that data are normally distributed (i.e., data follow a normal distribution). But what data are we talking about? Can I simply verify this assumption by creating a histogram from ALL the values of the response variable I am interested in? The answer is: no, you can’t. Why not? Because the assumption to be verifed is that the data within each group are normally distributed. This underlines the importance of having a sufficient number of replicates at each level of your covariate, which should have been carefully considered when designing the study. You can check whether your data are normally distributed by making histograms of the raw data for each group.\nLet’s go back to the sparrows dataset. Use ggplot2 to create a histogram of the weight (wt) of sparrows in June, July, and August. Use geom_histogram() to do this. What patterns do you observe?\n\n\nCode\nsparrows |&gt; \n  filter(Month &gt;= 6 & Month &lt;= 8) |&gt; \n  mutate(Month=replace(Month, Month==6, \"June\"),\n         Month=replace(Month, Month==7, \"July\"),\n         Month=replace(Month, Month==8, \"August\")) |&gt; \n  mutate(Month=factor(Month, levels=c(\"June\",\n                                      \"July\", \n                                      \"August\"))) |&gt; #Reorder factor levels to reorder facets\n  ggplot(aes(x=wt))+\n    geom_histogram()+\n    theme_bw()+\n    ylab(\"Frequency\")+\n    xlab(\"Weight (g)\")+\n    theme(axis.text = element_text(colour = \"black\"),\n          axis.title.y = element_text(margin = margin(r=10)),\n          axis.title.x = element_text(margin = margin(t=10)))+\n    facet_wrap(~Month)"
  },
  {
    "objectID": "data_exploration.html#step-4-are-there-lots-of-zeros-in-the-data",
    "href": "data_exploration.html#step-4-are-there-lots-of-zeros-in-the-data",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Step 4: Are there lots of zeros in the data?",
    "text": "Step 4: Are there lots of zeros in the data?\nWhen modelling the relationship between a response variable whose value is often zero and other covariates, the use of zero-inflated models is often an option. But how can we visualise if our response variable of interest is often equal to zero? Sounds like you need to create a frequency plot. You can do this using geom_bar(). In geom_bar(), use stat=\"count\".\nTo create a frequency plot, we will use another dataset (“ElphickBirdData.txt”). This dataset contains 2035 observations of the number of waterbirds (AQBIRDS) observed in flooded rice fields.\n\n\nCode\n#Load data into R\nwaterbirds &lt;- read_delim(\"Data_Zuur_et_al_2010/ElphickBirdData.txt\")\n\n#View data\nkable(head(waterbirds, n=10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCENSUS\nYEAR\nDATE…3\nData\nDATE…5\nSITE\nBLOCK\nFIELD\nFIELDNEW\nCHECK\nAREA\nSPTREAT\nDEPTH\nTUSW\nGWFG\nWHGO\nCAGO\nMALL\nGADW\nGWTE\nCITE\nUNTE\nAMWI\nNOPI\nNOSH\nRIDU\nCANV\nBUFF\nWODU\nRUDU\nEUWI\nUNDU\nPBGB\nSORA\nCOOT\nCOMO\nAMBI\nBCNH\nGBHE\nSNEG\nGREG\nWFIB\nSACR\nAMAV\nBNST\nBBPL\nKILL\nLBCU\nGRYE\nLEYE\nLBDO\nSNIP\nDUNL\nWESA\nLESA\nPEEP\nRUFF\nUNSH\nRBGU\nHEGU\nCAGU\nGUSP\nWATERFWL\nLLWADERS\nSHOREBDS\nAQBIRDS\n\n\n\n\n6\n2\n24-Jan-95\n13\n754\n4mile\n1\n6\n106\n0\n3.38\nrlfld\n83.9\n0\n0\n0\n0\n0.0000000\n0.0000000\n0\n0.0000000\n0\n0.591716\n0.0000000\n0.0000000\n0\n0\n0\n0.0000000\n0.0000000\n0\n0\n0.0000000\n0\n0.000000\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.5917160\n0.0000000\n0\n0.591716\n\n\n11\n2\n13-Mar-95\n15\n802\n4mile\n1\n6\n106\n0\n3.38\nrlfld\n73.9\n0\n0\n0\n0\n1.1834320\n0.0000000\n0\n0.0000000\n0\n0.000000\n0.0000000\n0.0000000\n0\n0\n0\n0.0000000\n0.0000000\n0\n0\n0.0000000\n0\n0.000000\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1.1834320\n0.0000000\n0\n1.183432\n\n\n6\n2\n24-Jan-95\n13\n754\n4mile\n1\n5\n105\n0\n7.66\nrlfld\n54.1\n0\n0\n0\n0\n1.9582245\n0.0000000\n0\n0.0000000\n0\n0.000000\n0.5221932\n0.2610966\n0\n0\n0\n0.0000000\n0.0000000\n0\n0\n0.0000000\n0\n6.527415\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2.7415144\n0.0000000\n0\n9.268930\n\n\n11\n2\n13-Mar-95\n15\n802\n4mile\n1\n5\n105\n0\n7.66\nrlfld\n53.1\n0\n0\n0\n0\n0.2610966\n0.0000000\n0\n0.0000000\n0\n0.000000\n0.0000000\n0.0000000\n0\n0\n0\n0.0000000\n0.0000000\n0\n0\n0.0000000\n0\n4.569191\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.2610966\n0.0000000\n0\n4.830287\n\n\n6\n2\n24-Jan-95\n13\n754\n4mile\n1\n3\n103\n0\n19.14\nrlfld\n44.2\n0\n0\n0\n0\n0.3134796\n0.3134796\n0\n0.0000000\n0\n0.000000\n0.0000000\n0.4702194\n0\n0\n0\n0.1044932\n0.0000000\n0\n0\n0.0522466\n0\n3.761756\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1.2016719\n0.0000000\n0\n5.015674\n\n\n11\n2\n13-Mar-95\n15\n802\n4mile\n1\n3\n103\n0\n19.14\nrlfld\n43.2\n0\n0\n0\n0\n0.1044932\n0.0000000\n0\n0.1567398\n0\n0.000000\n0.0000000\n0.2089864\n0\n0\n0\n0.0000000\n0.0522466\n0\n0\n0.0522466\n0\n1.567398\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.5224660\n0.0000000\n0\n2.142111\n\n\n11\n2\n13-Mar-95\n15\n802\n4mile\n1\n8\n108\n0\n3.36\nfld\n41.8\n0\n0\n0\n0\n0.0000000\n0.0000000\n0\n0.0000000\n0\n0.000000\n0.0000000\n0.0000000\n0\n0\n0\n0.0000000\n0.0000000\n0\n0\n0.0000000\n0\n0.000000\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.0000000\n0.0000000\n0\n0.000000\n\n\n6\n2\n24-Jan-95\n13\n754\n4mile\n1\n4\n104\n0\n4.52\nrlfld\n41.5\n0\n0\n0\n0\n0.0000000\n0.0000000\n0\n0.0000000\n0\n0.000000\n0.0000000\n0.0000000\n0\n0\n0\n0.0000000\n0.0000000\n0\n0\n0.2212389\n0\n18.584071\n0\n0\n0\n0\n0\n0\n0.6637168\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.0000000\n0.6637168\n0\n19.469027\n\n\n7\n2\n29-Jan-95\n13\n759\n4mile\n1\n5\n105\n0\n7.66\nrlfld\n40.1\n0\n0\n0\n0\n5.3524804\n0.0000000\n0\n0.0000000\n0\n0.000000\n0.3916449\n0.0000000\n0\n0\n0\n0.0000000\n0.0000000\n0\n0\n0.0000000\n0\n4.830287\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n5.7441253\n0.0000000\n0\n10.574412\n\n\n6\n1\n27-Jan-94\n13\n392\n4mile\n1\n8\n108\n0\n3.36\nfld\n40.0\n0\n0\n0\n0\n0.0000000\n0.0000000\n0\n0.0000000\n0\n0.000000\n0.0000000\n0.0000000\n0\n0\n0\n0.0000000\n0.0000000\n0\n0\n0.0000000\n0\n0.000000\n0\n0\n0\n0\n0\n0\n0.0000000\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0.0000000\n0.0000000\n0\n0.000000\n\n\n\n\n\nHow many times is the number of waterbirds equal to zero in this dataset? Create a frequency plot to find out! Focus on observed values between 0 and 100, and do not forget to round them off (use round()).\n\n\nCode\nwaterbirds |&gt; \n  filter(AQBIRDS &lt; 100) |&gt; \n  ggplot(aes(x=round(AQBIRDS)))+\n    geom_bar(stat = \"count\")+\n    theme_bw()+\n    ylab(\"Frequency\")+\n    xlab(\"Observed values\")+\n    theme(axis.text = element_text(colour = \"black\"),\n          axis.title.y = element_text(margin = margin(r=10)),\n          axis.title.x = element_text(margin = margin(t=10)))\n\n\n\n\n\n\n\n\n\nWhat can you conclude from this frequency plot?"
  },
  {
    "objectID": "data_exploration.html#step-5-is-there-colinearity-among-covariates",
    "href": "data_exploration.html#step-5-is-there-colinearity-among-covariates",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Step 5: Is there colinearity among covariates?",
    "text": "Step 5: Is there colinearity among covariates?\nZuur et al (2010) defined colinearity as “the existence of correlation between covariates”. The strength of the linear relationship between two continuous variables (X and Y) can be measured using Pearson’s correlation coefficient (Equation 1).\n\\[\nr=\\frac{cov(X,Y)}{\\sigma_X\\sigma_Y}\n\\tag{1}\\]\nIn Equation 1, \\(cov(X,Y)\\) is the covariance between X and Y. \\(\\sigma_X\\) and \\(\\sigma_Y\\) are the standard deviation values for variables X and Y. If \\(r=0\\), there is no linear relationship between X and Y. If \\(r=1\\) or \\(r=-1\\), there is a perfect positive or negative linear relationship between the two variables, respectively.\nA useful way to check for colinearity between covariates is to create a correlation plot. A scatter plot would also be a good idea, but as we will see how to create scatter plots in the next section, let’s concentrate here on creating a correlation plot.\nIn this example, we will work with a new sparrows dataset (VegSamplesV1.txt). The researchers who produced this dataset wanted to know whether the relative abundance of various plant species and other vegetation characteristics could explain the number of saltmarsh sparrows captured in each plot (Banded). We will work with the following covariates:\n\nMaximum vegetation height (Avgmaxht)\nVegetation stem density (Avgdens)\nHeight of thatch (ht.thatch)\nPercent cover of shrubs (Shrub)\nPercent cover of Juncus gerardii (Juncus)\nPercent cover of Spartina patens (S.patens)\nPercent cover of Distichlis spicata (Distichlis)\nPercent cover of short Spartina alterniflora (S.alternifloraShort)\nPercent cover of tall Spartina alterniflora (S.alternifloraTall)\nPercent cover of Phragmites australis (Phragmites)\nPercent cover of bare ground (Bare)\nPercent cover of water (Water)\n\n\n\nCode\n#Load data into R\nsparrows2 &lt;- read_delim(\"Data_Zuur_et_al_2010/VegSamplesV1.txt\",\n                        col_select = 1:19)\n\n#View data\nkable(head(sparrows2, n=10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nSite\nUniversalPlotName\nBanded\nPtCountsum\nAvgmaxht\nAvgdens\nht.thatch\nS.patens\nDistichlis\nS.alternifloraShort\nS.alternifloraTall\nJuncus\nBare\nOther\nPhragmites\nShrub\nTallsedge\nWater\n\n\n\n\n2002\nEastRiverMarsh\n02PLOT012\n31\n53\n33.19\n23.30\n4.67\n21.31\n41.47\n32.22\n2.78\n0.00\n1.67\n0.56\n0\n0.00\n0\n0.00\n\n\n2002\nEastRiverMarsh\n02PLOT013\n40\n40\n48.22\n27.63\n6.56\n11.67\n52.78\n23.61\n9.72\n0.00\n0.00\n0.00\n0\n0.00\n0\n2.22\n\n\n2002\nEastRiverMarsh\n02PLOT014\n15\n15\n33.81\n26.40\n3.33\n29.09\n17.80\n35.89\n0.00\n2.22\n8.33\n0.00\n0\n6.67\n0\n0.00\n\n\n2002\nEastRiverMarsh\n02PLOT015\n27\n33\n28.34\n45.63\n7.33\n52.22\n19.76\n5.56\n3.33\n7.78\n2.22\n8.89\n0\n0.00\n0\n0.25\n\n\n2002\nEastRiverMarsh\n02PLOT016\n20\n17\n28.75\n38.88\n3.44\n47.84\n12.78\n15.49\n10.00\n0.00\n10.14\n3.75\n0\n0.00\n0\n0.00\n\n\n2002\nEastRiverMarsh\n02PLOT017\n17\n30\n24.19\n53.60\n3.44\n60.42\n0.01\n26.44\n0.00\n0.00\n2.01\n0.00\n0\n0.00\n0\n11.11\n\n\n2002\nEastRiverMarsh\n02PLOT018\n17\n49\n39.34\n18.20\n2.11\n17.35\n2.67\n42.56\n25.03\n0.56\n11.29\n0.56\n0\n0.00\n0\n0.00\n\n\n2002\nEastRiverMarsh\n02PLOT019\n29\n39\n38.75\n48.18\n5.89\n55.34\n10.32\n20.56\n6.44\n5.56\n1.78\n0.00\n0\n0.00\n0\n0.00\n\n\n2002\nHammonassetSP\n02PLOT001\n13\n22\n38.06\n33.53\n5.22\n42.78\n0.00\n37.76\n9.78\n0.00\n3.33\n1.91\n0\n0.00\n0\n4.44\n\n\n2002\nHammonassetSP\n02PLOT002\n37\n23\n27.34\n17.40\n0.89\n17.22\n0.00\n29.74\n16.00\n0.00\n14.56\n0.26\n0\n0.00\n0\n22.22\n\n\n\n\n\nNow that the data have been imported into R, we can create a correlation plot to check for colinearity between the covariates we want to include in a statistical model. You can do this with the corrplot() or corrplot.mixed() function in the corrplot package.\n\n\nCode\ncorrplot.mixed(corr=cor(sparrows2[,c(\"Avgmaxht\",\n                                     \"Avgdens\",\n                                     \"ht.thatch\",\n                                     \"Shrub\",\n                                     \"Juncus\",\n                                     \"S.patens\",\n                                     \"Distichlis\",\n                                     \"S.alternifloraShort\",\n                                     \"S.alternifloraTall\",\n                                     \"Phragmites\",\n                                     \"Bare\",\n                                     \"Water\")]),\n           lower=\"number\",\n           upper=\"ellipse\",\n           tl.pos=\"lt\",\n           diag=\"n\",\n           tl.col=\"black\",\n           number.cex=0.7)\n\n\n\n\n\n\n\n\n\nWhat do you see? Is there colinearity among covariates in this dataset?"
  },
  {
    "objectID": "data_exploration.html#step-6-what-are-the-relationships-between-variables",
    "href": "data_exploration.html#step-6-what-are-the-relationships-between-variables",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Step 6: What are the relationships between variables?",
    "text": "Step 6: What are the relationships between variables?\nThe easiest way to find out how the relationship between a response variable of interest and a covariate looks like is to create a scatter plot. Let’s do this using the sparrows dataset we just used to look as colinearity. Using ggplot2, create a figure with multiple panels showing the relationship between the number of sparrows observed in a plot (Banded) and all covariates used in the previous section. In tidyverse, this is done by combining pivot_longer(), geom_point() and facet_wrap(). Let’s also add a smoother to each scatter plot to better visualise the relationships (use geom_smooth()). Give it a try!\n\n\nCode\nsparrows2 |&gt; \n  select(Banded,\n         Avgmaxht,\n         Avgdens,\n         ht.thatch,\n         Shrub,\n         Juncus,\n         S.patens,\n         Distichlis,\n         S.alternifloraShort,\n         S.alternifloraTall,\n         Phragmites,\n         Bare,\n         Water) |&gt;\n  pivot_longer(cols = Avgmaxht:Water,\n               names_to = \"Covariate\",\n               values_to = \"Value\") |&gt; \n  ggplot(aes(x=Value,\n             y=Banded))+\n  geom_point(shape=1)+\n  geom_smooth(span = 1.5)+\n  theme_bw()+\n  facet_wrap(~Covariate, scales = \"free_x\")+\n  ylab(\"Number of sparrows\")+\n  xlab(\"Covariate value\")+\n  theme(axis.text = element_text(colour = \"black\"),\n        axis.title.y = element_text(margin = margin(r=10)),\n        axis.title.x = element_text(margin = margin(t=10)))\n\n\n\n\n\n\n\n\n\nAre there any covariates that seem to be good predictors of the number of sparrows in a plot?"
  },
  {
    "objectID": "data_exploration.html#step-7-should-we-consider-interactions",
    "href": "data_exploration.html#step-7-should-we-consider-interactions",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Step 7: Should we consider interactions?",
    "text": "Step 7: Should we consider interactions?\nWhat do we mean by interaction in this context? Let’s return to the sparrow morphometric dataset used earlier. Let’s imagine that a researcher wants to determine whether the relationship between body mass (response variable) and wing length depends on other covariates, such as time and sex. If the relationship between body mass and wing length changes over time and differs between males and females, this suggests that there is a three-way interaction between wing length, time and sex. On the contrary, if the relationship between body mass and wing length is stable over time and is similar for males and females, there is probably no interaction between wing length, time and sex.\nLet’s visualise this! The best way to evaluate if interactions should be considered is to create a conditioning plot (or coplot). We can easily do this in tidyverse by combining geom_point() (to create scatter plots), geom_smooth(method=\"lm\") (to add a linear model on top of each scatter plot), and facet_grid() (to create multiple panels, with males/females as rows, and June/July/August as columns). In the Sex column, males are labelled 4 and females 5. Only consider observations where SpeciesCode is equal to 1. Give it a try!\n\n\nCode\nsparrows |&gt; \n  filter(SpeciesCode == 1) |&gt; \n  select(wt, wingcrd, Month, Sex) |&gt; \n  filter(Month &gt;= 6 & Month &lt;= 8) |&gt; \n  filter(Sex == 4 | Sex == 5) |&gt; \n  mutate(Month=replace(Month, Month==6, \"June\"),\n         Month=replace(Month, Month==7, \"July\"),\n         Month=replace(Month, Month==8, \"August\"),\n         Sex=replace(Sex, Sex==4, \"Male\"),\n         Sex=replace(Sex, Sex==5, \"Female\")) |&gt; \n  mutate(Month=factor(Month, levels=c(\"June\",\n                                      \"July\", \n                                      \"August\"))) |&gt;\n  \n  ggplot(aes(x=wingcrd,\n             y=wt))+\n    geom_point(shape=1)+\n    theme_bw()+\n    ylab(\"Weight (g)\")+\n    xlab(\"Wing length (mm)\")+\n    theme(axis.text = element_text(colour = \"black\"),\n          axis.title.y = element_text(margin = margin(r=10)),\n          axis.title.x = element_text(margin = margin(t=10)))+\n    facet_grid(Sex~Month)+\n    geom_smooth(method=\"lm\")\n\n\n\n\n\n\n\n\n\nWhat can you conclude from this figure?"
  },
  {
    "objectID": "data_exploration.html#step-8-are-observations-independent",
    "href": "data_exploration.html#step-8-are-observations-independent",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Step 8: Are observations independent?",
    "text": "Step 8: Are observations independent?"
  },
  {
    "objectID": "data_exploration.html#take-home-message",
    "href": "data_exploration.html#take-home-message",
    "title": "Tutorial 4: Data exploration in R",
    "section": "Take-home message",
    "text": "Take-home message\nWe hope this tutorial has convinced you of the importance of taking the time to explore your data before starting any form of analysis. Many problems occurring at the data analysis stage could be avoided by spending more time exploring and getting to know your data. This is particularly true for large datasets. Graphical tools are essential in this endeavor, which is why we have spent a fair amount of time in this course familiarizing ourselves with R functions to organise and plot data. Of course, this tutorial is far from exhaustive and we encourage you to continue learning and practicing data exploration in R."
  }
]